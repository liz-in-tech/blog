<!doctype html>
<html lang="zh-CN" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.0" />
    <meta name="theme" content="VuePress Theme Hope 2.0.0-rc.13" />
    <style>
      html {
        background: var(--bg-color, #fff);
      }

      html[data-theme="dark"] {
        background: var(--bg-color, #1d1e1f);
      }

      body {
        background: var(--bg-color);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <link rel="alternate" hreflang="en-us" href="https://liz-in-tech.github.io/blog/posts/llm/026_distribution_and_parallelism_2.html"><meta property="og:url" content="https://liz-in-tech.github.io/blog/zh/posts/llm/026_distribution_and_parallelism_2.html"><meta property="og:site_name" content="Liz"><meta property="og:title" content="åˆ†å¸ƒå¼è®­ç»ƒä¹‹ä¸‰ï¼šæ•°æ®å¹¶è¡Œ Data Parallelism"><meta property="og:description" content="åˆ†å¸ƒå¼è®­ç»ƒä¹‹ä¸‰ï¼šæ•°æ®å¹¶è¡Œ Data Parallelism"><meta property="og:type" content="article"><meta property="og:locale" content="zh-CN"><meta property="og:locale:alternate" content="en-US"><meta property="og:updated_time" content="2025-03-30T13:07:08.000Z"><meta property="article:author" content="Liz"><meta property="article:tag" content="åˆ†å¸ƒå¼"><meta property="article:tag" content="å¹¶è¡Œ"><meta property="article:published_time" content="2025-03-02T00:00:00.000Z"><meta property="article:modified_time" content="2025-03-30T13:07:08.000Z"><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"åˆ†å¸ƒå¼è®­ç»ƒä¹‹ä¸‰ï¼šæ•°æ®å¹¶è¡Œ Data Parallelism","image":[""],"datePublished":"2025-03-02T00:00:00.000Z","dateModified":"2025-03-30T13:07:08.000Z","author":[{"@type":"Person","name":"Liz","url":"https://github.com/liz-in-tech"}]}</script><link rel="icon" herf="/blogger.png"><link rel="icon" href="/blog/blogger.png"><title>åˆ†å¸ƒå¼è®­ç»ƒä¹‹ä¸‰ï¼šæ•°æ®å¹¶è¡Œ Data Parallelism | Liz</title><meta name="description" content="åˆ†å¸ƒå¼è®­ç»ƒä¹‹ä¸‰ï¼šæ•°æ®å¹¶è¡Œ Data Parallelism">
    <link rel="preload" href="/blog/assets/style-m_obra2h.css" as="style"><link rel="stylesheet" href="/blog/assets/style-m_obra2h.css">
    <link rel="modulepreload" href="/blog/assets/app-v5bcDFbF.js"><link rel="modulepreload" href="/blog/assets/026_distribution_and_parallelism_2.html-lTYQr6p_.js"><link rel="modulepreload" href="/blog/assets/026_distribution_and_parallelism_2.html-99kVKQLr.js"><link rel="modulepreload" href="/blog/assets/026_zero3_3-skr0K_0Q.js"><link rel="modulepreload" href="/blog/assets/024_mixed_precision_training_list-dG4PWcKt.js"><link rel="modulepreload" href="/blog/assets/plugin-vue_export-helper-x3n3nnut.js">
    <link rel="prefetch" href="/blog/assets/index.html-YbPtte5_.js" as="script"><link rel="prefetch" href="/blog/assets/intro.html-CGfhr1vY.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-FUMOuem4.js" as="script"><link rel="prefetch" href="/blog/assets/index.html--TTjrkIy.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-g4Nfr7z1.js" as="script"><link rel="prefetch" href="/blog/assets/intro.html-bitGHKd2.js" as="script"><link rel="prefetch" href="/blog/assets/001_langchain.html-nrisQopy.js" as="script"><link rel="prefetch" href="/blog/assets/002_langchain_sourcecode.html-9XtwFAwc.js" as="script"><link rel="prefetch" href="/blog/assets/003_streamlit.html-oji9upQP.js" as="script"><link rel="prefetch" href="/blog/assets/004_transformer.html-xrin91s2.js" as="script"><link rel="prefetch" href="/blog/assets/005_llama.html-RcwJewgQ.js" as="script"><link rel="prefetch" href="/blog/assets/006_llm_leaderboard.html-c628DmZb.js" as="script"><link rel="prefetch" href="/blog/assets/007_computer_use.html-4RcS3hxb.js" as="script"><link rel="prefetch" href="/blog/assets/008_rag_challenge.html-_8stdYVV.js" as="script"><link rel="prefetch" href="/blog/assets/009_llm_challenge.html-eluz3bTT.js" as="script"><link rel="prefetch" href="/blog/assets/010_rag_workflow.html-Ft0RQWf3.js" as="script"><link rel="prefetch" href="/blog/assets/011_vector_database.html-htZNHy9b.js" as="script"><link rel="prefetch" href="/blog/assets/012_prompt_engineering.html-Q27DlfZz.js" as="script"><link rel="prefetch" href="/blog/assets/013_optimizing_llm.html-6CxOIR84.js" as="script"><link rel="prefetch" href="/blog/assets/014_rag_evaluation.html-GIu-oGwK.js" as="script"><link rel="prefetch" href="/blog/assets/015_fine_tune.html-Gj-zyjT6.js" as="script"><link rel="prefetch" href="/blog/assets/016_multimodal.html-xa8M4Wu4.js" as="script"><link rel="prefetch" href="/blog/assets/017_agent_and_multiagent.html-dm178NRn.js" as="script"><link rel="prefetch" href="/blog/assets/018_huggingface.html-WI0c55vB.js" as="script"><link rel="prefetch" href="/blog/assets/019_ollama.html-kLkdC4dl.js" as="script"><link rel="prefetch" href="/blog/assets/020_neo4j.html-P-Llr3CJ.js" as="script"><link rel="prefetch" href="/blog/assets/021_microsoft_graphrag.html-0d0frUhq.js" as="script"><link rel="prefetch" href="/blog/assets/022_llamaindex_graphrag.html-RhkTd_Zr.js" as="script"><link rel="prefetch" href="/blog/assets/023_agent_framework.html-5MCDM_Sd.js" as="script"><link rel="prefetch" href="/blog/assets/024_distribution_and_parallelism.html-01hi9eD-.js" as="script"><link rel="prefetch" href="/blog/assets/025_distribution_and_parallelism_1.html-32IzAErP.js" as="script"><link rel="prefetch" href="/blog/assets/026_distribution_and_parallelism_2.html-rsWgIQO4.js" as="script"><link rel="prefetch" href="/blog/assets/027_distribution_and_parallelism_3.html-aP_ykF_V.js" as="script"><link rel="prefetch" href="/blog/assets/028_distribution_and_parallelism_4.html-Kub1JEXd.js" as="script"><link rel="prefetch" href="/blog/assets/029_unsloth_grpo.html-zgQtWVj-.js" as="script"><link rel="prefetch" href="/blog/assets/030_wandb.html-QwJ87Q-u.js" as="script"><link rel="prefetch" href="/blog/assets/031_qlora.html-JOYVOncP.js" as="script"><link rel="prefetch" href="/blog/assets/032_sft_trainer_sourcecode_prepare_model.html-6NUsa_LT.js" as="script"><link rel="prefetch" href="/blog/assets/033_sft_trainer_sourcecode_prepare_dataset.html-znW51XOY.js" as="script"><link rel="prefetch" href="/blog/assets/034_sft_trainer_sourcecode_prepare_trainer.html-jLWECXBF.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ZDCSnlc1.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ZYw6WxxA.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-OavE9BET.js" as="script"><link rel="prefetch" href="/blog/assets/001_langchain.html-hE_T0u_5.js" as="script"><link rel="prefetch" href="/blog/assets/002_langchain_sourcecode.html-iH0mq6XB.js" as="script"><link rel="prefetch" href="/blog/assets/003_streamlit.html-WyFhRqF6.js" as="script"><link rel="prefetch" href="/blog/assets/004_transformer.html-wy9Toayl.js" as="script"><link rel="prefetch" href="/blog/assets/005_llama.html-Igb8VTzY.js" as="script"><link rel="prefetch" href="/blog/assets/006_llm_leaderboard.html-WHPR-17-.js" as="script"><link rel="prefetch" href="/blog/assets/007_computer_use.html-hz6Q-DAA.js" as="script"><link rel="prefetch" href="/blog/assets/008_rag_challenge.html-3KMCwhrh.js" as="script"><link rel="prefetch" href="/blog/assets/009_llm_challenge.html-7gxKMp_3.js" as="script"><link rel="prefetch" href="/blog/assets/010_rag_workflow.html-KndRvZAj.js" as="script"><link rel="prefetch" href="/blog/assets/011_vector_database.html-DtFi92ig.js" as="script"><link rel="prefetch" href="/blog/assets/012_prompt_engineering.html-ZdCqy2Fu.js" as="script"><link rel="prefetch" href="/blog/assets/013_optimizing_llm.html-W-CdR_ck.js" as="script"><link rel="prefetch" href="/blog/assets/014_rag_evaluation.html-mimwqA-t.js" as="script"><link rel="prefetch" href="/blog/assets/015_fine_tune.html--JjBpVvQ.js" as="script"><link rel="prefetch" href="/blog/assets/016_multimodal.html-hiqs-a6X.js" as="script"><link rel="prefetch" href="/blog/assets/017_agent_and_multiagent.html-bS1SRdf4.js" as="script"><link rel="prefetch" href="/blog/assets/018_huggingface.html-Si3T7PB7.js" as="script"><link rel="prefetch" href="/blog/assets/019_ollama.html-V5tcXCC4.js" as="script"><link rel="prefetch" href="/blog/assets/020_neo4j.html-ytaIU5xV.js" as="script"><link rel="prefetch" href="/blog/assets/021_microsoft_graphrag.html-kvlLpO3f.js" as="script"><link rel="prefetch" href="/blog/assets/022_llamaindex_graphrag.html-nS8_ZZy5.js" as="script"><link rel="prefetch" href="/blog/assets/023_agent_framework.html-VZsN2kO8.js" as="script"><link rel="prefetch" href="/blog/assets/024_distribution_and_parallelism.html-oCd9cE9Q.js" as="script"><link rel="prefetch" href="/blog/assets/025_distribution_and_parallelism_1.html-ZR9kuXUl.js" as="script"><link rel="prefetch" href="/blog/assets/027_distribution_and_parallelism_3.html-j2B_wJ9U.js" as="script"><link rel="prefetch" href="/blog/assets/028_distribution_and_parallelism_4.html-38Gbieji.js" as="script"><link rel="prefetch" href="/blog/assets/029_unsloth_grpo.html-MLBLxBKQ.js" as="script"><link rel="prefetch" href="/blog/assets/030_wandb.html-nzAhc8i2.js" as="script"><link rel="prefetch" href="/blog/assets/031_qlora.html-vUUfqpgA.js" as="script"><link rel="prefetch" href="/blog/assets/032_sft_trainer_sourcecode_prepare_model.html-TUbRRh-O.js" as="script"><link rel="prefetch" href="/blog/assets/033_sft_trainer_sourcecode_prepare_dataset.html-RGXXyFkO.js" as="script"><link rel="prefetch" href="/blog/assets/034_sft_trainer_sourcecode_prepare_trainer.html-h3f0tH03.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-wh_dBtOR.js" as="script"><link rel="prefetch" href="/blog/assets/404.html-cxLWDy2T.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-kf4JCRaf.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-RkA-insV.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-4kI_oqSd.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-WhuidxNt.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-OqGkeUA_.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-5GeN-sdD.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-c4Rf4yh1.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-2r0jUs7o.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-BSKRXRQc.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-KjTsJ0Hg.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-TteIwMx3.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-g00XXzrL.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-YxbJgo4L.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-3T79Cy0i.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-A5tlQHan.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-04ff5e0O.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-vgZ6rfFh.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-OmipPplE.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-E1KrJL6a.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-oPH9QkTj.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-cHRqZSs8.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-74SU9ZTn.js" as="script"><link rel="prefetch" href="/blog/assets/index.html--iJiA8oX.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-oZPWb_Fc.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-FUIWSLsp.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-5ERWyusD.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Zjn0JNqd.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-jcvPTrgB.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-9t2TsyuQ.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-CcLVFNIv.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-DVoYOOaL.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-V52ipvRm.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-9If_KW0o.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-df9Mrf2R.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-f9bWoKcO.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-GYH0QUoo.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-JVTfeijx.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-_C1QVNqX.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-L_IXFmna.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-nZWHmXY7.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-x4gPgqE4.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-bWnVyuyA.js" as="script"><link rel="prefetch" href="/blog/assets/index.html--yTU23ka.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-tRnpyzfw.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-7aypos-L.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-1BXcbV1R.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-pu478WKz.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-DFi1VhMA.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-7uaSljkV.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-UeJoj0gS.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-BULhD4SJ.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-i7RIA9-O.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-cVdKTxAl.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-LHukpLS7.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-howjHe2f.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-DeN_iOWx.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-cnlzR0a7.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-0P_c_pcU.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-dy_CcFmq.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-FzFytZ_p.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-2KSwV7xp.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-F1coElwg.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ffflqCb9.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-F8ZuLYgH.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-HeYWaFeL.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-xKYeJEc5.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-xB-iS7Ql.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-OEUPqfTV.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-EE4iQI9m.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-g1PUF_BG.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-nUBcs85a.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-9Y3la5Sf.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-wufIFDPM.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-bXZQIxRE.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-wd6ZkEHi.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Xlk0AXmC.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Uv7c7pYa.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-FfZqC9tZ.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-mSPhZxqB.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-51HoKD5A.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Q5_K6Vux.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-jkWPo860.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-kTEqch5G.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-y4iBqBqc.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ibHhI9SI.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-3hk_s27_.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-QJ9j3Zl2.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-QvWFHL99.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Pefl6i_g.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-dNHrcQzx.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-tITHrBRq.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-l-UCqoWK.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-r_IMIQdZ.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-FFF0RGO4.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-jWI8KaSx.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ErByaVwg.js" as="script"><link rel="prefetch" href="/blog/assets/intro.html-i6L7adZK.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-EcsmugCa.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-XWhg2wST.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-hGblY0m5.js" as="script"><link rel="prefetch" href="/blog/assets/intro.html-XwiYvbIK.js" as="script"><link rel="prefetch" href="/blog/assets/001_langchain.html-GeYfHopu.js" as="script"><link rel="prefetch" href="/blog/assets/002_langchain_sourcecode.html-paWNKBSc.js" as="script"><link rel="prefetch" href="/blog/assets/003_streamlit.html-T76zUd_T.js" as="script"><link rel="prefetch" href="/blog/assets/004_transformer.html-bac1SKe4.js" as="script"><link rel="prefetch" href="/blog/assets/005_llama.html-xSapr9te.js" as="script"><link rel="prefetch" href="/blog/assets/006_llm_leaderboard.html-1r_2Xc4o.js" as="script"><link rel="prefetch" href="/blog/assets/007_computer_use.html-JiAq1EGf.js" as="script"><link rel="prefetch" href="/blog/assets/008_rag_challenge.html-f4WQ58r6.js" as="script"><link rel="prefetch" href="/blog/assets/009_llm_challenge.html-Ku6AJafC.js" as="script"><link rel="prefetch" href="/blog/assets/010_rag_workflow.html-J76tsHEg.js" as="script"><link rel="prefetch" href="/blog/assets/011_vector_database.html-oEvrlY2o.js" as="script"><link rel="prefetch" href="/blog/assets/012_prompt_engineering.html--WmmOiOZ.js" as="script"><link rel="prefetch" href="/blog/assets/013_optimizing_llm.html-jbc_FMd7.js" as="script"><link rel="prefetch" href="/blog/assets/014_rag_evaluation.html-jYryOp3z.js" as="script"><link rel="prefetch" href="/blog/assets/015_fine_tune.html-hOu-S7SI.js" as="script"><link rel="prefetch" href="/blog/assets/016_multimodal.html-k16i4rfI.js" as="script"><link rel="prefetch" href="/blog/assets/017_agent_and_multiagent.html-JQVQkktq.js" as="script"><link rel="prefetch" href="/blog/assets/018_huggingface.html-jzjkw5cs.js" as="script"><link rel="prefetch" href="/blog/assets/019_ollama.html-YYh65X8S.js" as="script"><link rel="prefetch" href="/blog/assets/020_neo4j.html-Oo-EF862.js" as="script"><link rel="prefetch" href="/blog/assets/021_microsoft_graphrag.html-5ZIO5m03.js" as="script"><link rel="prefetch" href="/blog/assets/022_llamaindex_graphrag.html-92Y9XPXc.js" as="script"><link rel="prefetch" href="/blog/assets/023_agent_framework.html-YUwLuN7l.js" as="script"><link rel="prefetch" href="/blog/assets/024_distribution_and_parallelism.html-0udqPsy-.js" as="script"><link rel="prefetch" href="/blog/assets/025_distribution_and_parallelism_1.html-wjtZF3Ey.js" as="script"><link rel="prefetch" href="/blog/assets/026_distribution_and_parallelism_2.html-EgYFIN8X.js" as="script"><link rel="prefetch" href="/blog/assets/027_distribution_and_parallelism_3.html-TDLmZOfN.js" as="script"><link rel="prefetch" href="/blog/assets/028_distribution_and_parallelism_4.html-m_lCatvv.js" as="script"><link rel="prefetch" href="/blog/assets/029_unsloth_grpo.html-mdMZZDiZ.js" as="script"><link rel="prefetch" href="/blog/assets/030_wandb.html-sXLsNyui.js" as="script"><link rel="prefetch" href="/blog/assets/031_qlora.html-zrhw_Nz5.js" as="script"><link rel="prefetch" href="/blog/assets/032_sft_trainer_sourcecode_prepare_model.html-00NJoJyb.js" as="script"><link rel="prefetch" href="/blog/assets/033_sft_trainer_sourcecode_prepare_dataset.html-V4JDlJWM.js" as="script"><link rel="prefetch" href="/blog/assets/034_sft_trainer_sourcecode_prepare_trainer.html-xtKFO81R.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-U65HNMax.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-h_iLVcMr.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-gAzgX_Y8.js" as="script"><link rel="prefetch" href="/blog/assets/001_langchain.html-qVgYj_8n.js" as="script"><link rel="prefetch" href="/blog/assets/002_langchain_sourcecode.html-ahmHFu1l.js" as="script"><link rel="prefetch" href="/blog/assets/003_streamlit.html-IO54_tgV.js" as="script"><link rel="prefetch" href="/blog/assets/004_transformer.html-rsSoIlKH.js" as="script"><link rel="prefetch" href="/blog/assets/005_llama.html-E4b3xtmI.js" as="script"><link rel="prefetch" href="/blog/assets/006_llm_leaderboard.html-Io7DUBa5.js" as="script"><link rel="prefetch" href="/blog/assets/007_computer_use.html-XXFflABF.js" as="script"><link rel="prefetch" href="/blog/assets/008_rag_challenge.html-JqVc-n7x.js" as="script"><link rel="prefetch" href="/blog/assets/009_llm_challenge.html-3uX6AwKv.js" as="script"><link rel="prefetch" href="/blog/assets/010_rag_workflow.html-zRnfxmsd.js" as="script"><link rel="prefetch" href="/blog/assets/011_vector_database.html-Q1iY5Uj4.js" as="script"><link rel="prefetch" href="/blog/assets/012_prompt_engineering.html-I9nefwrz.js" as="script"><link rel="prefetch" href="/blog/assets/013_optimizing_llm.html-KLB-VG4U.js" as="script"><link rel="prefetch" href="/blog/assets/014_rag_evaluation.html-nZVtnUPv.js" as="script"><link rel="prefetch" href="/blog/assets/015_fine_tune.html-PCT5rGE0.js" as="script"><link rel="prefetch" href="/blog/assets/016_multimodal.html-YYSHpU0u.js" as="script"><link rel="prefetch" href="/blog/assets/017_agent_and_multiagent.html-1MyeLcEX.js" as="script"><link rel="prefetch" href="/blog/assets/018_huggingface.html-NVIzrEOC.js" as="script"><link rel="prefetch" href="/blog/assets/019_ollama.html-B6gcA5-w.js" as="script"><link rel="prefetch" href="/blog/assets/020_neo4j.html-AzEW6-fH.js" as="script"><link rel="prefetch" href="/blog/assets/021_microsoft_graphrag.html-dqqv9B9q.js" as="script"><link rel="prefetch" href="/blog/assets/022_llamaindex_graphrag.html-4YSLyRj2.js" as="script"><link rel="prefetch" href="/blog/assets/023_agent_framework.html-q6oiIFur.js" as="script"><link rel="prefetch" href="/blog/assets/024_distribution_and_parallelism.html-YUJUICFH.js" as="script"><link rel="prefetch" href="/blog/assets/025_distribution_and_parallelism_1.html-rqJW4LIr.js" as="script"><link rel="prefetch" href="/blog/assets/027_distribution_and_parallelism_3.html-i3xmpf9k.js" as="script"><link rel="prefetch" href="/blog/assets/028_distribution_and_parallelism_4.html-rSvt4BiT.js" as="script"><link rel="prefetch" href="/blog/assets/029_unsloth_grpo.html-p3AHWjev.js" as="script"><link rel="prefetch" href="/blog/assets/030_wandb.html-P113Ufas.js" as="script"><link rel="prefetch" href="/blog/assets/031_qlora.html-5nko2JaU.js" as="script"><link rel="prefetch" href="/blog/assets/032_sft_trainer_sourcecode_prepare_model.html-yjZC4_RP.js" as="script"><link rel="prefetch" href="/blog/assets/033_sft_trainer_sourcecode_prepare_dataset.html-gxAJDbCu.js" as="script"><link rel="prefetch" href="/blog/assets/034_sft_trainer_sourcecode_prepare_trainer.html-Ned8InaI.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-dszj4xZ6.js" as="script"><link rel="prefetch" href="/blog/assets/404.html-SvzvhyaF.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-9JsptYhF.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Ezwlo9JL.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-KCAfw_8o.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-3rdHsD_R.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-b2xowSWT.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-rPjzPsy3.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-d4q5_OjH.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-rgZXamH3.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-9D5rz3jx.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-kr5ysTxR.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-FjgJHG03.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-v7_KHgMD.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-LbrL1opU.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-TIxjCoIX.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-TSL0K1Y3.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-pey5puwk.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-2zirtd8_.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-SW20Oz7Z.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ubN7mM4P.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-xVNPfcwn.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-l5Dz77VI.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-TsaR-7n2.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-16Mnz8fy.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-vj-OAkvH.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-srO5XcGP.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-uuKDebeZ.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-otdJ4BTm.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-4XauGXIh.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-s33vMsvv.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-vM_Wa4eu.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-KxvqrxFy.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-HoK77Wcm.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-6e79wm8i.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-DfPGKvx-.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-v0_52JLV.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-OX9qZZJz.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-X9seX8Dg.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-hBdp6RMr.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-L7lhNgy-.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-4iq44NwH.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-S0gd-d9z.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-O5DoB959.js" as="script"><link rel="prefetch" href="/blog/assets/index.html--6YLCYUA.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Ta8TJrWI.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Pd5d5VDQ.js" as="script"><link rel="prefetch" href="/blog/assets/index.html--UnxRw8M.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Vv7JBMJo.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-UEWUR72h.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-13A1owT0.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-sv-OzP_G.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-m0t0LOra.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-fbbYlZeb.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-lAnyfZ9Q.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-TCfEa3Gl.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-PpzSDfDV.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-0rXCichf.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-fO6izxrB.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-J0zpKUS0.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-3UjYX_62.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-qno38Psk.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ULjnqer6.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-FnMfu-6u.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-poyw1RqG.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-bxNiZfsg.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-iyY6UMUk.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-UvplFO08.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Sm7wQcUk.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-4sm21bru.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-GBXoWu1D.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-rNiSyx6S.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-bi9HQHU5.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-E_EqbmVz.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-IgefXqAi.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-pvfHxO2Y.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-TADG-VKz.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-9eBAyAZt.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-jrWuH7qI.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-9Q0K7ju_.js" as="script"><link rel="prefetch" href="/blog/assets/index.html--jlC3EcV.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-KwAzqYf3.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-SYcjPjF4.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-VPgbnH_9.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-83w8yP9j.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-JZsf5MBH.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-gqv1i1Hl.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-r6kseor5.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-KnV8X9Yk.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-sxJ0BMlW.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-7Zdy8I7q.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-i-XTqsEU.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-xx5skesc.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-XzDalOSj.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-yfPYpr9E.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-PuMxUPBL.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Z-QcTam5.js" as="script"><link rel="prefetch" href="/blog/assets/photoswipe.esm-08_zHRDQ.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">è·³è‡³ä¸»è¦å…§å®¹</a><!--]--><!--[--><div class="theme-container no-sidebar has-toc"><!--[--><header id="navbar" class="vp-navbar"><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!--[--><!----><!--]--><!--[--><a class="vp-link vp-brand vp-brand" href="/blog/zh/"><img class="vp-nav-logo" src="/blog/blogger.png" alt><!----><span class="vp-site-name hide-in-pad">Liz</span></a><!--]--><!--[--><!----><!--]--></div><div class="vp-navbar-center"><!--[--><!----><!--]--><!--[--><nav class="vp-nav-links"><div class="nav-item hide-in-mobile"><a aria-label="é¦–é¡µ" class="vp-link nav-link nav-link" href="/blog/zh/"><span class="font-icon icon fa-fw fa-sm fas fa-home" style=""></span>é¦–é¡µ<!----></a></div><div class="nav-item hide-in-mobile"><a aria-label="é¡¹ç›®" class="vp-link nav-link nav-link" href="/blog/zh/demo/"><span class="font-icon icon fa-fw fa-sm fas fa-star" style=""></span>é¡¹ç›®<!----></a></div></nav><!--]--><!--[--><!----><!--]--></div><div class="vp-navbar-end"><!--[--><!----><!--]--><!--[--><div class="nav-item"><div class="dropdown-wrapper i18n-dropdown"><button type="button" class="dropdown-title" aria-label="é€‰æ‹©è¯­è¨€"><!--[--><svg xmlns="http://www.w3.org/2000/svg" class="icon i18n-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="i18n icon" style="width:1rem;height:1rem;vertical-align:middle;"><path d="M379.392 460.8 494.08 575.488l-42.496 102.4L307.2 532.48 138.24 701.44l-71.68-72.704L234.496 460.8l-45.056-45.056c-27.136-27.136-51.2-66.56-66.56-108.544h112.64c7.68 14.336 16.896 27.136 26.112 35.84l45.568 46.08 45.056-45.056C382.976 312.32 409.6 247.808 409.6 204.8H0V102.4h256V0h102.4v102.4h256v102.4H512c0 70.144-37.888 161.28-87.04 210.944L378.88 460.8zM576 870.4 512 1024H409.6l256-614.4H768l256 614.4H921.6l-64-153.6H576zM618.496 768h196.608L716.8 532.48 618.496 768z"></path></svg><!--]--><span class="arrow"></span><ul class="nav-dropdown"><li class="dropdown-item"><a aria-label="English" class="vp-link nav-link nav-link" href="/blog/posts/llm/026_distribution_and_parallelism_2.html"><!---->English<!----></a></li><li class="dropdown-item"><a aria-label="ç®€ä½“ä¸­æ–‡" class="vp-link nav-link active nav-link active" href="/blog/zh/posts/llm/026_distribution_and_parallelism_2.html"><!---->ç®€ä½“ä¸­æ–‡<!----></a></li></ul></button></div></div><div class="nav-item vp-repo"><a class="vp-repo-link" href="https://github.com/liz-in-tech" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><div class="nav-item hide-in-mobile"><button type="button" id="appearance-switch"><svg xmlns="http://www.w3.org/2000/svg" class="icon auto-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="auto icon" style="display:block;"><path d="M512 992C246.92 992 32 777.08 32 512S246.92 32 512 32s480 214.92 480 480-214.92 480-480 480zm0-840c-198.78 0-360 161.22-360 360 0 198.84 161.22 360 360 360s360-161.16 360-360c0-198.78-161.22-360-360-360zm0 660V212c165.72 0 300 134.34 300 300 0 165.72-134.28 300-300 300z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon dark-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="dark icon" style="display:none;"><path d="M524.8 938.667h-4.267a439.893 439.893 0 0 1-313.173-134.4 446.293 446.293 0 0 1-11.093-597.334A432.213 432.213 0 0 1 366.933 90.027a42.667 42.667 0 0 1 45.227 9.386 42.667 42.667 0 0 1 10.24 42.667 358.4 358.4 0 0 0 82.773 375.893 361.387 361.387 0 0 0 376.747 82.774 42.667 42.667 0 0 1 54.187 55.04 433.493 433.493 0 0 1-99.84 154.88 438.613 438.613 0 0 1-311.467 128z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon light-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="light icon" style="display:none;"><path d="M952 552h-80a40 40 0 0 1 0-80h80a40 40 0 0 1 0 80zM801.88 280.08a41 41 0 0 1-57.96-57.96l57.96-58a41.04 41.04 0 0 1 58 58l-58 57.96zM512 752a240 240 0 1 1 0-480 240 240 0 0 1 0 480zm0-560a40 40 0 0 1-40-40V72a40 40 0 0 1 80 0v80a40 40 0 0 1-40 40zm-289.88 88.08-58-57.96a41.04 41.04 0 0 1 58-58l57.96 58a41 41 0 0 1-57.96 57.96zM192 512a40 40 0 0 1-40 40H72a40 40 0 0 1 0-80h80a40 40 0 0 1 40 40zm30.12 231.92a41 41 0 0 1 57.96 57.96l-57.96 58a41.04 41.04 0 0 1-58-58l58-57.96zM512 832a40 40 0 0 1 40 40v80a40 40 0 0 1-80 0v-80a40 40 0 0 1 40-40zm289.88-88.08 58 57.96a41.04 41.04 0 0 1-58 58l-57.96-58a41 41 0 0 1 57.96-57.96z"></path></svg></button></div><form class="search-box" role="search"><input type="search" placeholder="æœç´¢" autocomplete="off" spellcheck="false" value><!----></form><!--]--><!--[--><!----><!--]--><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar"><!--[--><!----><!--]--><ul class="vp-sidebar-links"></ul><!--[--><!----><!--]--></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!--[--><!----><!--]--><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><span class="font-icon icon fa-fw fa-sm fas fa-lightbulb" style=""></span>åˆ†å¸ƒå¼è®­ç»ƒä¹‹ä¸‰ï¼šæ•°æ®å¹¶è¡Œ Data Parallelism</h1><div class="page-info"><span class="page-author-info" aria-label="ä½œè€…ğŸ–Š" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><a class="page-author-item" href="https://github.com/liz-in-tech" target="_blank" rel="noopener noreferrer">Liz</a></span><span property="author" content="Liz"></span></span><!----><span class="page-date-info" aria-label="å†™ä½œæ—¥æœŸğŸ“…" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span><!----></span><meta property="datePublished" content="2025-03-02T00:00:00.000Z"></span><!----><span class="page-reading-time-info" aria-label="é˜…è¯»æ—¶é—´âŒ›" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>å¤§çº¦ 12 åˆ†é’Ÿ</span><meta property="timeRequired" content="PT12M"></span><span class="page-category-info" aria-label="åˆ†ç±»ğŸŒˆ" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon category-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="category icon"><path d="M148.41 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H148.41c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.311-40.31zM147.556 553.478H429.73c22.263 0 40.311 18.048 40.311 40.31v282.176c0 22.263-18.048 40.312-40.31 40.312H147.555c-22.263 0-40.311-18.049-40.311-40.312V593.79c0-22.263 18.048-40.311 40.31-40.311zM593.927 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H593.927c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.31-40.31zM730.22 920.502H623.926c-40.925 0-74.22-33.388-74.22-74.425V623.992c0-41.038 33.387-74.424 74.425-74.424h222.085c41.038 0 74.424 33.226 74.424 74.067v114.233c0 10.244-8.304 18.548-18.547 18.548s-18.548-8.304-18.548-18.548V623.635c0-20.388-16.746-36.974-37.33-36.974H624.13c-20.585 0-37.331 16.747-37.331 37.33v222.086c0 20.585 16.654 37.331 37.126 37.331H730.22c10.243 0 18.547 8.304 18.547 18.547 0 10.244-8.304 18.547-18.547 18.547z"></path></svg><!--[--><span class="page-category-item category6 clickable" role="navigation">LLM</span><!--]--><meta property="articleSection" content="LLM"></span><span class="page-tag-info" aria-label="æ ‡ç­¾ğŸ·" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon tag-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="tag icon"><path d="M939.902 458.563L910.17 144.567c-1.507-16.272-14.465-29.13-30.737-30.737L565.438 84.098h-.402c-3.215 0-5.726 1.005-7.634 2.913l-470.39 470.39a10.004 10.004 0 000 14.164l365.423 365.424c1.909 1.908 4.42 2.913 7.132 2.913s5.223-1.005 7.132-2.913l470.39-470.39c2.01-2.11 3.014-5.023 2.813-8.036zm-240.067-72.121c-35.458 0-64.286-28.828-64.286-64.286s28.828-64.285 64.286-64.285 64.286 28.828 64.286 64.285-28.829 64.286-64.286 64.286z"></path></svg><!--[--><span class="page-tag-item tag4 clickable" role="navigation">åˆ†å¸ƒå¼</span><span class="page-tag-item tag3 clickable" role="navigation">å¹¶è¡Œ</span><!--]--><meta property="keywords" content="åˆ†å¸ƒå¼,å¹¶è¡Œ"></span></div><hr></div><div class="toc-place-holder"><aside id="toc"><!--[--><!----><!--]--><div class="toc-header">æ­¤é¡µå†…å®¹<button type="button" class="print-button" title="æ‰“å°"><svg xmlns="http://www.w3.org/2000/svg" class="icon print-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="print icon"><path d="M819.2 364.8h-44.8V128c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v236.8h-44.8C145.067 364.8 96 413.867 96 473.6v192c0 59.733 49.067 108.8 108.8 108.8h44.8V896c0 17.067 14.933 32 32 32h460.8c17.067 0 32-14.933 32-32V774.4h44.8c59.733 0 108.8-49.067 108.8-108.8v-192c0-59.733-49.067-108.8-108.8-108.8zM313.6 160h396.8v204.8H313.6V160zm396.8 704H313.6V620.8h396.8V864zM864 665.6c0 25.6-19.2 44.8-44.8 44.8h-44.8V588.8c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v121.6h-44.8c-25.6 0-44.8-19.2-44.8-44.8v-192c0-25.6 19.2-44.8 44.8-44.8h614.4c25.6 0 44.8 19.2 44.8 44.8v192z"></path></svg></button></div><div class="toc-wrapper"><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_1-dpæ¦‚è§ˆ">1. DPæ¦‚è§ˆ</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_2-data-parallelism-dp">2. Data Parallelism (DP)</a></li><li><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_2-1-æœ´ç´ dp-naive-ddp-approach">2.1. æœ´ç´ DPï¼ˆnaive DDP approachï¼‰</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_2-2-dpä¼˜åŒ–">2.2. DPä¼˜åŒ–</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_2-3-dbå®è·µ">2.3. DBå®è·µ</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_2-4-é‡‡ç”¨dpçš„è¡¨ç°">2.4. é‡‡ç”¨DPçš„è¡¨ç°</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_3-deepspeed-zero">3. DeepSpeed ZeRO</a></li><li><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_3-1-zero">3.1. ZeRO</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_3-2-æ··åˆç²¾åº¦è®­ç»ƒå›é¡¾">3.2. æ··åˆç²¾åº¦è®­ç»ƒå›é¡¾</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_3-3-zero-1">3.3. ZeRO-1</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_3-4-zero-2">3.4. ZeRO-2</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_3-5-zero-3">3.5. ZeRO-3</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_4-æ‰©å±•é“¾æ¥">4. æ‰©å±•é“¾æ¥</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_5-ä»£ç å®ç°">5. ä»£ç å®ç°</a></li><li><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_5-1-naive-dp-implementation-with-overlap-in-picotron">5.1. Naive DP implementation with overlap in Picotron</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_5-2-bucket-dp-implementation-in-picotron">5.2. Bucket DP implementation in Picotron</a></li><!----><!--]--></ul></li><!--]--></ul><div class="toc-marker" style="top:-1.7rem;"></div></div><!--[--><!----><!--]--></aside></div><!--[--><!----><!--]--><div class="theme-hope-content"><h1 id="åˆ†å¸ƒå¼è®­ç»ƒä¹‹ä¸‰-æ•°æ®å¹¶è¡Œ-data-parallelism" tabindex="-1"><a class="header-anchor" href="#åˆ†å¸ƒå¼è®­ç»ƒä¹‹ä¸‰-æ•°æ®å¹¶è¡Œ-data-parallelism" aria-hidden="true">#</a> åˆ†å¸ƒå¼è®­ç»ƒä¹‹ä¸‰ï¼šæ•°æ®å¹¶è¡Œ Data Parallelism</h1><!-- more --><h2 id="_1-dpæ¦‚è§ˆ" tabindex="-1"><a class="header-anchor" href="#_1-dpæ¦‚è§ˆ" aria-hidden="true">#</a> 1. DPæ¦‚è§ˆ</h2><p>Data parallelism (DP)</p><ul><li>æœ´ç´ DPï¼ˆnaive DDP approachï¼‰</li><li>DPä¼˜åŒ–ä¸€ï¼šä¸ºæ¯ä¸ªå‚æ•°é™„åŠ ä¸€ä¸ªall-reduceçš„é’©å­å‡½æ•°</li><li>DPä¼˜åŒ–äºŒï¼šåˆ†æ¡¶ Bucketing gradients</li><li>ZeRO (Zero Redundancy Optimizer) <ul><li>ZeRO-1: optimizer state partitioning</li><li>ZeRO-2: optimizer state + gradient partitioning</li><li>ZeRO-3 / FSDP (Fully-Sharded Data Parallelism): optimizer state + gradient + parameter partitioning</li></ul></li></ul><h2 id="_2-data-parallelism-dp" tabindex="-1"><a class="header-anchor" href="#_2-data-parallelism-dp" aria-hidden="true">#</a> 2. Data Parallelism (DP)</h2><p>ä¸åŒå¾®æ‰¹æ¬¡åœ¨ä¸åŒçš„GPUä¸Šå¹¶è¡Œå¤„ç†ï¼ˆmicro batchä¸Šåªè¿›è¡Œæ¢¯åº¦è®¡ç®—ï¼Œæ¯ä¸ªglobal batchæ›´æ–°ä¸€æ¬¡æ¨¡å‹å‚æ•°ï¼‰</p><ul><li>æ¯ä¸ªGPUä¸Šå¤åˆ¶ä¸€ä»½æ¨¡å‹å®ä¾‹</li><li>å¤šä¸ªGPUå¹¶è¡Œè®¡ç®—å¾®æ‰¹æ¬¡çš„å‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­ï¼Œç„¶åè®¡ç®—å‡ºæ¯ä¸ªå¾®æ‰¹æ¬¡çš„æ¢¯åº¦</li><li>å°†å¾®æ‰¹æ¬¡çš„æ¢¯åº¦è¿›è¡Œall-reduceæ“ä½œæ±‚å¹³å‡å€¼</li><li>ä¼˜åŒ–å™¨ç”¨å¹³å‡æ¢¯åº¦æ›´æ–°æ¨¡å‹å‚æ•°</li></ul><figure><img src="/blog/assets/026_dp-EXtwUza9.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>æ¶‰åŠåˆ°çš„åˆ†å¸ƒå¼é€šä¿¡ distributed communication</p><ul><li>all-reduceï¼šæ­¤å¤„ç”¨äºå°†ä¸åŒGPUä¸Šè®¡ç®—çš„æ¢¯åº¦æ±‚å¹³å‡å€¼ï¼Œå¹¶æŠŠæ¯ä¸ªGPUä¸Šçš„æ¢¯åº¦éƒ½æ›´æ–°ä¸ºå¹³å‡æ¢¯åº¦ï¼Œä»è€Œè¿›è¡Œæ¢¯åº¦åŒæ­¥</li></ul><p>æ¢¯åº¦è®¡ç®—ä¸æ¢¯åº¦åŒæ­¥</p><ul><li>æ¢¯åº¦è®¡ç®—ï¼ˆGPUè®¡ç®—ï¼‰ï¼šå‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­çš„æ¢¯åº¦è®¡ç®—</li><li>æ¢¯åº¦åŒæ­¥ï¼ˆGPUé€šä¿¡ï¼‰ï¼šè§¦å‘åˆ†å¸ƒå¼é€šä¿¡all-reduceæ“ä½œè¿›è¡Œæ¢¯åº¦åŒæ­¥</li></ul><h3 id="_2-1-æœ´ç´ dp-naive-ddp-approach" tabindex="-1"><a class="header-anchor" href="#_2-1-æœ´ç´ dp-naive-ddp-approach" aria-hidden="true">#</a> 2.1. æœ´ç´ DPï¼ˆnaive DDP approachï¼‰</h3><p>åŸç†ï¼šGPUè®¡ç®—å®Œæˆåè¿›è¡ŒGPUé€šä¿¡ï¼Œå†ç­‰GPUé€šä¿¡å®Œæˆåè¿›è¡ŒGPUè®¡ç®—</p><ul><li>ç­‰å¾…æ¯ä¸ªGPUè®¡ç®—æ¢¯åº¦å®Œæˆåï¼Œè§¦å‘ä¸€æ¬¡åˆ†å¸ƒå¼é€šä¿¡all-reduceæ“ä½œè¿›è¡Œæ¢¯åº¦åŒæ­¥ï¼Œç„¶åç­‰å¾…æ¢¯åº¦åŒæ­¥å®Œæˆåï¼Œä¼˜åŒ–å™¨è¿›è¡Œæ›´æ–°å‚æ•°</li></ul><figure><img src="/blog/assets/026_naive_dp-E_HNnfVP.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>æ”¹è¿›ç©ºé—´ï¼šåœ¨é€šä¿¡è¿›è¡Œæ—¶ï¼ŒGPUå¤„äºç©ºé—²çŠ¶æ€ï¼Œè€Œæˆ‘ä»¬åº”è¯¥å°½é‡è®©é€šä¿¡å’Œè®¡ç®—é‡å ï¼Œå°½å¯èƒ½ä½¿å®ƒä»¬åŒæ—¶è¿›è¡Œ</p><h3 id="_2-2-dpä¼˜åŒ–" tabindex="-1"><a class="header-anchor" href="#_2-2-dpä¼˜åŒ–" aria-hidden="true">#</a> 2.2. DPä¼˜åŒ–</h3><p>å°†æ¢¯åº¦è®¡ç®—çš„åå‘ä¼ æ’­å’Œæ¢¯åº¦åŒæ­¥é‡å </p><ul><li>DPä¼˜åŒ–ä¸€ï¼šå¤šä¸ªGPUä¸Šçš„æŸä¸ªå‚æ•°éƒ½è®¡ç®—å‡ºæ¢¯åº¦äº†ï¼Œå°±å¼€å§‹å¯¹è¿™ä¸ªå‚æ•°çš„æ¢¯åº¦è¿›è¡Œall-reduceæ“ä½œ</li><li>DPä¼˜åŒ–äºŒï¼šå¤šä¸ªGPUä¸Šçš„æŸä¸ªå±‚éƒ½è®¡ç®—å‡ºæ¢¯åº¦äº†ï¼Œå°±å¼€å§‹å¯¹è¿™ä¸ªå±‚çš„æ¢¯åº¦è¿›è¡Œall-reduceæ“ä½œ</li></ul><h4 id="_2-2-1-dpä¼˜åŒ–ä¸€-ä¸ºæ¯ä¸ªå‚æ•°é™„åŠ ä¸€ä¸ªall-reduceçš„é’©å­å‡½æ•°" tabindex="-1"><a class="header-anchor" href="#_2-2-1-dpä¼˜åŒ–ä¸€-ä¸ºæ¯ä¸ªå‚æ•°é™„åŠ ä¸€ä¸ªall-reduceçš„é’©å­å‡½æ•°" aria-hidden="true">#</a> 2.2.1. DPä¼˜åŒ–ä¸€ï¼šä¸ºæ¯ä¸ªå‚æ•°é™„åŠ ä¸€ä¸ªall-reduceçš„é’©å­å‡½æ•°</h4><p>åŸç†ï¼šä¸ç­‰æ‰€æœ‰å±‚çš„åå‘ä¼ æ’­éƒ½è®¡ç®—å®Œæˆäº†æ‰å¼€å§‹æ¢¯åº¦åŒæ­¥ï¼Œè€Œæ˜¯åœ¨è®¡ç®—å‡ºéƒ¨åˆ†å±‚çš„æ¢¯åº¦åï¼Œå°±å¼€å§‹åŒæ­¥è¿™äº›è®¡ç®—å‡ºçš„å±‚çš„æ¢¯åº¦åŒæ­¥ï¼Œä»è€Œæ˜¾è‘—åŠ é€Ÿæ•°æ®å¹¶è¡Œï¼Œå‡å°‘ç­‰å¾…æ•´ä¸ªæ¨¡å‹æ¢¯åº¦åŒæ­¥çš„æ—¶é—´ï¼ˆä¾‹å¦‚:llamaåœ¨è®¡ç®—å‡ºç¬¬32å±‚çš„æ¢¯åº¦å,GPUè¿˜åœ¨è®¡ç®—ç¬¬31å±‚çš„æ¢¯åº¦æ—¶ï¼Œå°±å¼€å§‹åŒæ­¥ç¬¬32å±‚çš„æ¢¯åº¦ï¼‰</p><p>Note: ä¼˜åŒ–ä¸€ç”šè‡³ä¸ç­‰ä¸€ä¸ªè§£ç å±‚çš„æ¢¯åº¦å®Œå…¨è®¡ç®—å®Œæˆæ‰å¼€å§‹æ¢¯åº¦åŒæ­¥ï¼Œè€Œæ˜¯åªè¦æ¯ä¸ªå‚æ•°åœ¨å„ä¸ªGPUä¸Šè®¡ç®—å‡ºæ¢¯åº¦å°±å¼€å§‹åŒæ­¥è¿™ä¸ªå‚æ•°çš„æ¢¯åº¦</p><figure><img src="/blog/assets/026_dp_opt1-c6SNtqfy.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>PyTorchå®ç°ï¼šä¸ºæ¯ä¸ªå‚æ•°é™„åŠ ä¸€ä¸ªall-reduceçš„é’©å­å‡½æ•°ï¼Œä¸€æ—¦æŸä¸ªå‚æ•°çš„æ¢¯åº¦å‡†å¤‡å°±ç»ªï¼Œå°±ä¼šç«‹å³è§¦å‘all-reduceæ“ä½œï¼Œè€Œæ­¤æ—¶å…¶ä»–å‚æ•°çš„æ¢¯åº¦å¯èƒ½ä»åœ¨è®¡ç®—ä¸­</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">register_backward_hook</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> hook<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">&quot;&quot;&quot;
    Registers a backward hook for all parameters of the model that 
    require gradients.
    &quot;&quot;&quot;</span>
    <span class="token keyword">for</span> p <span class="token keyword">in</span> self<span class="token punctuation">.</span>module<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> p<span class="token punctuation">.</span>requires_grad <span class="token keyword">is</span> <span class="token boolean">True</span><span class="token punctuation">:</span>
            p<span class="token punctuation">.</span>register_post_accumulate_grad_hook<span class="token punctuation">(</span>hook<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="_2-2-2-dpä¼˜åŒ–äºŒ-åˆ†æ¡¶-bucketing-gradients" tabindex="-1"><a class="header-anchor" href="#_2-2-2-dpä¼˜åŒ–äºŒ-åˆ†æ¡¶-bucketing-gradients" aria-hidden="true">#</a> 2.2.2. DPä¼˜åŒ–äºŒï¼šåˆ†æ¡¶ Bucketing gradients</h4><p>å‰ç½®ç†è®ºï¼šGPU æ“ä½œåœ¨å¤„ç†å¤§å¼ é‡æ—¶é€šå¸¸æ¯”å¯¹è®¸å¤šå°å¼ é‡æ‰§è¡Œå¤šæ¬¡æ“ä½œæ›´é«˜æ•ˆã€‚è¿™ä¸€ç‚¹å¯¹é€šä¿¡æ“ä½œåŒæ ·é€‚ç”¨ã€‚</p><p>åŸç†ï¼šå°†æ¢¯åº¦åˆ†æ¡¶ï¼ˆä¾‹å¦‚ï¼ŒæŒ‰å±‚åˆ†æ¡¶ï¼Œæ¯ä¸ªè§£ç å±‚ä½œä¸ºä¸€ä¸ªæ•´ä½“ï¼‰ï¼Œå¯¹åŒä¸€æ¡¶çš„æ‰€æœ‰æ¢¯åº¦å¯åŠ¨ä¸€æ¬¡all-reduceæ“ä½œï¼Œè€Œä¸æ˜¯å¯¹æ¯ä¸ªå‚æ•°çš„æ¢¯åº¦å•ç‹¬æ‰§è¡Œall-reduceæ“ä½œã€‚é€šè¿‡å¯¹æ¯ä¸ªæ¡¶æ‰§è¡Œä¸€æ¬¡all-reduceæ“ä½œï¼Œæˆ‘ä»¬å¯ä»¥æ˜¾è‘—å‡å°‘é€šä¿¡å¼€é”€å¹¶åŠ é€Ÿé€šä¿¡è¿‡ç¨‹ã€‚</p><figure><img src="/blog/assets/026_dp_opt2-iYKI8SGn.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h3 id="_2-3-dbå®è·µ" tabindex="-1"><a class="header-anchor" href="#_2-3-dbå®è·µ" aria-hidden="true">#</a> 2.3. DBå®è·µ</h3><p>æœ¯è¯­</p><ul><li>bs: batch size æ‰¹æ¬¡å¤§å°</li><li>mbs: micro batch size å¾®æ‰¹æ¬¡å¤§å°</li><li>gbs: global batch size å…¨å±€æ‰¹æ¬¡å¤§å°</li><li>grad_acc: the number of gradient accumulation step æ¢¯åº¦ç´¯ç§¯æ­¥éª¤æ•° (æŒ‡åœ¨æ²¡æ³•å¹¶è¡Œçš„æƒ…å†µä¸‹ï¼Œåœ¨ä¸€ä¸ªGPUä¸Šè¿ç»­ä¸²è¡Œè®¡ç®—å‡ ä¸ªmbsï¼ŒæŠŠä¸²è¡Œè®¡ç®—çš„è¿™å‡ ä¸ªç´¯ç§¯èµ·æ¥)</li><li>dp: the number of parallel instances used for data parallelism æ•°æ®å¹¶è¡Œçš„å¹¶è¡Œå®ä¾‹æ•°</li><li>gbst: global batch size tokens å…¨å±€æ‰¹æ¬¡å¤§å°Tokenæ•°</li></ul><p>å…¬å¼</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>bs = gbs = mbs * grad_acc * dp
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>gbst = batch_size * sequence_length 
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>æ•°æ®å¹¶è¡Œåˆæ­¥æ–¹æ¡ˆ</p><ul><li>1.ç¡®å®šæœ€ä½³çš„å…¨å±€æ‰¹æ¬¡å¤§å°Tokenæ•° global batch size tokens (gbst) <ul><li>é€šè¿‡æŸ¥é˜…æ–‡çŒ®æˆ–è¿è¡Œå®éªŒï¼ˆæµ‹é‡æ¨¡å‹æ”¶æ•›æ€§ï¼‰æ¥ç¡®å®š</li></ul></li><li>2.é€‰æ‹©è®­ç»ƒçš„åºåˆ—é•¿åº¦ <ul><li>åŒæ ·å¯ä»¥é€šè¿‡æŸ¥é˜…æ–‡çŒ®æˆ–å®éªŒæ¥å†³å®š</li><li>é€šå¸¸ï¼Œ2-8k ä¸ª token å¯¹äºæˆ‘ä»¬ä»Šå¤©çš„è¯„ä¼°æ¥è¯´æ•ˆæœå¯é </li></ul></li><li>3.æ‰¾åˆ°æœ€å¤§æœ¬åœ°æ‰¹æ¬¡å¤§å° micro batch size (mbs) <ul><li>å¯ä»¥é€šè¿‡ä¸æ–­å¢åŠ å• GPU ä¸Šçš„æœ¬åœ°æ‰¹æ¬¡å¤§å°ï¼ˆmbsï¼‰ï¼Œç›´åˆ°å†…å­˜è€—å°½ï¼Œæ¥æ‰¾åˆ°æœ€å¤§æœ¬åœ°æ‰¹æ¬¡å¤§å°</li></ul></li><li>4.ç¡®å®šç›®æ ‡æ•°æ®å¹¶è¡Œï¼ˆDPï¼‰å¯ç”¨çš„GPUæ•°é‡ <ul><li>gbs/dp çš„å€¼å°†å‘Šè¯‰æˆ‘ä»¬ï¼Œä¸ºäº†è¾¾åˆ°æ‰€éœ€çš„ gbsï¼Œè¿˜éœ€è¦å¤šå°‘æ¢¯åº¦ç´¯ç§¯æ­¥éª¤ã€‚</li></ul></li></ul><p>å…·ä½“æ¡ˆä¾‹</p><ul><li>gbstï¼ˆtokenæ•°ï¼‰= 4M tokens</li><li>sequence_length=4K tokens</li><li>bs=1024 samples</li><li>observe assume: a single GPU can only fit mbs=2 in memory (ä¹Ÿå°±æ˜¯å•ä¸ªGPUå•ä½æ—¶é—´åªèƒ½å®¹çº³åºåˆ—é•¿åº¦ä¸º4k tokensçš„2ä¸ªæ ·æœ¬), mbséœ€è¦å°äºç­‰äº2</li><li>we have 128 GPUs available for training</li><li>This means with 4 gradient accumulation steps weâ€™ll achieve our goal of 1024 samples or 4M tokens per training step. <ul><li>grad_acc = bs / (dp * mbs) = 1024 / (128 * 2) = 4</li></ul></li><li>Now what if we suddenly have 512 GPUs available? We can achieve the same GBS and thus identical training by keeping MBS=2 and setting gradient accumulation steps to 1 and achieve faster training! <ul><li>grad_acc = bs / (dp * mbs) = 1024 / (512 * 2) = 1</li></ul></li></ul><h3 id="_2-4-é‡‡ç”¨dpçš„è¡¨ç°" tabindex="-1"><a class="header-anchor" href="#_2-4-é‡‡ç”¨dpçš„è¡¨ç°" aria-hidden="true">#</a> 2.4. é‡‡ç”¨DPçš„è¡¨ç°</h3><figure><img src="/blog/assets/026_throughput_and_memory-SnE7PVSE.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>éšç€æ‰©å……DPå¹¶è¡Œæ•°é‡</p><ul><li>ååé‡(throughput)ä¸‹é™</li><li>å†…å­˜å ç”¨ä¿æŒç¨³å®š</li></ul><p>é‡‡ç”¨è¿™ä¸ªçš„å‰ææ˜¯mbsè‡³å°‘æ˜¯1ï¼Œä¹Ÿå°±æ˜¯ä¸€ä¸ªGPUè‡³å°‘èƒ½æ”¯æŒä¸€ä¸ªè¾“å…¥æ ·æœ¬çš„å‰å‘ä¼ æ’­ï¼Œä½†è¿™ä¸ªä¸æ€»æ˜¯æˆç«‹ï¼Œç”šè‡³é‡‡ç”¨äº†æ¿€æ´»å€¼é‡æ–°è®¡ç®—çš„æƒ…å†µä¸‹</p><figure><img src="/blog/assets/026_memory_usage-pj4jdpOl.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>Tip: å¿«é€Ÿç›®æµ‹æ¨¡å‹å‚æ•°æ‰€éœ€çš„æœ€å°å†…å­˜ï¼šæ¨¡å‹å‚æ•° * 2ï¼ˆe.g. 70B â†’ 140GB (=133GiB)ï¼‰</p><p>å¯¹äºè¶…å¤§çš„æ¨¡å‹æˆ–è¾ƒå¤§çš„æ‰¹æ¬¡tokenæ•°ï¼Œæˆ‘ä»¬è¿˜æœ‰å…¶ä»–å¯é€‰é¡¹å—ï¼Ÿ</p><ul><li>æœ‰ä¸¤ç§ä¸»è¦çš„æ‹†åˆ†æ–¹æ³•ï¼šå¹¶è¡Œæ€§ parallelismï¼ˆå¼ é‡å¹¶è¡Œã€ä¸Šä¸‹æ–‡å¹¶è¡Œæˆ–æµæ°´çº¿å¹¶è¡Œï¼‰å’Œåˆ†ç‰‡ shardingï¼ˆDeepSpeed Zero æˆ– PyTorch FSDPï¼‰ã€‚è¿™ä¸¤ç§æ–¹æ³•åœ¨æŸç§ç¨‹åº¦ä¸Šæ˜¯ç›¸äº’ç‹¬ç«‹çš„ï¼Œå®é™…ä¸Šå¯ä»¥ç»“åˆä½¿ç”¨ï¼</li></ul><h2 id="_3-deepspeed-zero" tabindex="-1"><a class="header-anchor" href="#_3-deepspeed-zero" aria-hidden="true">#</a> 3. DeepSpeed ZeRO</h2><h3 id="_3-1-zero" tabindex="-1"><a class="header-anchor" href="#_3-1-zero" aria-hidden="true">#</a> 3.1. ZeRO</h3><p>DeepSpeed ZeROå®˜æ–¹æ–‡æ¡£ï¼š<a href="https://www.deepspeed.ai/tutorials/zero/" target="_blank" rel="noopener noreferrer">https://www.deepspeed.ai/tutorials/zero/<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><p>ZeRO</p><ul><li>(<strong>Ze</strong>ro <strong>R</strong>edundancy <strong>O</strong>ptimizer)</li><li>ä¸€ç§å†…å­˜ä¼˜åŒ–æŠ€æœ¯ï¼Œæ—¨åœ¨å‡å°‘LLMè®­ç»ƒä¸­çš„å†…å­˜å†—ä½™</li><li>ZeROé€šè¿‡åœ¨<strong>æ•°æ®å¹¶è¡ŒDPç»´åº¦</strong>ä¸Šå°†optimizer states, gradients, and parametersè¿›è¡Œåˆ†ç‰‡æ¥å‡å°‘å†…å­˜å†—ä½™ï¼Œè¿™æœ‰æ—¶éœ€è¦æ›´å¤šGPUé€šä¿¡ï¼Œè¿™äº›é€šä¿¡ä¹Ÿè®¸èƒ½å’ŒGPUè®¡ç®—é‡å ä¹Ÿè®¸ä¸èƒ½</li><li>å½“æˆ‘ä»¬æåˆ°â€œåˆ†åŒºâ€æ—¶ï¼Œæ˜¯æŒ‡æ²¿ç€ DP è½´è¿›è¡Œåˆ†åŒºï¼Œå› ä¸º ZeRO æ˜¯æ•°æ®å¹¶è¡Œçš„ä¸€éƒ¨åˆ†</li></ul><p>ZeROçš„ä¸‰ç§ä¼˜åŒ–ç­–ç•¥</p><ul><li>ZeRO-1: optimizer state partitioning</li><li>ZeRO-2: optimizer state + gradient partitioning</li><li>ZeRO-3 / FSDP (also called FSDP for â€œFully-Sharded Data Parallelismâ€): optimizer state + gradient + parameter partitioning</li></ul><figure><img src="/blog/assets/026_zero-6AWHVtA1.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>Noteï¼šk=12 for Adam ï¼ˆæ··åˆç²¾åº¦è®­ç»ƒæƒ…å†µä¸‹ï¼šå…¨ç²¾åº¦çš„æ¨¡å‹å‚æ•°+å…¨ç²¾åº¦çš„2ä¸ªAdamä¼˜åŒ–å™¨å‚æ•°ï¼‰</p><p>Note: æ¿€æ´»å€¼activationsæ€ä¹ˆä¸è¿›è¡Œåˆ†ç‰‡ï¼Ÿ å› ä¸ºæ¯ä¸ªDPæ¥æ”¶ä¸åŒçš„å¾®æ‰¹æ¬¡micro-batchï¼Œå…¶è®¡ç®—çš„æ¿€æ´»å€¼è‡ªç„¶ä¹Ÿä¸åŒï¼Œå®ƒæœ¬èº«å°±æ²¡æœ‰å†—ä½™ï¼Œæœ¬æ¥å°±ä¸æ˜¯å…±äº«æˆ–é‡å¤çš„æ•°æ®ï¼Œæ‰€ä»¥ä¸éœ€è¦åŒæ­¥ï¼Œä¸éœ€è¦åˆ†ç‰‡ï¼Œå¹¶ä¸”å·²ç»è¢«ç”¨äºè®¡ç®—DP rankå„è‡ªçš„æ¢¯åº¦ï¼Œå®ƒçš„ä¸»è¦ä»»åŠ¡å°±å®Œæˆäº†ï¼Œåé¢å·²ç»ç”¨ä¸åˆ°äº†</p><p>DPä¸åŒç­–ç•¥çš„å†…å­˜å ç”¨ï¼š</p><figure><img src="/blog/assets/026_zero_memory_usage-fGTznOTt.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>ZeROçš„é™åˆ¶ï¼š</p><p>æ•°æ®å¹¶è¡Œï¼ˆDPï¼‰åªæœ‰åœ¨æ¨¡å‹çš„å•å±‚èƒ½å¤Ÿé€‚åº”å•ä¸ª GPU çš„æƒ…å†µä¸‹æ‰èƒ½æ­£å¸¸å·¥ä½œï¼Œè€Œ ZeRO åªèƒ½å¯¹å‚æ•°ã€æ¢¯åº¦å’Œä¼˜åŒ–å™¨çŠ¶æ€è¿›è¡Œåˆ†åŒºï¼Œæ— æ³•å¯¹æ¿€æ´»å€¼å†…å­˜è¿›è¡Œåˆ†åŒºï¼æˆ‘ä»¬ä»ä¹‹å‰çš„æ¿€æ´»å€¼å†…å­˜è®¨è®ºä¸­å›å¿†ï¼Œæ¿€æ´»å€¼å†…å­˜çš„è¿™ä¸€éƒ¨åˆ†ä¼šéšç€åºåˆ—é•¿åº¦å’Œæ‰¹æ¬¡å¤§å°ï¼ˆbatch sizeï¼‰è€Œçº¿æ€§å¢åŠ ã€‚è‡ªç„¶åœ°ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡é™åˆ¶åºåˆ—é•¿åº¦å’Œæ‰¹æ¬¡å¤§å°æ¥åº”å¯¹ï¼Œä½†å®é™…ä¸Šï¼Œæˆ‘ä»¬ä¸å¸Œæœ›å› ç¡¬ä»¶é™åˆ¶è€Œåªèƒ½ä½¿ç”¨è¾ƒçŸ­çš„åºåˆ—é•¿åº¦è¿›è¡Œè®­ç»ƒã€‚</p><h3 id="_3-2-æ··åˆç²¾åº¦è®­ç»ƒå›é¡¾" tabindex="-1"><a class="header-anchor" href="#_3-2-æ··åˆç²¾åº¦è®­ç»ƒå›é¡¾" aria-hidden="true">#</a> 3.2. æ··åˆç²¾åº¦è®­ç»ƒå›é¡¾</h3><p>æ··åˆç²¾åº¦è®­ç»ƒçš„å·²çŸ¥æ–¹æ³•æ±‡æ€»ï¼š</p><figure><img src="/blog/assets/024_mixed_precision_training_list-zWnwhm6Z.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>å‚æ•°é‡ num_parameters : Î¨</p><ul><li>BF16+FP32æ··åˆç²¾åº¦baselineï¼š2Î¨ + 6Î¨ + 12Î¨ = 20Î¨ <ul><li>æ¨¡å‹å‚æ•°ï¼ˆåŠç²¾åº¦ï¼‰ï¼š2 bytes</li><li>æ¢¯åº¦ï¼ˆåŠç²¾åº¦ï¼‰ + FP32çš„æ¢¯åº¦ï¼ˆä»¥FP32çš„ç²¾åº¦è¿›è¡Œæ¢¯åº¦ç´¯ç§¯ï¼‰ï¼š2 + 4 = 6 bytes</li><li>FP32çš„æ¨¡å‹å‚æ•°å’Œä¼˜åŒ–å™¨çŠ¶æ€ï¼š4 + ï¼ˆ4 + 4ï¼‰= 12 bytes</li></ul></li><li>å»æ‰FP32æ¢¯åº¦çš„BF16+FP32æ··åˆç²¾åº¦ï¼š2Î¨ + 2Î¨ + 12Î¨ = 16Î¨ <ul><li>æ¨¡å‹å‚æ•°ï¼ˆåŠç²¾åº¦ï¼‰ï¼š2 bytes</li><li>æ¢¯åº¦ï¼ˆåŠç²¾åº¦ï¼‰ï¼š2 bytes</li><li>FP32çš„æ¨¡å‹å‚æ•°å’Œä¼˜åŒ–å™¨çŠ¶æ€ï¼š4 + ï¼ˆ4 + 4ï¼‰= 12 bytes</li></ul></li></ul><h3 id="_3-3-zero-1" tabindex="-1"><a class="header-anchor" href="#_3-3-zero-1" aria-hidden="true">#</a> 3.3. ZeRO-1</h3><figure><img src="/blog/assets/026_zero1_1-chKLWwve.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><figure><img src="/blog/assets/026_zero1_2-nDtu1GKB.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>å•ä¸ªè®­ç»ƒæ­¥çš„æ‰§è¡Œè¿‡ç¨‹</p><ul><li>å‰å‘ä¼ æ’­ï¼šæ¯ä¸ªå‰¯æœ¬æŒç›¸åŒä¸”å®Œæ•´çš„æ¨¡å‹å‚æ•°ï¼ˆBF16ï¼‰ï¼Œä½†å¤„ç†ä¸åŒçš„å¾®æ‰¹æ¬¡micro_batchï¼ˆå°½ç®¡å‚æ•°ç›¸åŒï¼Œä¹‹åè®¡ç®—å‡ºçš„æ¿€æ´»å€¼å’Œæ¢¯åº¦ä¼šå› å¾®æ‰¹æ¬¡ä¸åŒè€Œä¸åŒï¼‰</li><li>åå‘ä¼ æ’­ï¼šæ¯ä¸ªå‰¯æœ¬è®¡ç®—å‡ºå®Œæ•´çš„æ¢¯åº¦ï¼Œä½†ç”±äºå¾®æ‰¹æ¬¡ä¸åŒï¼Œæ¯ä¸ªå‰¯æœ¬çš„æ¢¯åº¦ä¹Ÿä¸åŒ</li><li>å¯¹æ¢¯åº¦è¿›è¡Œreduce-scatteræ“ä½œï¼šæ¯ä¸ªå‰¯æœ¬åªæŠŠä¼˜åŒ–å™¨çŠ¶æ€åˆ†ç‰‡å¯¹åº”çš„éƒ¨åˆ†æ¢¯åº¦è¿›è¡Œç´¯ç§¯ï¼Œå…¶ä»–éƒ¨åˆ†çš„æ¢¯åº¦ä¿æŒä¸å˜</li><li>æœ¬åœ°ä¼˜åŒ–ï¼šæ¯ä¸ªå‰¯æœ¬åœ¨å…¶æœ¬åœ°ä¼˜åŒ–å™¨çŠ¶æ€ä¸Šæ‰§è¡Œæ›´æ–°å‚æ•°çš„æ­¥éª¤ï¼Œåªæ›´æ–°ä¼˜åŒ–å™¨çŠ¶æ€åˆ†ç‰‡å¯¹åº”çš„éƒ¨åˆ†å‚æ•°ï¼ˆä» FP32 æ ¼å¼æ›´æ–°åè½¬æ¢å› BF16ï¼‰ï¼Œå…¶ä»–å‚æ•°ä¿æŒä¸å˜</li><li>å¯¹å‚æ•°è¿›è¡Œall-gatheræ“ä½œï¼šå°†æ¯ä¸ªå‰¯æœ¬æ›´æ–°çš„å‚æ•°ï¼ˆBF16ï¼‰éƒ¨åˆ†è¿›è¡Œæ”¶é›†ï¼Œä½¿æ¯ä¸ªå‰¯æœ¬éƒ½æœ‰å®Œæ•´çš„æ›´æ–°åçš„å‚æ•°</li></ul><p>å’Œæœ´ç´ DPç›¸æ¯”</p><ul><li>æ¢¯åº¦ç´¯ç§¯ä»æœ´ç´ DPçš„all-reduceæ“ä½œè½¬å˜ä¸ºreduce-scatteræ“ä½œï¼ˆreduce-scatter is 2 times faster than all-reduce! ï¼‰</li><li>åœ¨ä¼˜åŒ–å™¨æ­¥éª¤åæ·»åŠ äº†all-gatheræ“ä½œ</li></ul><p>ZeROçš„è¿›ä¸€æ­¥ä¼˜åŒ–: å°†all-gatherä¸å‰åæ“ä½œé‡å </p><ul><li>all-gatheré‡å ä¼˜åŒ–å™¨æ­¥éª¤ï¼šä¼˜åŒ–å™¨æ›´æ–°éƒ¨åˆ†å‚æ•°åï¼Œå°±å¼€å¯all-gatheræ“ä½œ</li><li>all-gatheré‡å å‰å‘ä¼ æ’­ï¼šall-gatheræ‰§è¡Œå®Œä¸€å±‚çš„å‚æ•°æ”¶é›†ï¼Œå°±å¼€å¯è¿™å±‚çš„å‰å‘ä¼ æ’­</li></ul><h3 id="_3-4-zero-2" tabindex="-1"><a class="header-anchor" href="#_3-4-zero-2" aria-hidden="true">#</a> 3.4. ZeRO-2</h3><figure><img src="/blog/assets/026_zero2_1-ltGxlP93.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><figure><img src="/blog/assets/026_zero2_2-jKSycbBf.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h3 id="_3-5-zero-3" tabindex="-1"><a class="header-anchor" href="#_3-5-zero-3" aria-hidden="true">#</a> 3.5. ZeRO-3</h3><p>ZeRO-3åœ¨PyTorchçš„å®ç°ä¸­å«FSDP(Fully Shared Data Parallelism)</p><figure><img src="/blog/assets/026_zero3_1-Cnk6_7Bf.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><figure><img src="/blog/assets/026_zero3_2-P1IgyB-r.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><figure><img src="/blog/assets/026_zero3_3-kj-z2o8V.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>åªæœ‰åœ¨æ¨¡å‹å‚æ•°ç”¨åˆ°çš„æ—¶å€™æŒ‰éœ€æ”¶é›†å®ƒä»¬</p><ul><li>æ¯ä¸€å±‚å‰å‘ä¼ æ’­ä¹‹å‰é‡‡ç”¨all-gatheræ“ä½œæ”¶é›†æ‰€æœ‰å‚æ•°ï¼Œæ¯ä¸€å±‚å‰å‘ä¼ æ’­ä¹‹åï¼Œå°†ä¸éœ€è¦çš„å‚æ•°ä»å†…å­˜ä¸­åˆ·æ‰ï¼ˆä»ç¬¬1å±‚åˆ°ç¬¬32å±‚è¿›è¡Œ32æ¬¡ï¼‰</li><li>æ¯ä¸€å±‚åå‘ä¼ æ’­ä¹‹å‰é‡‡ç”¨all-gatheræ“ä½œæ”¶é›†æ‰€æœ‰å‚æ•°ï¼Œæ¯ä¸€å±‚åå‘ä¼ æ’­è®¡ç®—å‡ºæ¢¯åº¦ä¹‹åï¼Œå°†ä¸éœ€è¦çš„å‚æ•°ä»å†…å­˜ä¸­åˆ·æ‰ï¼ˆä»ç¬¬32å±‚åˆ°ç¬¬1å±‚è¿›è¡Œ32æ¬¡ï¼‰</li><li>ä¼˜åŒ–ï¼šç¬¬32å±‚çš„å‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­åˆåœ¨ä¸€èµ·ï¼Œåœ¨ç¬¬32å±‚å‰å‘ä¼ æ’­ä¹‹å‰é‡‡ç”¨all-gatheræ“ä½œæ”¶é›†æ‰€æœ‰å‚æ•°ï¼Œåœ¨ç¬¬32å±‚åå‘ä¼ æ’­è®¡ç®—å‡ºæ¢¯åº¦ä¹‹åï¼Œå°†ä¸éœ€è¦çš„å‚æ•°ä»å†…å­˜ä¸­åˆ·æ‰</li><li>æ‰€ä»¥æ‰§è¡Œall-gatheræ“ä½œå’Œå°†ä¸éœ€è¦çš„å‚æ•°ä»å†…å­˜åˆ·æ‰çš„æ“ä½œæ€»å…±æ‰§è¡Œ num_layers + num_layers - 1 = 32 + 32 - 1 = 63 æ¬¡ï¼Œå¦‚ç¬¬3ä¸ªå›¾æ‰€ç¤ºæœ‰ä¸€ç‚¹å»¶è¿Ÿå¼€é”€</li><li>ZeRO-3é‡åº¦ä¾èµ–å‚æ•°é€šä¿¡</li></ul><h2 id="_4-æ‰©å±•é“¾æ¥" tabindex="-1"><a class="header-anchor" href="#_4-æ‰©å±•é“¾æ¥" aria-hidden="true">#</a> 4. æ‰©å±•é“¾æ¥</h2><p><a href="https://siboehm.com/articles/22/data-parallel-training" target="_blank" rel="noopener noreferrer">https://siboehm.com/articles/22/data-parallel-training<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><p><a href="https://www.harmdevries.com/post/context-length/" target="_blank" rel="noopener noreferrer">https://www.harmdevries.com/post/context-length/<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><h2 id="_5-ä»£ç å®ç°" tabindex="-1"><a class="header-anchor" href="#_5-ä»£ç å®ç°" aria-hidden="true">#</a> 5. ä»£ç å®ç°</h2><h3 id="_5-1-naive-dp-implementation-with-overlap-in-picotron" tabindex="-1"><a class="header-anchor" href="#_5-1-naive-dp-implementation-with-overlap-in-picotron" aria-hidden="true">#</a> 5.1. Naive DP implementation with overlap in Picotron</h3><p>å®Œæˆä»£ç </p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">DataParallelNaive</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">&quot;&quot;&quot;
    Naive Data Parallelism. Not used in practice. But it is a good starting point to understand how data parallelism works.
    It implements a simple all-reduce operation to synchronize gradients across multiple processes.
    And `no_sync` context manager to disable gradient synchronization.
    &quot;&quot;&quot;</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> module<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">&quot;&quot;&quot;
        Initializes the DataParallel wrapper for a given module.

        Args:
            module (nn.Module): The model to be wrapped for data parallelism.
            process_group (torch.distributed.ProcessGroup): The process group used for gradient synchronization. 
                                                            It could be a data parallel or context parallel group.
        &quot;&quot;&quot;</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>module <span class="token operator">=</span> module
        self<span class="token punctuation">.</span>require_backward_grad_sync <span class="token operator">=</span> <span class="token boolean">True</span> <span class="token comment"># whether to synchronize gradients during backward pass. Set to False when using gradient accumulation</span>
        self<span class="token punctuation">.</span>register_backward_hook<span class="token punctuation">(</span>self<span class="token punctuation">.</span>_allreduce_grads<span class="token punctuation">)</span>
    
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token operator">*</span>inputs<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>module<span class="token punctuation">(</span><span class="token operator">*</span>inputs<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>
    
    <span class="token keyword">def</span> <span class="token function">register_backward_hook</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> hook<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">&quot;&quot;&quot;
        Registers a backward hook for all parameters of the model that require gradients.    
        &quot;&quot;&quot;</span>
        <span class="token keyword">for</span> p <span class="token keyword">in</span> self<span class="token punctuation">.</span>module<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">if</span> p<span class="token punctuation">.</span>requires_grad <span class="token keyword">is</span> <span class="token boolean">True</span><span class="token punctuation">:</span>
                p<span class="token punctuation">.</span>register_hook<span class="token punctuation">(</span>hook<span class="token punctuation">)</span>
                
    <span class="token keyword">def</span> <span class="token function">_allreduce_grads</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> grad<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">&quot;&quot;&quot;
        Performs an all-reduce operation to synchronize gradients across multiple processes.    
        &quot;&quot;&quot;</span>
        <span class="token comment"># No synchronization needed during gradient accumulation, except at the final accumulation step.</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>require_backward_grad_sync<span class="token punctuation">:</span>
            dist<span class="token punctuation">.</span>all_reduce<span class="token punctuation">(</span>grad<span class="token punctuation">,</span> op<span class="token operator">=</span>dist<span class="token punctuation">.</span>ReduceOp<span class="token punctuation">.</span>SUM<span class="token punctuation">,</span> group<span class="token operator">=</span>pgm<span class="token punctuation">.</span>process_group_manager<span class="token punctuation">.</span>cp_dp_group<span class="token punctuation">)</span>
            grad <span class="token operator">/=</span> pgm<span class="token punctuation">.</span>process_group_manager<span class="token punctuation">.</span>cp_dp_world_size
        <span class="token keyword">return</span> grad 
    
    <span class="token decorator annotation punctuation">@contextlib<span class="token punctuation">.</span>contextmanager</span>
    <span class="token keyword">def</span> <span class="token function">no_sync</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">&quot;&quot;&quot;
        A context manager to temporarily disable gradient synchronization. 
        This is useful for performing multiple backward passes during gradient accumulation without synchronizing 
        gradients in between.
        &quot;&quot;&quot;</span>
        self<span class="token punctuation">.</span>require_backward_grad_sync <span class="token operator">=</span> <span class="token boolean">False</span>
        <span class="token keyword">yield</span>
        self<span class="token punctuation">.</span>require_backward_grad_sync <span class="token operator">=</span> <span class="token boolean">True</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_5-2-bucket-dp-implementation-in-picotron" tabindex="-1"><a class="header-anchor" href="#_5-2-bucket-dp-implementation-in-picotron" aria-hidden="true">#</a> 5.2. Bucket DP implementation in Picotron</h3><p>å®Œæ•´ä»£ç </p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">DataParallelBucket</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">&quot;&quot;&quot;
    Data Parallelism with gradient grouped into buckets to reduce the communication overhead.
    &quot;&quot;&quot;</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> module<span class="token punctuation">,</span> bucket_cap_mb<span class="token operator">=</span><span class="token number">25</span><span class="token punctuation">,</span> grad_type <span class="token operator">=</span> torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">&quot;&quot;&quot;
        Initialize the DataParallelBucket module.
        
        Args:
            module (nn.Module): The model to be parallelized.
            process_group: The process group for gradient synchronization, which can be either 
                           a data parallel group or a context parallel group.
            bucket_cap_mb (int, optional): The maximum size of each gradient synchronization bucket in megabytes. 
                                           Defaults to 25 MB.
            grad_type (torch.dtype, optional): The data type of gradients, defaulting to float32.
        &quot;&quot;&quot;</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>module <span class="token operator">=</span> module
        self<span class="token punctuation">.</span>require_backward_grad_sync <span class="token operator">=</span> <span class="token boolean">True</span> <span class="token comment"># whether to synchronize gradients during backward pass. Set to False when using gradient accumulation</span>
        grad_size <span class="token operator">=</span> <span class="token number">2</span> <span class="token keyword">if</span> grad_type <span class="token operator">==</span> torch<span class="token punctuation">.</span>bfloat16 <span class="token keyword">else</span> <span class="token number">4</span> <span class="token comment"># float32 gradient: 4 bytes</span>
        bucket_size <span class="token operator">=</span> bucket_cap_mb <span class="token operator">*</span> <span class="token number">1024</span> <span class="token operator">*</span> <span class="token number">1024</span> <span class="token operator">//</span> grad_size <span class="token comment"># number of gradients in one bucket</span>
        self<span class="token punctuation">.</span>bucket_manager <span class="token operator">=</span> BucketManager<span class="token punctuation">(</span>module<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> pgm<span class="token punctuation">.</span>process_group_manager<span class="token punctuation">.</span>cp_dp_group<span class="token punctuation">,</span> bucket_size<span class="token punctuation">,</span> grad_type<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>register_backward_hook<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>_post_backward_callback_set <span class="token operator">=</span> <span class="token boolean">False</span> <span class="token comment"># whether the callback for wait gradient synchronization is set</span>
        
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token operator">*</span>inputs<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>module<span class="token punctuation">(</span><span class="token operator">*</span>inputs<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">backward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_tensor<span class="token punctuation">,</span> output_tensor<span class="token punctuation">,</span> output_tensor_grad<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>module<span class="token punctuation">.</span>backward<span class="token punctuation">(</span>input_tensor<span class="token punctuation">,</span> output_tensor<span class="token punctuation">,</span> output_tensor_grad<span class="token punctuation">)</span>
    
    <span class="token keyword">def</span> <span class="token function">register_backward_hook</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">&quot;&quot;&quot;
        Registers a backward hook to manually accumulate and synchronize gradients.
        
        This hook serves two main purposes:
        1. PyTorch does not natively support gradient accumulation with mixed precision.
        2. After gradient accumulation, it flags parameters as ready for synchronization.
        
        The gradient accumulation functions are stored to prevent them from going out of scope.
        
        References:
        - https://github.com/NVIDIA/Megatron-LM/issues/690
        - https://pytorch.org/docs/stable/generated/torch.autograd.graph.Node.register_hook.html
        - https://arxiv.org/abs/2006.15704 (page 5)
        &quot;&quot;&quot;</span>
        self<span class="token punctuation">.</span>grad_accs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> param <span class="token keyword">in</span> self<span class="token punctuation">.</span>module<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">if</span> param<span class="token punctuation">.</span>requires_grad<span class="token punctuation">:</span>
                <span class="token comment"># Expand so we get access to grad_fn.</span>
                param_tmp <span class="token operator">=</span> param<span class="token punctuation">.</span>expand_as<span class="token punctuation">(</span>param<span class="token punctuation">)</span>
                <span class="token comment"># Get the gradient accumulator function.</span>
                grad_acc_fn <span class="token operator">=</span> param_tmp<span class="token punctuation">.</span>grad_fn<span class="token punctuation">.</span>next_functions<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
                grad_acc_fn<span class="token punctuation">.</span>register_hook<span class="token punctuation">(</span>self<span class="token punctuation">.</span>_make_param_hook<span class="token punctuation">(</span>param<span class="token punctuation">,</span> self<span class="token punctuation">.</span>bucket_manager<span class="token punctuation">)</span><span class="token punctuation">)</span>
                self<span class="token punctuation">.</span>grad_accs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>grad_acc_fn<span class="token punctuation">)</span>
                
    <span class="token keyword">def</span> <span class="token function">_make_param_hook</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> param<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">,</span>bucket_manager<span class="token punctuation">:</span> BucketManager<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">&quot;&quot;&quot;
        Creates the a hook for each parameter to handle gradient accumulation and synchronization.
        &quot;&quot;&quot;</span>
        <span class="token keyword">def</span> <span class="token function">param_hook</span><span class="token punctuation">(</span><span class="token operator">*</span>unused<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token triple-quoted-string string">&quot;&quot;&quot;
            The hook called after the gradient is ready. It performs the following:
            1. Accumulates the gradient into the main gradient.
            2. Adds a post-backward callback to wait for gradient synchronization completion.
            3. Marks the parameter as ready for synchronization.
            &quot;&quot;&quot;</span>
            <span class="token keyword">if</span> param<span class="token punctuation">.</span>requires_grad<span class="token punctuation">:</span>
                <span class="token keyword">assert</span> param<span class="token punctuation">.</span>grad <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span>
                param<span class="token punctuation">.</span>main_grad<span class="token punctuation">.</span>add_<span class="token punctuation">(</span>param<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>data<span class="token punctuation">)</span> <span class="token comment"># accumulate the gradients</span>
                param<span class="token punctuation">.</span>grad <span class="token operator">=</span> <span class="token boolean">None</span>
                
                <span class="token comment"># skip the gradient synchronization (gradient accumulation/PP micro batches)</span>
                <span class="token keyword">if</span> self<span class="token punctuation">.</span>require_backward_grad_sync<span class="token punctuation">:</span>
                    <span class="token comment"># Add a callback to wait for gradient synchronization. Ensures the callback is added only once.</span>
                    <span class="token comment"># Callback is executed after the backward pass. It should be added per backward pass.</span>
                    <span class="token keyword">if</span> <span class="token keyword">not</span> self<span class="token punctuation">.</span>_post_backward_callback_set<span class="token punctuation">:</span>
                        Variable<span class="token punctuation">.</span>_execution_engine<span class="token punctuation">.</span>queue_callback<span class="token punctuation">(</span>self<span class="token punctuation">.</span>_post_backward<span class="token punctuation">)</span>
                        self<span class="token punctuation">.</span>_post_backward_callback_set <span class="token operator">=</span> <span class="token boolean">True</span>
                        
                    <span class="token comment"># mark the parameter as ready for gradient synchronization. </span>
                    bucket_manager<span class="token punctuation">.</span>mark_param_as_ready<span class="token punctuation">(</span>param<span class="token punctuation">)</span> 
        <span class="token keyword">return</span> param_hook
    
    <span class="token decorator annotation punctuation">@contextlib<span class="token punctuation">.</span>contextmanager</span>
    <span class="token keyword">def</span> <span class="token function">no_sync</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">&quot;&quot;&quot;A context manager to disable gradient synchronization.&quot;&quot;&quot;</span>
        self<span class="token punctuation">.</span>require_backward_grad_sync <span class="token operator">=</span> <span class="token boolean">False</span>
        <span class="token keyword">yield</span>
        self<span class="token punctuation">.</span>require_backward_grad_sync <span class="token operator">=</span> <span class="token boolean">True</span>
        
    <span class="token keyword">def</span> <span class="token function">_post_backward</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">&quot;&quot;&quot;
        A post-backward callback that waits for gradient synchronization to finish, then copies 
        the synchronized gradients back to the parameters&#39; grad attribute.
        
        This method is called after the backward pass and before the optimizer step.
        &quot;&quot;&quot;</span>
        self<span class="token punctuation">.</span>bucket_manager<span class="token punctuation">.</span>wait<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>_post_backward_callback_set <span class="token operator">=</span> <span class="token boolean">False</span>
        <span class="token comment"># copy to params.grad so we can use the optimizer to update the parameters</span>
        <span class="token keyword">for</span> p <span class="token keyword">in</span> self<span class="token punctuation">.</span>module<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">if</span> p<span class="token punctuation">.</span>requires_grad<span class="token punctuation">:</span>
                p<span class="token punctuation">.</span>grad <span class="token operator">=</span> p<span class="token punctuation">.</span>main_grad<span class="token punctuation">.</span>to<span class="token punctuation">(</span>p<span class="token punctuation">.</span>dtype<span class="token punctuation">)</span> <span class="token comment"># In PyTorch, you cannot assign a gradient with one data type to a tensor of another data type.</span>

    <span class="token keyword">def</span> <span class="token function">reset</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">&quot;&quot;&quot;
        Reset the bucket manager and zero out gradients in the model
        &quot;&quot;&quot;</span>
        self<span class="token punctuation">.</span>bucket_manager<span class="token punctuation">.</span>reset<span class="token punctuation">(</span><span class="token punctuation">)</span> 
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></div><!--[--><!----><!--]--><footer class="page-meta"><!----><div class="meta-item git-info"><!----><!----></div></footer><nav class="vp-page-nav"><a aria-label="åˆ†å¸ƒå¼è®­ç»ƒä¹‹å››ï¼šå¹¶è¡Œç­–ç•¥" class="vp-link nav-link prev nav-link prev" href="/blog/zh/posts/llm/027_distribution_and_parallelism_3.html"><div class="hint"><span class="arrow start"></span>ä¸Šä¸€é¡µ</div><div class="link"><span class="font-icon icon fa-fw fa-sm fas fa-lightbulb" style=""></span>åˆ†å¸ƒå¼è®­ç»ƒä¹‹å››ï¼šå¹¶è¡Œç­–ç•¥</div></a><a aria-label="åˆ†å¸ƒå¼è®­ç»ƒä¹‹äºŒï¼šå¹¶è¡Œç¼–ç¨‹ Parallel Programming" class="vp-link nav-link next nav-link next" href="/blog/zh/posts/llm/025_distribution_and_parallelism_1.html"><div class="hint">ä¸‹ä¸€é¡µ<span class="arrow end"></span></div><div class="link">åˆ†å¸ƒå¼è®­ç»ƒä¹‹äºŒï¼šå¹¶è¡Œç¼–ç¨‹ Parallel Programming<span class="font-icon icon fa-fw fa-sm fas fa-lightbulb" style=""></span></div></a></nav><!----><!--[--><!----><!--]--><!--]--></main><!--]--><!----></div><!--]--><!--]--><!----><!--]--></div>
    <script type="module" src="/blog/assets/app-v5bcDFbF.js" defer></script>
  </body>
</html>
