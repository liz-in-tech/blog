<!doctype html>
<html lang="zh-CN" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.0" />
    <meta name="theme" content="VuePress Theme Hope 2.0.0-rc.13" />
    <style>
      html {
        background: var(--bg-color, #fff);
      }

      html[data-theme="dark"] {
        background: var(--bg-color, #1d1e1f);
      }

      body {
        background: var(--bg-color);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <link rel="alternate" hreflang="en-us" href="https://liz-in-tech.github.io/blog/posts/llm/024_distribution_and_parallelism.html"><meta property="og:url" content="https://liz-in-tech.github.io/blog/zh/posts/llm/024_distribution_and_parallelism.html"><meta property="og:site_name" content="Liz"><meta property="og:title" content="分布式训练之一：模型训练的内存占用"><meta property="og:description" content="分布式训练之一：模型训练的内存占用"><meta property="og:type" content="article"><meta property="og:locale" content="zh-CN"><meta property="og:locale:alternate" content="en-US"><meta property="og:updated_time" content="2025-03-08T14:32:06.000Z"><meta property="article:author" content="Liz"><meta property="article:tag" content="分布式"><meta property="article:tag" content="并行"><meta property="article:published_time" content="2025-02-26T00:00:00.000Z"><meta property="article:modified_time" content="2025-03-08T14:32:06.000Z"><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"分布式训练之一：模型训练的内存占用","image":[""],"datePublished":"2025-02-26T00:00:00.000Z","dateModified":"2025-03-08T14:32:06.000Z","author":[{"@type":"Person","name":"Liz","url":"https://github.com/liz-in-tech"}]}</script><link rel="icon" herf="/blogger.png"><link rel="icon" href="/blog/blogger.png"><title>分布式训练之一：模型训练的内存占用 | Liz</title><meta name="description" content="分布式训练之一：模型训练的内存占用">
    <link rel="preload" href="/blog/assets/style-m_obra2h.css" as="style"><link rel="stylesheet" href="/blog/assets/style-m_obra2h.css">
    <link rel="modulepreload" href="/blog/assets/app-QwHuhOwl.js"><link rel="modulepreload" href="/blog/assets/024_distribution_and_parallelism.html-gAVkG0oI.js"><link rel="modulepreload" href="/blog/assets/024_scaling_experiments1-sDd0n9MZ.js"><link rel="modulepreload" href="/blog/assets/024_mixed_precision_training_list-dG4PWcKt.js"><link rel="modulepreload" href="/blog/assets/plugin-vue_export-helper-x3n3nnut.js"><link rel="modulepreload" href="/blog/assets/024_distribution_and_parallelism.html-MO4kg9bC.js">
    <link rel="prefetch" href="/blog/assets/index.html-YbPtte5_.js" as="script"><link rel="prefetch" href="/blog/assets/intro.html-CGfhr1vY.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-FUMOuem4.js" as="script"><link rel="prefetch" href="/blog/assets/index.html--TTjrkIy.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-g4Nfr7z1.js" as="script"><link rel="prefetch" href="/blog/assets/intro.html-bitGHKd2.js" as="script"><link rel="prefetch" href="/blog/assets/001_langchain.html-nrisQopy.js" as="script"><link rel="prefetch" href="/blog/assets/002_langchain_sourcecode.html-9XtwFAwc.js" as="script"><link rel="prefetch" href="/blog/assets/003_streamlit.html-oji9upQP.js" as="script"><link rel="prefetch" href="/blog/assets/004_transformer.html-xrin91s2.js" as="script"><link rel="prefetch" href="/blog/assets/005_llama.html-zssRppb4.js" as="script"><link rel="prefetch" href="/blog/assets/006_llm_leaderboard.html-c628DmZb.js" as="script"><link rel="prefetch" href="/blog/assets/007_computer_use.html-4RcS3hxb.js" as="script"><link rel="prefetch" href="/blog/assets/008_rag_challenge.html-_8stdYVV.js" as="script"><link rel="prefetch" href="/blog/assets/009_llm_challenge.html-eluz3bTT.js" as="script"><link rel="prefetch" href="/blog/assets/010_rag_workflow.html-Ft0RQWf3.js" as="script"><link rel="prefetch" href="/blog/assets/011_vector_database.html-htZNHy9b.js" as="script"><link rel="prefetch" href="/blog/assets/012_prompt_engineering.html-Q27DlfZz.js" as="script"><link rel="prefetch" href="/blog/assets/013_optimizing_llm.html-6CxOIR84.js" as="script"><link rel="prefetch" href="/blog/assets/014_rag_evaluation.html-GIu-oGwK.js" as="script"><link rel="prefetch" href="/blog/assets/015_fine_tune.html-48naV3Ea.js" as="script"><link rel="prefetch" href="/blog/assets/016_multimodal.html-xa8M4Wu4.js" as="script"><link rel="prefetch" href="/blog/assets/017_agent_and_multiagent.html-dm178NRn.js" as="script"><link rel="prefetch" href="/blog/assets/018_huggingface.html-WI0c55vB.js" as="script"><link rel="prefetch" href="/blog/assets/019_ollama.html-kLkdC4dl.js" as="script"><link rel="prefetch" href="/blog/assets/020_neo4j.html-P-Llr3CJ.js" as="script"><link rel="prefetch" href="/blog/assets/021_microsoft_graphrag.html-0d0frUhq.js" as="script"><link rel="prefetch" href="/blog/assets/022_llamaindex_graphrag.html-RhkTd_Zr.js" as="script"><link rel="prefetch" href="/blog/assets/023_agent_framework.html-5MCDM_Sd.js" as="script"><link rel="prefetch" href="/blog/assets/024_distribution_and_parallelism.html-uCefT9T7.js" as="script"><link rel="prefetch" href="/blog/assets/025_distribution_and_parallelism_1.html-32IzAErP.js" as="script"><link rel="prefetch" href="/blog/assets/026_distribution_and_parallelism_2.html-MEZ1JY2b.js" as="script"><link rel="prefetch" href="/blog/assets/027_distribution_and_parallelism_3.html-IYByZhbZ.js" as="script"><link rel="prefetch" href="/blog/assets/028_distribution_and_parallelism_4.html-Kub1JEXd.js" as="script"><link rel="prefetch" href="/blog/assets/029_unsloth_grpo.html-T25XLAW-.js" as="script"><link rel="prefetch" href="/blog/assets/030_wandb.html-61V6KLeo.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ZDCSnlc1.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ZYw6WxxA.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-OavE9BET.js" as="script"><link rel="prefetch" href="/blog/assets/001_langchain.html-hE_T0u_5.js" as="script"><link rel="prefetch" href="/blog/assets/002_langchain_sourcecode.html-iH0mq6XB.js" as="script"><link rel="prefetch" href="/blog/assets/003_streamlit.html-WyFhRqF6.js" as="script"><link rel="prefetch" href="/blog/assets/004_transformer.html-wy9Toayl.js" as="script"><link rel="prefetch" href="/blog/assets/005_llama.html-6PFDsh_d.js" as="script"><link rel="prefetch" href="/blog/assets/006_llm_leaderboard.html-WHPR-17-.js" as="script"><link rel="prefetch" href="/blog/assets/007_computer_use.html-hz6Q-DAA.js" as="script"><link rel="prefetch" href="/blog/assets/008_rag_challenge.html-3KMCwhrh.js" as="script"><link rel="prefetch" href="/blog/assets/009_llm_challenge.html-7gxKMp_3.js" as="script"><link rel="prefetch" href="/blog/assets/010_rag_workflow.html-KndRvZAj.js" as="script"><link rel="prefetch" href="/blog/assets/011_vector_database.html-DtFi92ig.js" as="script"><link rel="prefetch" href="/blog/assets/012_prompt_engineering.html-ZdCqy2Fu.js" as="script"><link rel="prefetch" href="/blog/assets/013_optimizing_llm.html-W-CdR_ck.js" as="script"><link rel="prefetch" href="/blog/assets/014_rag_evaluation.html-mimwqA-t.js" as="script"><link rel="prefetch" href="/blog/assets/015_fine_tune.html-egR6ajJ8.js" as="script"><link rel="prefetch" href="/blog/assets/016_multimodal.html-hiqs-a6X.js" as="script"><link rel="prefetch" href="/blog/assets/017_agent_and_multiagent.html-bS1SRdf4.js" as="script"><link rel="prefetch" href="/blog/assets/018_huggingface.html-Si3T7PB7.js" as="script"><link rel="prefetch" href="/blog/assets/019_ollama.html-V5tcXCC4.js" as="script"><link rel="prefetch" href="/blog/assets/020_neo4j.html-ytaIU5xV.js" as="script"><link rel="prefetch" href="/blog/assets/021_microsoft_graphrag.html-kvlLpO3f.js" as="script"><link rel="prefetch" href="/blog/assets/022_llamaindex_graphrag.html-nS8_ZZy5.js" as="script"><link rel="prefetch" href="/blog/assets/023_agent_framework.html-VZsN2kO8.js" as="script"><link rel="prefetch" href="/blog/assets/025_distribution_and_parallelism_1.html-ZR9kuXUl.js" as="script"><link rel="prefetch" href="/blog/assets/026_distribution_and_parallelism_2.html-GkjDPoeT.js" as="script"><link rel="prefetch" href="/blog/assets/027_distribution_and_parallelism_3.html-5kFJGreK.js" as="script"><link rel="prefetch" href="/blog/assets/028_distribution_and_parallelism_4.html-38Gbieji.js" as="script"><link rel="prefetch" href="/blog/assets/029_unsloth_grpo.html-sutxVW-j.js" as="script"><link rel="prefetch" href="/blog/assets/030_wandb.html-VCoqJJSk.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-wh_dBtOR.js" as="script"><link rel="prefetch" href="/blog/assets/404.html-cxLWDy2T.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-kf4JCRaf.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-RkA-insV.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-4kI_oqSd.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-WhuidxNt.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-OqGkeUA_.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-5GeN-sdD.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-c4Rf4yh1.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-2r0jUs7o.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-BSKRXRQc.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-KjTsJ0Hg.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-TteIwMx3.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-g00XXzrL.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-YxbJgo4L.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-3T79Cy0i.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-A5tlQHan.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-04ff5e0O.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-vgZ6rfFh.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-OmipPplE.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-E1KrJL6a.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-oPH9QkTj.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-cHRqZSs8.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-74SU9ZTn.js" as="script"><link rel="prefetch" href="/blog/assets/index.html--iJiA8oX.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-oZPWb_Fc.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-FUIWSLsp.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-5ERWyusD.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Zjn0JNqd.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-jcvPTrgB.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-9t2TsyuQ.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-CcLVFNIv.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-DVoYOOaL.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-V52ipvRm.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-9If_KW0o.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-df9Mrf2R.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-f9bWoKcO.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-GYH0QUoo.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-JVTfeijx.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-_C1QVNqX.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-L_IXFmna.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-nZWHmXY7.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-x4gPgqE4.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-bWnVyuyA.js" as="script"><link rel="prefetch" href="/blog/assets/index.html--yTU23ka.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-tRnpyzfw.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-7aypos-L.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-1BXcbV1R.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-pu478WKz.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-LHukpLS7.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-howjHe2f.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-DeN_iOWx.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-cnlzR0a7.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-0P_c_pcU.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-dy_CcFmq.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-FzFytZ_p.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-2KSwV7xp.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-F1coElwg.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ffflqCb9.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-F8ZuLYgH.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-HeYWaFeL.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-xKYeJEc5.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-xB-iS7Ql.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-OEUPqfTV.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-EE4iQI9m.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-g1PUF_BG.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-nUBcs85a.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-9Y3la5Sf.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-wufIFDPM.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-bXZQIxRE.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-wd6ZkEHi.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Xlk0AXmC.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Uv7c7pYa.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-FfZqC9tZ.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-mSPhZxqB.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-51HoKD5A.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Q5_K6Vux.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-jkWPo860.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-kTEqch5G.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-y4iBqBqc.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ibHhI9SI.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-3hk_s27_.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-QJ9j3Zl2.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-QvWFHL99.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Pefl6i_g.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-DmPXMi3I.js" as="script"><link rel="prefetch" href="/blog/assets/intro.html-rCTPxMxT.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-GI0Urq_4.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-QRSKjfFC.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-L0ASVFc_.js" as="script"><link rel="prefetch" href="/blog/assets/intro.html-hZa3DGKI.js" as="script"><link rel="prefetch" href="/blog/assets/001_langchain.html-YI7MuWf1.js" as="script"><link rel="prefetch" href="/blog/assets/002_langchain_sourcecode.html-wyZu9Tmo.js" as="script"><link rel="prefetch" href="/blog/assets/003_streamlit.html-fKx1Mm0J.js" as="script"><link rel="prefetch" href="/blog/assets/004_transformer.html-Rtd0KqAk.js" as="script"><link rel="prefetch" href="/blog/assets/005_llama.html-qrZg-V3Q.js" as="script"><link rel="prefetch" href="/blog/assets/006_llm_leaderboard.html-yk8aMAJ7.js" as="script"><link rel="prefetch" href="/blog/assets/007_computer_use.html-atR2rdyD.js" as="script"><link rel="prefetch" href="/blog/assets/008_rag_challenge.html-n90PzKJP.js" as="script"><link rel="prefetch" href="/blog/assets/009_llm_challenge.html-kchm4UOZ.js" as="script"><link rel="prefetch" href="/blog/assets/010_rag_workflow.html-q_7ymOCn.js" as="script"><link rel="prefetch" href="/blog/assets/011_vector_database.html-90DjUlSf.js" as="script"><link rel="prefetch" href="/blog/assets/012_prompt_engineering.html-rw1udcvZ.js" as="script"><link rel="prefetch" href="/blog/assets/013_optimizing_llm.html-j7nlo-va.js" as="script"><link rel="prefetch" href="/blog/assets/014_rag_evaluation.html-lVwqVAtJ.js" as="script"><link rel="prefetch" href="/blog/assets/015_fine_tune.html-H-ibfrQZ.js" as="script"><link rel="prefetch" href="/blog/assets/016_multimodal.html-CVDXpTPG.js" as="script"><link rel="prefetch" href="/blog/assets/017_agent_and_multiagent.html-dAZ6UuaQ.js" as="script"><link rel="prefetch" href="/blog/assets/018_huggingface.html-ZjrzYgv1.js" as="script"><link rel="prefetch" href="/blog/assets/019_ollama.html-0qDHD7oN.js" as="script"><link rel="prefetch" href="/blog/assets/020_neo4j.html-Eph2ZO8R.js" as="script"><link rel="prefetch" href="/blog/assets/021_microsoft_graphrag.html-ZM4vOQVt.js" as="script"><link rel="prefetch" href="/blog/assets/022_llamaindex_graphrag.html-YMry8RdT.js" as="script"><link rel="prefetch" href="/blog/assets/023_agent_framework.html-l5jnXifo.js" as="script"><link rel="prefetch" href="/blog/assets/024_distribution_and_parallelism.html-_V5Hk2e1.js" as="script"><link rel="prefetch" href="/blog/assets/025_distribution_and_parallelism_1.html-bH3sOZtf.js" as="script"><link rel="prefetch" href="/blog/assets/026_distribution_and_parallelism_2.html-oJNpAdYY.js" as="script"><link rel="prefetch" href="/blog/assets/027_distribution_and_parallelism_3.html-cZFBE7OB.js" as="script"><link rel="prefetch" href="/blog/assets/028_distribution_and_parallelism_4.html-Pil4d0-I.js" as="script"><link rel="prefetch" href="/blog/assets/029_unsloth_grpo.html-zNn5Zf9x.js" as="script"><link rel="prefetch" href="/blog/assets/030_wandb.html--0NgaMlI.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-sdMW06pT.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-_fcGozYW.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-QthModks.js" as="script"><link rel="prefetch" href="/blog/assets/001_langchain.html-2FQSkroM.js" as="script"><link rel="prefetch" href="/blog/assets/002_langchain_sourcecode.html-ysl8y9iT.js" as="script"><link rel="prefetch" href="/blog/assets/003_streamlit.html-fjRj8SMQ.js" as="script"><link rel="prefetch" href="/blog/assets/004_transformer.html-gX63hxJe.js" as="script"><link rel="prefetch" href="/blog/assets/005_llama.html-Uu_inU0J.js" as="script"><link rel="prefetch" href="/blog/assets/006_llm_leaderboard.html-wF5prtVt.js" as="script"><link rel="prefetch" href="/blog/assets/007_computer_use.html-Q_ImSuge.js" as="script"><link rel="prefetch" href="/blog/assets/008_rag_challenge.html-q09ZNBI_.js" as="script"><link rel="prefetch" href="/blog/assets/009_llm_challenge.html-8PLnVMdr.js" as="script"><link rel="prefetch" href="/blog/assets/010_rag_workflow.html-8Z3a1bP7.js" as="script"><link rel="prefetch" href="/blog/assets/011_vector_database.html-txWlRXf6.js" as="script"><link rel="prefetch" href="/blog/assets/012_prompt_engineering.html-AUNNAHot.js" as="script"><link rel="prefetch" href="/blog/assets/013_optimizing_llm.html-FbTPgQw5.js" as="script"><link rel="prefetch" href="/blog/assets/014_rag_evaluation.html-__ml780e.js" as="script"><link rel="prefetch" href="/blog/assets/015_fine_tune.html-iaFlb3Zh.js" as="script"><link rel="prefetch" href="/blog/assets/016_multimodal.html-kLdp0btB.js" as="script"><link rel="prefetch" href="/blog/assets/017_agent_and_multiagent.html-j5nncf3K.js" as="script"><link rel="prefetch" href="/blog/assets/018_huggingface.html-0vy8fGhG.js" as="script"><link rel="prefetch" href="/blog/assets/019_ollama.html-bx0pTkmd.js" as="script"><link rel="prefetch" href="/blog/assets/020_neo4j.html-pnlOlWWy.js" as="script"><link rel="prefetch" href="/blog/assets/021_microsoft_graphrag.html-8_Y09Ryr.js" as="script"><link rel="prefetch" href="/blog/assets/022_llamaindex_graphrag.html-2nL-H166.js" as="script"><link rel="prefetch" href="/blog/assets/023_agent_framework.html-sxvk_-Pm.js" as="script"><link rel="prefetch" href="/blog/assets/025_distribution_and_parallelism_1.html-RQvp4pCr.js" as="script"><link rel="prefetch" href="/blog/assets/026_distribution_and_parallelism_2.html-MRS5wRwB.js" as="script"><link rel="prefetch" href="/blog/assets/027_distribution_and_parallelism_3.html-27LKwwQM.js" as="script"><link rel="prefetch" href="/blog/assets/028_distribution_and_parallelism_4.html-vvc7e0gC.js" as="script"><link rel="prefetch" href="/blog/assets/029_unsloth_grpo.html-LJLrkVzu.js" as="script"><link rel="prefetch" href="/blog/assets/030_wandb.html-IdRHUvg8.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-9HxNBzzv.js" as="script"><link rel="prefetch" href="/blog/assets/404.html-cKIhE0f9.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ZUpMGtCK.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-dUirw8rF.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-lFz4Jzm4.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-nzbiv3-G.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-R8-PWKr8.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-SfuLco_q.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-TnXQHZ5x.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-eS9ccxOO.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-5w6FbXC1.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-m0yxYD3h.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-RYnLEyn3.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-0d2qIU-C.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-N1hKdz3H.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-eBx63u35.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-NJEOztns.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-_xJsDqIZ.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-SfwJevq2.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-m42tZR8j.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-XuBqOjET.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-7frzHF5a.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-dJB0U1SG.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-4wCAbaUx.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-GVTRvVd5.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-nUjpsH9q.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-MRicmxdr.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-EqT-nCy9.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-PYu5dZ8o.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-3mT8Go0e.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Zou205tl.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-q4gLiKIz.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ylUZHwO8.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-da30LueP.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-cj1hyiqj.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Rrr4HDrt.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-iGPJQ_JY.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-CaFVT96A.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-p4N4vCUh.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-83oHZya5.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ZfD5Flbs.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-_VBd4l4D.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ovhCDQzo.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-3ml2IFUB.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-FkDaxg7z.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-qlR7uBPg.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-twZN1hxo.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-J_OYVIk_.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-6Lym8tPm.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-8tseqTpO.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-QZk3ThtJ.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-HB3HNPEr.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-AbDCD6zj.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-mqQCju1t.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-NKOAsFvB.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-u1Jhrd1b.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-zhEofi9a.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-5cQGjhI1.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-OOQ0fcfD.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-GB10Swpw.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ch-yzqwK.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-di9Ixbyo.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-P3d_3P8i.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-bwxjqjib.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-9yHFuqVb.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-59S1nWmQ.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-sEZXBovo.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-tN41OFvw.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-DoiPUF-f.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-YvX5Sqvd.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-kbzwc3iJ.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-GH01Y3Ya.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-X8Ed29yu.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-JBAKlIzp.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-i_-fWoFN.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-5vV6j6we.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-KiHCnbex.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-QhLLPRn9.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-65CO348n.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Q0YuwFHX.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Af2-ZVvx.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-vhp1XWf8.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-I1SRwoae.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-uTg1Vebk.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-qlXkh-Rg.js" as="script"><link rel="prefetch" href="/blog/assets/photoswipe.esm-08_zHRDQ.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">跳至主要內容</a><!--]--><!--[--><div class="theme-container no-sidebar has-toc"><!--[--><header id="navbar" class="vp-navbar"><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!--[--><!----><!--]--><!--[--><a class="vp-link vp-brand vp-brand" href="/blog/zh/"><img class="vp-nav-logo" src="/blog/blogger.png" alt><!----><span class="vp-site-name hide-in-pad">Liz</span></a><!--]--><!--[--><!----><!--]--></div><div class="vp-navbar-center"><!--[--><!----><!--]--><!--[--><nav class="vp-nav-links"><div class="nav-item hide-in-mobile"><a aria-label="首页" class="vp-link nav-link nav-link" href="/blog/zh/"><span class="font-icon icon fa-fw fa-sm fas fa-home" style=""></span>首页<!----></a></div><div class="nav-item hide-in-mobile"><a aria-label="项目" class="vp-link nav-link nav-link" href="/blog/zh/demo/"><span class="font-icon icon fa-fw fa-sm fas fa-star" style=""></span>项目<!----></a></div></nav><!--]--><!--[--><!----><!--]--></div><div class="vp-navbar-end"><!--[--><!----><!--]--><!--[--><div class="nav-item"><div class="dropdown-wrapper i18n-dropdown"><button type="button" class="dropdown-title" aria-label="选择语言"><!--[--><svg xmlns="http://www.w3.org/2000/svg" class="icon i18n-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="i18n icon" style="width:1rem;height:1rem;vertical-align:middle;"><path d="M379.392 460.8 494.08 575.488l-42.496 102.4L307.2 532.48 138.24 701.44l-71.68-72.704L234.496 460.8l-45.056-45.056c-27.136-27.136-51.2-66.56-66.56-108.544h112.64c7.68 14.336 16.896 27.136 26.112 35.84l45.568 46.08 45.056-45.056C382.976 312.32 409.6 247.808 409.6 204.8H0V102.4h256V0h102.4v102.4h256v102.4H512c0 70.144-37.888 161.28-87.04 210.944L378.88 460.8zM576 870.4 512 1024H409.6l256-614.4H768l256 614.4H921.6l-64-153.6H576zM618.496 768h196.608L716.8 532.48 618.496 768z"></path></svg><!--]--><span class="arrow"></span><ul class="nav-dropdown"><li class="dropdown-item"><a aria-label="English" class="vp-link nav-link nav-link" href="/blog/posts/llm/024_distribution_and_parallelism.html"><!---->English<!----></a></li><li class="dropdown-item"><a aria-label="简体中文" class="vp-link nav-link active nav-link active" href="/blog/zh/posts/llm/024_distribution_and_parallelism.html"><!---->简体中文<!----></a></li></ul></button></div></div><div class="nav-item vp-repo"><a class="vp-repo-link" href="https://github.com/liz-in-tech" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><div class="nav-item hide-in-mobile"><button type="button" id="appearance-switch"><svg xmlns="http://www.w3.org/2000/svg" class="icon auto-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="auto icon" style="display:block;"><path d="M512 992C246.92 992 32 777.08 32 512S246.92 32 512 32s480 214.92 480 480-214.92 480-480 480zm0-840c-198.78 0-360 161.22-360 360 0 198.84 161.22 360 360 360s360-161.16 360-360c0-198.78-161.22-360-360-360zm0 660V212c165.72 0 300 134.34 300 300 0 165.72-134.28 300-300 300z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon dark-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="dark icon" style="display:none;"><path d="M524.8 938.667h-4.267a439.893 439.893 0 0 1-313.173-134.4 446.293 446.293 0 0 1-11.093-597.334A432.213 432.213 0 0 1 366.933 90.027a42.667 42.667 0 0 1 45.227 9.386 42.667 42.667 0 0 1 10.24 42.667 358.4 358.4 0 0 0 82.773 375.893 361.387 361.387 0 0 0 376.747 82.774 42.667 42.667 0 0 1 54.187 55.04 433.493 433.493 0 0 1-99.84 154.88 438.613 438.613 0 0 1-311.467 128z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon light-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="light icon" style="display:none;"><path d="M952 552h-80a40 40 0 0 1 0-80h80a40 40 0 0 1 0 80zM801.88 280.08a41 41 0 0 1-57.96-57.96l57.96-58a41.04 41.04 0 0 1 58 58l-58 57.96zM512 752a240 240 0 1 1 0-480 240 240 0 0 1 0 480zm0-560a40 40 0 0 1-40-40V72a40 40 0 0 1 80 0v80a40 40 0 0 1-40 40zm-289.88 88.08-58-57.96a41.04 41.04 0 0 1 58-58l57.96 58a41 41 0 0 1-57.96 57.96zM192 512a40 40 0 0 1-40 40H72a40 40 0 0 1 0-80h80a40 40 0 0 1 40 40zm30.12 231.92a41 41 0 0 1 57.96 57.96l-57.96 58a41.04 41.04 0 0 1-58-58l58-57.96zM512 832a40 40 0 0 1 40 40v80a40 40 0 0 1-80 0v-80a40 40 0 0 1 40-40zm289.88-88.08 58 57.96a41.04 41.04 0 0 1-58 58l-57.96-58a41 41 0 0 1 57.96-57.96z"></path></svg></button></div><form class="search-box" role="search"><input type="search" placeholder="搜索" autocomplete="off" spellcheck="false" value><!----></form><!--]--><!--[--><!----><!--]--><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar"><!--[--><!----><!--]--><ul class="vp-sidebar-links"></ul><!--[--><!----><!--]--></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!--[--><!----><!--]--><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><span class="font-icon icon fa-fw fa-sm fas fa-lightbulb" style=""></span>分布式训练之一：模型训练的内存占用</h1><div class="page-info"><span class="page-author-info" aria-label="作者🖊" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><a class="page-author-item" href="https://github.com/liz-in-tech" target="_blank" rel="noopener noreferrer">Liz</a></span><span property="author" content="Liz"></span></span><!----><span class="page-date-info" aria-label="写作日期📅" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span><!----></span><meta property="datePublished" content="2025-02-26T00:00:00.000Z"></span><!----><span class="page-reading-time-info" aria-label="阅读时间⌛" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>大约 16 分钟</span><meta property="timeRequired" content="PT16M"></span><span class="page-category-info" aria-label="分类🌈" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon category-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="category icon"><path d="M148.41 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H148.41c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.311-40.31zM147.556 553.478H429.73c22.263 0 40.311 18.048 40.311 40.31v282.176c0 22.263-18.048 40.312-40.31 40.312H147.555c-22.263 0-40.311-18.049-40.311-40.312V593.79c0-22.263 18.048-40.311 40.31-40.311zM593.927 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H593.927c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.31-40.31zM730.22 920.502H623.926c-40.925 0-74.22-33.388-74.22-74.425V623.992c0-41.038 33.387-74.424 74.425-74.424h222.085c41.038 0 74.424 33.226 74.424 74.067v114.233c0 10.244-8.304 18.548-18.547 18.548s-18.548-8.304-18.548-18.548V623.635c0-20.388-16.746-36.974-37.33-36.974H624.13c-20.585 0-37.331 16.747-37.331 37.33v222.086c0 20.585 16.654 37.331 37.126 37.331H730.22c10.243 0 18.547 8.304 18.547 18.547 0 10.244-8.304 18.547-18.547 18.547z"></path></svg><!--[--><span class="page-category-item category6 clickable" role="navigation">LLM</span><!--]--><meta property="articleSection" content="LLM"></span><span class="page-tag-info" aria-label="标签🏷" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon tag-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="tag icon"><path d="M939.902 458.563L910.17 144.567c-1.507-16.272-14.465-29.13-30.737-30.737L565.438 84.098h-.402c-3.215 0-5.726 1.005-7.634 2.913l-470.39 470.39a10.004 10.004 0 000 14.164l365.423 365.424c1.909 1.908 4.42 2.913 7.132 2.913s5.223-1.005 7.132-2.913l470.39-470.39c2.01-2.11 3.014-5.023 2.813-8.036zm-240.067-72.121c-35.458 0-64.286-28.828-64.286-64.286s28.828-64.285 64.286-64.285 64.286 28.828 64.286 64.285-28.829 64.286-64.286 64.286z"></path></svg><!--[--><span class="page-tag-item tag4 clickable" role="navigation">分布式</span><span class="page-tag-item tag3 clickable" role="navigation">并行</span><!--]--><meta property="keywords" content="分布式,并行"></span></div><hr></div><div class="toc-place-holder"><aside id="toc"><!--[--><!----><!--]--><div class="toc-header">此页内容<button type="button" class="print-button" title="打印"><svg xmlns="http://www.w3.org/2000/svg" class="icon print-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="print icon"><path d="M819.2 364.8h-44.8V128c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v236.8h-44.8C145.067 364.8 96 413.867 96 473.6v192c0 59.733 49.067 108.8 108.8 108.8h44.8V896c0 17.067 14.933 32 32 32h460.8c17.067 0 32-14.933 32-32V774.4h44.8c59.733 0 108.8-49.067 108.8-108.8v-192c0-59.733-49.067-108.8-108.8-108.8zM313.6 160h396.8v204.8H313.6V160zm396.8 704H313.6V620.8h396.8V864zM864 665.6c0 25.6-19.2 44.8-44.8 44.8h-44.8V588.8c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v121.6h-44.8c-25.6 0-44.8-19.2-44.8-44.8v-192c0-25.6 19.2-44.8 44.8-44.8h614.4c25.6 0 44.8 19.2 44.8 44.8v192z"></path></svg></button></div><div class="toc-wrapper"><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_1-指标">1. 指标</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_2-三大关键挑战-three-key-challenges">2. 三大关键挑战 three key challenges</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_3-模型训练基础">3. 模型训练基础</a></li><li><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_3-1-模型训练过程">3.1. 模型训练过程</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_3-2-重要超参数-批大小">3.2. 重要超参数 -- 批大小</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_4-模型训练的内存使用">4. 模型训练的内存使用</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_5-混合精度训练-mixed-precision-training">5. 混合精度训练 Mixed Precision Training</a></li><li><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_5-1-浮点数的数值范围与精度">5.1. 浮点数的数值范围与精度</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_5-2-混合精度训练理念">5.2. 混合精度训练理念</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_5-3-混合精度训练的已知方法汇总">5.3. 混合精度训练的已知方法汇总</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_5-4-fp16和bf16训练">5.4. FP16和BF16训练</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_5-5-fp8训练">5.5. FP8训练</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_6-激活值重新计算-activation-recomputation-gradient-checkpointing-rematerialization">6. 激活值重新计算 Activation Recomputation / Gradient Checkpointing / rematerialization</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_7-梯度累积-gradient-accumulation">7. 梯度累积 Gradient Accumulation</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_8-小工具">8. 小工具</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_8-1-计算内存使用量工具-predict-memory">8.1. 计算内存使用量工具：Predict Memory</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_8-2-可视化gpu计算和通信成本的分布式训练工具-profiler">8.2. 可视化GPU计算和通信成本的分布式训练工具：Profiler</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_9-参考资料-ultrascale-playbook">9. 参考资料：ultrascale-playbook</a></li><li><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_9-1-概览">9.1. 概览</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_9-2-前置基础知识">9.2. 前置基础知识</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_9-3-scaling-experiments">9.3. scaling experiments</a></li><!----><!--]--></ul></li><!--]--></ul><div class="toc-marker" style="top:-1.7rem;"></div></div><!--[--><!----><!--]--></aside></div><!--[--><!----><!--]--><div class="theme-hope-content"><h1 id="分布式训练之一-模型训练的内存占用" tabindex="-1"><a class="header-anchor" href="#分布式训练之一-模型训练的内存占用" aria-hidden="true">#</a> 分布式训练之一：模型训练的内存占用</h1><!-- more --><h2 id="_1-指标" tabindex="-1"><a class="header-anchor" href="#_1-指标" aria-hidden="true">#</a> 1. 指标</h2><p>目标： 充分利用GPU这个昂贵的硬件</p><ul><li>吞吐量 throughput</li><li>GPU利用率 GPU utilization</li><li>训练时间 training time</li></ul><h2 id="_2-三大关键挑战-three-key-challenges" tabindex="-1"><a class="header-anchor" href="#_2-三大关键挑战-three-key-challenges" aria-hidden="true">#</a> 2. 三大关键挑战 three key challenges</h2><ul><li>内存使用量 Memory Usage / Memory <ul><li>硬限制</li><li>it&#39;s a hard limitation - if a training step doesn&#39;t fit in memory, training cannot proceed</li><li>OOM（out-of-memory）内存溢出问题</li></ul></li><li>计算效率 Compute Efficiency / Computation <ul><li>硬件花费更多时间在计算上而不是数据传输或等待其他GPU执行任务上</li><li>we want our hardware to spend most time computing, so we need to reduce time spent on data transfers or waiting for other GPUs to perform work.</li></ul></li><li>通信开销 Communication overhead / Communication <ul><li>充分使用节点内带宽（快速）和节点间带宽（较慢）</li><li>尽可能多的与计算重叠通信</li><li>we want to minimize communication overhead as it keeps GPUs idle. To archieve this we will try to make best use of intra-node (fast) and inter-node (slower) bandwidths as well as overlap communication with compute as much as possible.</li></ul></li></ul><h2 id="_3-模型训练基础" tabindex="-1"><a class="header-anchor" href="#_3-模型训练基础" aria-hidden="true">#</a> 3. 模型训练基础</h2><h3 id="_3-1-模型训练过程" tabindex="-1"><a class="header-anchor" href="#_3-1-模型训练过程" aria-hidden="true">#</a> 3.1. 模型训练过程</h3><p>模型训练由3个步骤组成</p><ul><li>前向传播：inputs传给model输出outputs</li><li>反向传播：计算梯度gradients</li><li>优化步骤：优化器使用梯度gradients更新模型参数model parameters</li></ul><figure><img src="/blog/assets/024_model_train_process-h1blFZuC.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h3 id="_3-2-重要超参数-批大小" tabindex="-1"><a class="header-anchor" href="#_3-2-重要超参数-批大小" aria-hidden="true">#</a> 3.2. 重要超参数 -- 批大小</h3><h4 id="_3-2-1-批大小-batch-size-bs" tabindex="-1"><a class="header-anchor" href="#_3-2-1-批大小-batch-size-bs" aria-hidden="true">#</a> 3.2.1. 批大小 Batch Size (bs)</h4><p>同时影响模型的收敛性(convergence)和吞吐量(throughput)</p><p>在训练初期，小批量大小可能很有用，因为它可以快速沿着训练场景移动，达到最佳学习点。但是，在模型训练的后期，小批量大小会使梯度保持嘈杂，模型可能无法收敛到最佳的最终性能。在另一个极端，大批量大小虽然可以提供非常准确的梯度估计，但往往会减少每个训练标记的使用，从而导致收敛速度变慢，并可能浪费计算。</p><p>A small batch size can be useful early in training to quickly move along the training landscape reaching an optimal learning point. However, further along the model training, small batch sizes will keep gradients noisy and the model may not be able to converge to the most optimal final performances. At the other extreme, a large batch size while giving very accurate gradient estimations will tend to make less use of each training token rendering convergence slower and potentially wasting compute.</p><p>批次大小还会影响在给定文本数据集上进行训练所需的时间：较小的批次大小将需要更多的优化器步骤来对相同数量的样本进行训练。优化器步骤成本高昂（在计算时间方面），因此与使用较大的批次大小相比，总训练时间将会增加。话虽如此，请注意，批次大小通常可以在最佳批次大小附近进行相当大的调整，而不会对模型的性能产生重大影响，即最终模型性能对确切批次大小值的敏感度通常在最佳批次大小附近相当低。</p><p>Batch size also affects the time it takes to train on a given text dataset: a small batch size will require more optimizer steps to train on the same amount of samples. Optimizer steps are costly (in compute time) and the total time to train will thus increase compared to using a larger batch size. This being said, note that the batch size can often be adjusted quite largely around the optimal batch size without major impact to the performance of the model, i.e. the sensitivity of final model performances to the exact batch size value is usually rather low around the optimal batch size.</p><p>batch size 扩展链接：</p><ul><li>OpenAI论文：https://arxiv.org/pdf/1812.06162</li><li>MiniMax-01论文：https://filecdn.minimax.chat/_Arxiv_MiniMax_01_Report.pdf</li></ul><h4 id="_3-2-2-批大小token数-batch-size-tokens-bst" tabindex="-1"><a class="header-anchor" href="#_3-2-2-批大小token数-batch-size-tokens-bst" aria-hidden="true">#</a> 3.2.2. 批大小token数 Batch Size Tokens (bst)</h4><p>在LLM预训练领域，通常以词元tokens而非样本数量samples来报告批次大小（bst = Batch Size Tokens）。 这样做使得训练数据量在总体上与训练期间使用的具体输入序列长度无关。</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>bst=bs∗seq
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>其中seq为模型输入序列长度</p><ul><li>理想批大小： 4-60 million token</li><li>Llama 1：对于 1.4 trillions tokens，批大小约 4 million tokens</li><li>Deepseek：对于 14 trillion tokens，批大小约 60 million tokens</li></ul><p>A sweet spot for recent LLM training is typically on the order of 4-60 million tokens per batch. The batch size as well as the training corpus have been steadily increasing over the years: Llama 1 was trained with a batch size of ~4M tokens for 1.4 trillions tokens while DeepSeek was trained with a batch size of ~60M tokens for 14 trillion tokens.</p><h2 id="_4-模型训练的内存使用" tabindex="-1"><a class="header-anchor" href="#_4-模型训练的内存使用" aria-hidden="true">#</a> 4. 模型训练的内存使用</h2><p>4项</p><ul><li>模型参数 Model Parameters (weights &amp; Biases) <ul><li>作用：决定了模型的表现，训练模型就是更新这些参数</li><li>内存占用：由参数量决定，每个参数是一个浮点数，具体取决于使用的精度</li><li>变化情况：训练期间固定不变</li></ul></li><li>优化器状态 Optimizer States <ul><li>作用：用于辅助参数更新来最小化损失函数</li><li>内存占用：不同的优化器会占用不同大小的内存，许多优化器（如Adam、RMSprop等）会存储每个参数的额外状态（如动量、平方梯度等）。例如，Adam优化器会为每个参数存储两个额外的变量：一是动量（momentum），二是梯度平方的平均值（variance）。这意味着每个参数都会占用额外的内存，通常是其参数内存占用的两倍。</li><li>变化情况：训练期间固定不变</li></ul></li><li>激活值 Activations <ul><li>作用：前向传播时各层的输出为激活值，用于反向传播时计算梯度</li><li>内存占用：与批次大小、序列长度、模型结构相关。通常较大，尤其是在深层网络或大批次训练时。</li><li>变化情况：在每一次前向传播后，激活值会被存储并在反向传播中使用，随批次大小和输入数据变化，训练期间动态变化</li></ul></li><li>梯度 Gradients <ul><li>作用：反向传播，计算参数更新的方向和幅度，用于更新参数</li><li>内存占用：在反向传播过程中，需要为每个参数存储一个相同维度的梯度矩阵（每个参数对应一个梯度），占用内存总量与模型参数大小相同</li><li>变化情况：训练期间动态变化，反向传播时计算并存储，更新参数后释放</li></ul></li></ul><p>上述4项以张量tensors的形式存储，有不同的形状shapes和精度precisions</p><p>决定形状shapes的超参数</p><ul><li>batch size</li><li>sequence length</li><li>model hidden dimensions</li><li>attention heads</li><li>vocabulary size</li><li>model sharding</li></ul><p>常见精度precisions</p><ul><li>FP32 (full precision) -&gt; 4 bytes</li><li>BF16 -&gt; 2 bytes</li><li>FP8 -&gt; 1 byte</li></ul><p>训练过程中，内存的使用量是持续变化的而不是静止不变的</p><ul><li>初始化 <ul><li>初始化模型参数（神经网络模型通常会随机初始化权重，有些方法（如Xavier初始化、He初始化）能帮助避免梯度消失或梯度爆炸问题）</li></ul></li><li>循环迭代 <ul><li>前向传播 <ul><li>计算模型输出，存储激活值hidden_state</li></ul></li><li>计算损失 <ul><li>计算损失值（损失值通常是一个标量，内存占用较小）</li></ul></li><li>反向传播 <ul><li>计算并存储梯度</li></ul></li><li>参数更新 <ul><li>优化器会根据梯度更新模型参数，并维护优化器状态</li></ul></li></ul></li></ul><figure><img src="/blog/assets/024_memory_profile-l_mjFy4T.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>内存优化建议</p><ul><li>激活值重新计算: 减少激活值的内存占用，仅存储部分激活值，在需要时重新计算，以减少内存占用</li><li>梯度累积：将多个小批量的梯度累积起来，再进行一次参数更新，可以减少内存占用</li><li>混合精度训练（Mixed Precision Training）: 减少参数和梯度的内存占用，使用半精度浮点数（float16）代替单精度浮点数（float32）可以减少内存占用</li><li>分布式训练: 分摊内存压力，将模型或数据分布在多个GPU上，以减少单个GPU的内存占用</li><li>减小批量大小：减小批量大小会减少内存占用，但可能会影响训练速度</li><li>减少模型大小：使用更小的模型或模型压缩技术</li></ul><p>扩展链接： https://zdevito.github.io/2022/08/04/cuda-caching-allocator.html</p><h2 id="_5-混合精度训练-mixed-precision-training" tabindex="-1"><a class="header-anchor" href="#_5-混合精度训练-mixed-precision-training" aria-hidden="true">#</a> 5. 混合精度训练 Mixed Precision Training</h2><h3 id="_5-1-浮点数的数值范围与精度" tabindex="-1"><a class="header-anchor" href="#_5-1-浮点数的数值范围与精度" aria-hidden="true">#</a> 5.1. 浮点数的数值范围与精度</h3><p>PyTorch张量的默认数值精度：单精度浮点格式，也称为 FP32 或 float32</p><ul><li>这意味着存储的每个数字占用 32 位（即 4 字节）</li></ul><p>可用位数被分为三个部分来表示一个数字（科学计数法表示）：</p><ul><li>符号位（Sign）：第一位决定数字是正数还是负数</li><li>指数（Exponent）：控制数字的大小范围</li><li>尾数（Mantissa）：决定数字的有效数字</li></ul><figure><img src="/blog/assets/024_float_point-6dd9mggT.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>PyTorch提供的浮点格式列表：</p><ul><li>FP32 / float32 / 32-bit Floating Point</li><li>FP16 / float16 / 16-bit Floating Point</li><li>BF16 / bfloat16 / 16-bit Brain Floating Point</li><li>FP8 / float8 / 8-bit Floating Point</li></ul><figure><img src="/blog/assets/024_float_point_list-16OE-Y0d.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>Note</p><ul><li>bfloat16是由Google Brain提出的，其中的b表示“brain”</li><li>两种float8根据指数和尾数命名（e4m3和e5m2）</li></ul><p>我们关注浮点数的2个方面：精度和数值范围</p><ul><li>精度 precision：能表示数字的细腻程度（即两个相邻可表示数字之间的差距）</li><li>数值范围 range： 能表示的最大值和最小值</li></ul><p>不同浮点数的数值范围：</p><figure><img src="/blog/assets/024_float_point_list-16OE-Y0d.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>从图中可看出（看宽度，越宽数值范围越大）：</p><ul><li>float32和bfloat16的数值范围一样且比较大</li><li>float16和float8_e5m2的数值范围一样，数值范围就比较小了</li><li>float8_e4m3有最小的数值范围</li></ul><p>不同浮点数的精度： <img src="/blog/assets/024_float_point_precision-Ddm83ksq.png" alt="" loading="lazy"></p><p>从图中可看出（看竖线的间距，间距越小精度越大）：</p><ul><li>bfloat16的精度比float32和float16低</li></ul><h3 id="_5-2-混合精度训练理念" tabindex="-1"><a class="header-anchor" href="#_5-2-混合精度训练理念" aria-hidden="true">#</a> 5.2. 混合精度训练理念</h3><p>混合精度训练的理念是利用较低精度的格式来减少计算和内存需求，同时尽量保持与全精度（float32）训练的性能。</p><p>但是，完全放弃 float32 是不现实的，因为某些关键部分需要更高的精度来避免数值不稳定性。因此，实际应用中通常会混合使用高精度和低精度格式，这种方法被称为“混合精度训练”。</p><h3 id="_5-3-混合精度训练的已知方法汇总" tabindex="-1"><a class="header-anchor" href="#_5-3-混合精度训练的已知方法汇总" aria-hidden="true">#</a> 5.3. 混合精度训练的已知方法汇总</h3><figure><img src="/blog/assets/024_mixed_precision_training_list-zWnwhm6Z.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>参数量 num_parameters : Ψ</p><ul><li>BF16+FP32混合精度baseline：2Ψ + 6Ψ + 12Ψ = 20Ψ <ul><li>模型参数（半精度）：2 bytes</li><li>梯度（半精度） + FP32的梯度（以FP32的精度进行梯度累积）：2 + 4 = 6 bytes</li><li>FP32的模型参数和优化器状态：4 + （4 + 4）= 12 bytes</li></ul></li><li>去掉FP32梯度的BF16+FP32混合精度：2Ψ + 2Ψ + 12Ψ = 16Ψ <ul><li>模型参数（半精度）：2 bytes</li><li>梯度（半精度）：2 bytes</li><li>FP32的模型参数和优化器状态：4 + （4 + 4）= 12 bytes</li></ul></li></ul><h3 id="_5-4-fp16和bf16训练" tabindex="-1"><a class="header-anchor" href="#_5-4-fp16和bf16训练" aria-hidden="true">#</a> 5.4. FP16和BF16训练</h3><p>简单地将所有张量和操作切换到 float16 格式通常是行不通的，结果往往是loss值发散。然而，最初的混合精度训练论文提出了三种技巧来保持 float32 训练的性能：</p><ul><li>FP32 权重副本 (FP32 copy of weights)： <ul><li>使用 float16 权重可能会遇到两个问题。在训练过程中，某些权重可能会变得非常小，被四舍五入为 0。然而，即使权重本身不接近 0，如果更新量非常小，量级差异可能导致权重在加法操作中下溢（underflow）。一旦权重变为 0，它们在后续训练中将一直保持为 0，因为此时不再有梯度信号传递过来。</li></ul></li><li>Loss 缩放（Loss Scaling）： <ul><li>梯度也会面临类似的问题，因为梯度往往远小于 1，容易发生下溢。一个简单但有效的策略是在反向传播前对损失进行缩放（放大），然后在反向传播后再对梯度进行反向缩放（缩小）。这确保了反向传播过程中不会发生下溢，同时缩放操作不会影响训练，因为我们在进一步处理梯度（例如裁剪）以及优化步骤之前已经进行了反向缩放。</li></ul></li><li>累积（Accumulation）： <ul><li>在 16 位精度下执行某些算术操作（例如求平均或求和）时，也可能会遇到下溢或上溢（overflow）的问题。解决方法是在操作过程中使用 float32 精度来累积中间结果，仅在最后将结果转换回 16 位精度。</li></ul></li></ul><p>三种技巧的核心目标是既利用低精度带来的计算加速，又通过引入高精度（如 float32）的部分操作来确保训练的稳定性，避免数值不稳定问题（如梯度或权重下溢）。通过这些技术，我们可以在保持训练稳定性的同时，受益于更快的低精度算术操作，从而获得更高的吞吐量。</p><h3 id="_5-5-fp8训练" tabindex="-1"><a class="header-anchor" href="#_5-5-fp8训练" aria-hidden="true">#</a> 5.5. FP8训练</h3><ul><li>FP8 精度和数值范围都非常有限，容易导致数值不稳定和Loss发散，尤其是在高学习率场景下。</li><li>FP8 的主要优势在于它能显著提升计算效率（例如在 NVIDIA H100 GPU 上，FP8 的矩阵乘法性能是 bfloat16 的两倍），这对追求高吞吐量和低能耗的训练非常有吸引力。</li></ul><figure><img src="/blog/assets/024_divergent_loss-nJoB-ECp.png" alt="Loss 发散" tabindex="0" loading="lazy"><figcaption>Loss 发散</figcaption></figure><h4 id="_5-5-1-deepseek-v3的fp8混合精度训练" tabindex="-1"><a class="header-anchor" href="#_5-5-1-deepseek-v3的fp8混合精度训练" aria-hidden="true">#</a> 5.5.1. DeepSeek-V3的FP8混合精度训练</h4><ul><li>首次成功的、非常大规模的FP8混合精度训练在 DeepSeek-V3 上被公开报道。</li><li>作者仔细分析了前向传播（Fprop）的每个操作，以及反向传播中的激活值（Dgrad）和权重（Wgrad）操作。</li><li>为了解决 FP8 低精度带来的数值不稳定性，他们采用了与 BF16 混合精度训练类似的策略：将关键部分（如聚合操作和主权重）保持在较高精度（可能是 float32 或 bfloat16），而将计算密集的操作（例如矩阵乘法）交给 FP8 执行，从而在保证稳定性的同时充分利用 FP8 的高性能优势。</li></ul><figure><img src="/blog/assets/024_deepseek_v3_fp8-j18TkbxW.png" alt="DeepSeek-V3的FP8混合精度训练框架" tabindex="0" loading="lazy"><figcaption>DeepSeek-V3的FP8混合精度训练框架</figcaption></figure><p>DeepSeek-V3论文：http://arxiv.org/pdf/2412.19437</p><h2 id="_6-激活值重新计算-activation-recomputation-gradient-checkpointing-rematerialization" tabindex="-1"><a class="header-anchor" href="#_6-激活值重新计算-activation-recomputation-gradient-checkpointing-rematerialization" aria-hidden="true">#</a> 6. 激活值重新计算 Activation Recomputation / Gradient Checkpointing / rematerialization</h2><p>以时间换空间，以计算换内存：丢弃一些前向传播计算出的激活值来节省内存，并花费额外的计算在反向传播中来动态地重新计算激活值</p><p>激活值存储内容：</p><ul><li>不使用重新计算的情况下：存储两个可学习操作（例如前馈网络、层归一化等）之间的每个隐藏状态，以便在反向传播时使用它们来计算梯度</li><li>使用重新计算的情况下：只在模型架构的几个关键点存储激活值，丢弃其余的激活值，并在反向传播时从最近保存的激活值开始动态重新计算它们，基本上是再次执行前向传播的一个子部分</li></ul><figure><img src="/blog/assets/024_activation_recomputation_process-tNDxYgfa.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>激活值重新计算策略：</p><ul><li>全部激活值重新计算 Full <ul><li>在反向传播时走一遍完整的前向传播</li><li>内存占用：激活值几乎不占内存</li><li>计算消耗：增加计算成本和时间高达 30-40%</li></ul></li><li>选择部分激活值重新计算 Selective （更优选） <ul><li>丢弃并重新计算注意力部分（这部分造成了激活值的最大增长但有最廉价的计算成本）</li><li>内存占用：减少了70%的激活值内存占用（显著减少了内存访问开销）</li><li>计算消耗：增加了2.7%的计算消耗（略微增加了FLOPS的数量，其中FLOPS (Floating point operations per second)）</li><li>这种权衡在具有小型高速内存的硬件上尤其有利，例如GPU，因为访问内存通常比执行计算要慢。尽管涉及额外的操作，但整体效果往往是计算速度更快，同时内存占用也大大减少。</li></ul></li></ul><figure><img src="/blog/assets/024_no_recomputation_8b-F_J5_04-.png" alt="No Recomputation - 8B" tabindex="0" loading="lazy"><figcaption>No Recomputation - 8B</figcaption></figure><figure><img src="/blog/assets/024_full_recomputation_8b-hjGV9SJN.png" alt="Full Recomputation - 8B" tabindex="0" loading="lazy"><figcaption>Full Recomputation - 8B</figcaption></figure><figure><img src="/blog/assets/024_selective_recomputation_8b-G5un0y8u.png" alt="Selective Recomputation - 8B" tabindex="0" loading="lazy"><figcaption>Selective Recomputation - 8B</figcaption></figure><figure><img src="/blog/assets/024_no_recomputation_70b-5yTACmz2.png" alt="No Recomputation - 70B" tabindex="0" loading="lazy"><figcaption>No Recomputation - 70B</figcaption></figure><figure><img src="/blog/assets/024_full_recomputation_70b-N_l20i9U.png" alt="Full Recomputation - 70B" tabindex="0" loading="lazy"><figcaption>Full Recomputation - 70B</figcaption></figure><figure><img src="/blog/assets/024_selective_recomputation_70b-Fnz-Nn2X.png" alt="Selective Recomputation - 70B" tabindex="0" loading="lazy"><figcaption>Selective Recomputation - 70B</figcaption></figure><ul><li>越小的模型，激活值占比越大</li><li>序列越长，激活值占比越大</li><li>对于小模型的长序列情形，重新计算对内存的影响显著</li></ul><p>Selective Recomputation的实现：FlashAttention</p><p>然而，激活值仍然与批次大小呈线性依赖关系，我们在上面的条形图中所有的配置文件都使用的是批次大小为1，因此当我们转向更大的批次大小时，这可能会再次成为一个问题。别绝望，因为我们还有第二件工具——梯度累积来救场！</p><h2 id="_7-梯度累积-gradient-accumulation" tabindex="-1"><a class="header-anchor" href="#_7-梯度累积-gradient-accumulation" aria-hidden="true">#</a> 7. 梯度累积 Gradient Accumulation</h2><p>以时间换空间，以计算换内存：把批次batch再进行分批为微批次micro-batch，对每个micro-batch进行前向传播和反向传播计算梯度，然后将每个micro-batch计算的梯度进行梯度累积后（梯度累积实际上不是求和而是求平均值，以至于不受微批次micro-batch个数的影响），再执行优化器更新参数的步骤</p><p>术语</p><ul><li>batch size (bs)</li><li>micro batch size (mbs)</li><li>global batch size (gbs)</li><li>grad_acc: the number of gradient accumulation step 梯度累积数</li></ul><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>bs = gbs = mbs * grad_acc
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><figure><img src="/blog/assets/024_gradient_accumulation-qnp3itkV.png" alt="Gradient Accumulation" tabindex="0" loading="lazy"><figcaption>Gradient Accumulation</figcaption></figure><p>梯度累积优劣势</p><ul><li>优势 <ul><li>允许batch size设置的较大但内存占用保持稳定，通过微批次micro batch size降低了随batch size线形增长的激活值的内存占用</li><li>与Activation Recomputation兼容，可以一同采用来降低内存占用</li><li>多个微批次的前向传播和反向传播计算，可以并行处理</li></ul></li><li>劣势 <ul><li>需要计算多个前向传播和反向传播，增加了计算消耗</li></ul></li></ul><h2 id="_8-小工具" tabindex="-1"><a class="header-anchor" href="#_8-小工具" aria-hidden="true">#</a> 8. 小工具</h2><h2 id="_8-1-计算内存使用量工具-predict-memory" tabindex="-1"><a class="header-anchor" href="#_8-1-计算内存使用量工具-predict-memory" aria-hidden="true">#</a> 8.1. 计算内存使用量工具：Predict Memory</h2><p>before diving into code and experiments, we want to understand how each method works at a high level and what it’s advantages and limits are. You’ll learn about which parts of a language model eat away your memory and when during training it happens. You’ll learn how we can solve memory constraints by parallelizing the models and increase the throughput by scaling up GPUs. As a result you&#39;ll understand how the following widget to compute the memory breakdown of a transformer model works</p><figure><img src="/blog/assets/024_memory_usage_widget-GZpHZ-eQ.png" alt="Memory Usage Widget" tabindex="0" loading="lazy"><figcaption>Memory Usage Widget</figcaption></figure><p>预测内存使用量工具：https://huggingface.co/spaces/nanotron/predict_memory</p><figure><img src="/blog/assets/024_memory_timeline-cE57v0pS.png" alt="Memory Timeline" tabindex="0" loading="lazy"><figcaption>Memory Timeline</figcaption></figure><h2 id="_8-2-可视化gpu计算和通信成本的分布式训练工具-profiler" tabindex="-1"><a class="header-anchor" href="#_8-2-可视化gpu计算和通信成本的分布式训练工具-profiler" aria-hidden="true">#</a> 8.2. 可视化GPU计算和通信成本的分布式训练工具：Profiler</h2><p>用途：理解和验证GPU计算和通信成本，知道瓶颈在哪</p><p><a href="https://pytorch.org/tutorials/recipes/recipes/profiler_recipe.html" target="_blank" rel="noopener noreferrer">PyTorch&#39;s profiler<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><p>代码：</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>with torch.profiler.profile(
    activities=[
        torch.profiler.ProfilerActivity.CPU,
        torch.profiler.ProfilerActivity.CUDA,
    ],
    schedule=torch.profiler.schedule(wait=1, warmup=1, active=3),
    on_trace_ready=torch.profiler.tensorboard_trace_handler(&#39;./log/profile&#39;),
    with_stack=True
) as prof:
    for step in range(steps):
        train_step() 
        prof.step()
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><figure><img src="/blog/assets/024_profiler-TUbH0qPy.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>这会生成一个跟踪记录，我们可以在 TensorBoard 或 Chrome 的跟踪查看器中进行可视化。跟踪记录显示：</p><ul><li>CPU 线程异步地将内核启动到 GPU</li><li>多个 CUDA 流并行处理计算和通信</li><li>内核执行时间和内存分配 例如，跟踪记录显示 CPU 线程异步地将内核启动到 GPU，计算内核和通信在不同的 CUDA 流上并行进行。 跟踪记录有助于识别瓶颈，例如：</li><li>本可以重叠的顺序计算和通信</li><li>GPU 等待数据传输的空闲时间</li><li>CPU 和 GPU 之间的内存移动</li><li>CPU 的内核启动开销</li></ul><h2 id="_9-参考资料-ultrascale-playbook" tabindex="-1"><a class="header-anchor" href="#_9-参考资料-ultrascale-playbook" aria-hidden="true">#</a> 9. 参考资料：ultrascale-playbook</h2><p><a href="https://huggingface.co/spaces/nanotron/ultrascale-playbook" target="_blank" rel="noopener noreferrer">https://huggingface.co/spaces/nanotron/ultrascale-playbook<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><h3 id="_9-1-概览" tabindex="-1"><a class="header-anchor" href="#_9-1-概览" aria-hidden="true">#</a> 9.1. 概览</h3><figure><img src="/blog/assets/024_preview-AUOpCXxY.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><figure><img src="/blog/assets/024_preview1-5sq2ztyI.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><figure><img src="/blog/assets/024_preview2-jIG_e765.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h3 id="_9-2-前置基础知识" tabindex="-1"><a class="header-anchor" href="#_9-2-前置基础知识" aria-hidden="true">#</a> 9.2. 前置基础知识</h3><ul><li>主流的LLM架构</li><li>模型训练的基础：深度学习模型怎么被训练的 <ul><li>推荐优质教学资源 <ul><li>https://www.deeplearning.ai/</li><li>https://pytorch.org/tutorials/beginner/basics/intro.html</li></ul></li></ul></li></ul><h3 id="_9-3-scaling-experiments" tabindex="-1"><a class="header-anchor" href="#_9-3-scaling-experiments" aria-hidden="true">#</a> 9.3. scaling experiments</h3><p>We ran over 4000 scaling experiments on up to 512 GPUs and measured throughput (size of markers) and GPU utilization (color of markers). Note that both are normalized per model size in this visualization.</p><p>We ran over 4100 distributed experiments (over 16k including test runs) with up to 512 GPUs to scan many possible distributed training layouts and model sizes.</p><figure><img src="/blog/assets/024_scaling_experiments-7UafEv_Q.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><figure><img src="/blog/assets/024_scaling_experiments1-_V_eQt5b.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure></div><!--[--><!----><!--]--><footer class="page-meta"><!----><div class="meta-item git-info"><!----><!----></div></footer><nav class="vp-page-nav"><a aria-label="分布式训练之二：并行编程 Parallel Programming" class="vp-link nav-link prev nav-link prev" href="/blog/zh/posts/llm/025_distribution_and_parallelism_1.html"><div class="hint"><span class="arrow start"></span>上一页</div><div class="link"><span class="font-icon icon fa-fw fa-sm fas fa-lightbulb" style=""></span>分布式训练之二：并行编程 Parallel Programming</div></a><a aria-label="Langchain and LLamaindex Integration" class="vp-link nav-link next nav-link next" href="/blog/zh/posts/llm/023_agent_framework.html"><div class="hint">下一页<span class="arrow end"></span></div><div class="link">Langchain and LLamaindex Integration<span class="font-icon icon fa-fw fa-sm fas fa-lightbulb" style=""></span></div></a></nav><!----><!--[--><!----><!--]--><!--]--></main><!--]--><!----></div><!--]--><!--]--><!----><!--]--></div>
    <script type="module" src="/blog/assets/app-QwHuhOwl.js" defer></script>
  </body>
</html>
