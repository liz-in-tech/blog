<!doctype html>
<html lang="zh-CN" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.0" />
    <meta name="theme" content="VuePress Theme Hope 2.0.0-rc.13" />
    <style>
      html {
        background: var(--bg-color, #fff);
      }

      html[data-theme="dark"] {
        background: var(--bg-color, #1d1e1f);
      }

      body {
        background: var(--bg-color);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <link rel="alternate" hreflang="en-us" href="https://liz-in-tech.github.io/blog/posts/llm/025_distribution_and_parallelism_1.html"><meta property="og:url" content="https://liz-in-tech.github.io/blog/zh/posts/llm/025_distribution_and_parallelism_1.html"><meta property="og:site_name" content="Liz"><meta property="og:title" content="分布式训练之二：并行编程 Parallel Programming"><meta property="og:description" content="分布式训练之二：并行编程 Parallel Programming"><meta property="og:type" content="article"><meta property="og:locale" content="zh-CN"><meta property="og:locale:alternate" content="en-US"><meta property="og:updated_time" content="2025-03-08T14:32:06.000Z"><meta property="article:author" content="Liz"><meta property="article:tag" content="分布式"><meta property="article:tag" content="并行"><meta property="article:published_time" content="2025-02-28T00:00:00.000Z"><meta property="article:modified_time" content="2025-03-08T14:32:06.000Z"><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"分布式训练之二：并行编程 Parallel Programming","image":[""],"datePublished":"2025-02-28T00:00:00.000Z","dateModified":"2025-03-08T14:32:06.000Z","author":[{"@type":"Person","name":"Liz","url":"https://github.com/liz-in-tech"}]}</script><link rel="icon" herf="/blogger.png"><link rel="icon" href="/blog/blogger.png"><title>分布式训练之二：并行编程 Parallel Programming | Liz</title><meta name="description" content="分布式训练之二：并行编程 Parallel Programming">
    <link rel="preload" href="/blog/assets/style-m_obra2h.css" as="style"><link rel="stylesheet" href="/blog/assets/style-m_obra2h.css">
    <link rel="modulepreload" href="/blog/assets/app-RtLkXOlm.js"><link rel="modulepreload" href="/blog/assets/025_distribution_and_parallelism_1.html-ZR9kuXUl.js"><link rel="modulepreload" href="/blog/assets/025_distribution_and_parallelism_1.html-VLmKbMAj.js"><link rel="modulepreload" href="/blog/assets/025_barrier-Cle6-zl5.js"><link rel="modulepreload" href="/blog/assets/plugin-vue_export-helper-x3n3nnut.js">
    <link rel="prefetch" href="/blog/assets/index.html-YbPtte5_.js" as="script"><link rel="prefetch" href="/blog/assets/intro.html-CGfhr1vY.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-FUMOuem4.js" as="script"><link rel="prefetch" href="/blog/assets/index.html--TTjrkIy.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-g4Nfr7z1.js" as="script"><link rel="prefetch" href="/blog/assets/intro.html-bitGHKd2.js" as="script"><link rel="prefetch" href="/blog/assets/001_langchain.html-nrisQopy.js" as="script"><link rel="prefetch" href="/blog/assets/002_langchain_sourcecode.html-9XtwFAwc.js" as="script"><link rel="prefetch" href="/blog/assets/003_streamlit.html-oji9upQP.js" as="script"><link rel="prefetch" href="/blog/assets/004_transformer.html-xrin91s2.js" as="script"><link rel="prefetch" href="/blog/assets/005_llama.html-zssRppb4.js" as="script"><link rel="prefetch" href="/blog/assets/006_llm_leaderboard.html-c628DmZb.js" as="script"><link rel="prefetch" href="/blog/assets/007_computer_use.html-4RcS3hxb.js" as="script"><link rel="prefetch" href="/blog/assets/008_rag_challenge.html-_8stdYVV.js" as="script"><link rel="prefetch" href="/blog/assets/009_llm_challenge.html-eluz3bTT.js" as="script"><link rel="prefetch" href="/blog/assets/010_rag_workflow.html-Ft0RQWf3.js" as="script"><link rel="prefetch" href="/blog/assets/011_vector_database.html-CImz0KSx.js" as="script"><link rel="prefetch" href="/blog/assets/012_prompt_engineering.html-Q27DlfZz.js" as="script"><link rel="prefetch" href="/blog/assets/013_optimizing_llm.html-6CxOIR84.js" as="script"><link rel="prefetch" href="/blog/assets/014_rag_evaluation.html-l_kCYUI1.js" as="script"><link rel="prefetch" href="/blog/assets/015_fine_tune.html-48naV3Ea.js" as="script"><link rel="prefetch" href="/blog/assets/016_multimodal.html-XtD4OMNh.js" as="script"><link rel="prefetch" href="/blog/assets/017_agent_and_multiagent.html-dm178NRn.js" as="script"><link rel="prefetch" href="/blog/assets/018_huggingface.html-WI0c55vB.js" as="script"><link rel="prefetch" href="/blog/assets/019_ollama.html-kLkdC4dl.js" as="script"><link rel="prefetch" href="/blog/assets/020_neo4j.html-P-Llr3CJ.js" as="script"><link rel="prefetch" href="/blog/assets/021_microsoft_graphrag.html-0d0frUhq.js" as="script"><link rel="prefetch" href="/blog/assets/022_llamaindex_graphrag.html-RhkTd_Zr.js" as="script"><link rel="prefetch" href="/blog/assets/023_agent_framework.html-5MCDM_Sd.js" as="script"><link rel="prefetch" href="/blog/assets/024_distribution_and_parallelism.html-uCefT9T7.js" as="script"><link rel="prefetch" href="/blog/assets/025_distribution_and_parallelism_1.html-32IzAErP.js" as="script"><link rel="prefetch" href="/blog/assets/026_distribution_and_parallelism_2.html-MEZ1JY2b.js" as="script"><link rel="prefetch" href="/blog/assets/027_distribution_and_parallelism_3.html-IYByZhbZ.js" as="script"><link rel="prefetch" href="/blog/assets/028_distribution_and_parallelism_4.html-Kub1JEXd.js" as="script"><link rel="prefetch" href="/blog/assets/029_unsloth_grpo.html-T25XLAW-.js" as="script"><link rel="prefetch" href="/blog/assets/030_wandb.html-61V6KLeo.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ZDCSnlc1.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ZYw6WxxA.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-OavE9BET.js" as="script"><link rel="prefetch" href="/blog/assets/001_langchain.html-hE_T0u_5.js" as="script"><link rel="prefetch" href="/blog/assets/002_langchain_sourcecode.html-iH0mq6XB.js" as="script"><link rel="prefetch" href="/blog/assets/003_streamlit.html-WyFhRqF6.js" as="script"><link rel="prefetch" href="/blog/assets/004_transformer.html-YaT0PR6o.js" as="script"><link rel="prefetch" href="/blog/assets/005_llama.html-6PFDsh_d.js" as="script"><link rel="prefetch" href="/blog/assets/006_llm_leaderboard.html-WHPR-17-.js" as="script"><link rel="prefetch" href="/blog/assets/007_computer_use.html-hz6Q-DAA.js" as="script"><link rel="prefetch" href="/blog/assets/008_rag_challenge.html-3KMCwhrh.js" as="script"><link rel="prefetch" href="/blog/assets/009_llm_challenge.html-7gxKMp_3.js" as="script"><link rel="prefetch" href="/blog/assets/010_rag_workflow.html-KndRvZAj.js" as="script"><link rel="prefetch" href="/blog/assets/011_vector_database.html-Akmj-Ub_.js" as="script"><link rel="prefetch" href="/blog/assets/012_prompt_engineering.html-ZdCqy2Fu.js" as="script"><link rel="prefetch" href="/blog/assets/013_optimizing_llm.html-W-CdR_ck.js" as="script"><link rel="prefetch" href="/blog/assets/014_rag_evaluation.html-aq7YkQ-T.js" as="script"><link rel="prefetch" href="/blog/assets/015_fine_tune.html-egR6ajJ8.js" as="script"><link rel="prefetch" href="/blog/assets/016_multimodal.html-DCPUUxWe.js" as="script"><link rel="prefetch" href="/blog/assets/017_agent_and_multiagent.html-RlA7g4kG.js" as="script"><link rel="prefetch" href="/blog/assets/018_huggingface.html-Si3T7PB7.js" as="script"><link rel="prefetch" href="/blog/assets/019_ollama.html-V5tcXCC4.js" as="script"><link rel="prefetch" href="/blog/assets/020_neo4j.html-ytaIU5xV.js" as="script"><link rel="prefetch" href="/blog/assets/021_microsoft_graphrag.html-kvlLpO3f.js" as="script"><link rel="prefetch" href="/blog/assets/022_llamaindex_graphrag.html-nS8_ZZy5.js" as="script"><link rel="prefetch" href="/blog/assets/023_agent_framework.html-VZsN2kO8.js" as="script"><link rel="prefetch" href="/blog/assets/024_distribution_and_parallelism.html-MO4kg9bC.js" as="script"><link rel="prefetch" href="/blog/assets/026_distribution_and_parallelism_2.html-GkjDPoeT.js" as="script"><link rel="prefetch" href="/blog/assets/027_distribution_and_parallelism_3.html-5kFJGreK.js" as="script"><link rel="prefetch" href="/blog/assets/028_distribution_and_parallelism_4.html-38Gbieji.js" as="script"><link rel="prefetch" href="/blog/assets/029_unsloth_grpo.html-sutxVW-j.js" as="script"><link rel="prefetch" href="/blog/assets/030_wandb.html-VCoqJJSk.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-wh_dBtOR.js" as="script"><link rel="prefetch" href="/blog/assets/404.html-cxLWDy2T.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-kf4JCRaf.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-RkA-insV.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-4kI_oqSd.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-WhuidxNt.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-OqGkeUA_.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-5GeN-sdD.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-c4Rf4yh1.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-2r0jUs7o.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-BSKRXRQc.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-KjTsJ0Hg.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-TteIwMx3.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-g00XXzrL.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-YxbJgo4L.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-3T79Cy0i.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-A5tlQHan.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-04ff5e0O.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-vgZ6rfFh.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-OmipPplE.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-E1KrJL6a.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-oPH9QkTj.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-cHRqZSs8.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-74SU9ZTn.js" as="script"><link rel="prefetch" href="/blog/assets/index.html--iJiA8oX.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-oZPWb_Fc.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-FUIWSLsp.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-5ERWyusD.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Zjn0JNqd.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-jcvPTrgB.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-9t2TsyuQ.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-CcLVFNIv.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-DVoYOOaL.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-V52ipvRm.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-9If_KW0o.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-df9Mrf2R.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-f9bWoKcO.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-GYH0QUoo.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-JVTfeijx.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-_C1QVNqX.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-L_IXFmna.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-nZWHmXY7.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-x4gPgqE4.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-bWnVyuyA.js" as="script"><link rel="prefetch" href="/blog/assets/index.html--yTU23ka.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-tRnpyzfw.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-7aypos-L.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-1BXcbV1R.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-pu478WKz.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-LHukpLS7.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-howjHe2f.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-DeN_iOWx.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-cnlzR0a7.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-0P_c_pcU.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-dy_CcFmq.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-FzFytZ_p.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-2KSwV7xp.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-F1coElwg.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ffflqCb9.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-F8ZuLYgH.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-HeYWaFeL.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-xKYeJEc5.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-xB-iS7Ql.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-OEUPqfTV.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-EE4iQI9m.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-g1PUF_BG.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-nUBcs85a.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-9Y3la5Sf.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-wufIFDPM.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-bXZQIxRE.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-wd6ZkEHi.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Xlk0AXmC.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Uv7c7pYa.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-FfZqC9tZ.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-mSPhZxqB.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-51HoKD5A.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Q5_K6Vux.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-jkWPo860.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-kTEqch5G.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-y4iBqBqc.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ibHhI9SI.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-3hk_s27_.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-QJ9j3Zl2.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-QvWFHL99.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Pefl6i_g.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-mVxXMlZb.js" as="script"><link rel="prefetch" href="/blog/assets/intro.html-sghZc5Sy.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-uNG3icgm.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-XzC2jM83.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-e-qKB0BU.js" as="script"><link rel="prefetch" href="/blog/assets/intro.html-eKqc0Ica.js" as="script"><link rel="prefetch" href="/blog/assets/001_langchain.html-g9Y94Dag.js" as="script"><link rel="prefetch" href="/blog/assets/002_langchain_sourcecode.html-CQzSND44.js" as="script"><link rel="prefetch" href="/blog/assets/003_streamlit.html-YBZe0aqw.js" as="script"><link rel="prefetch" href="/blog/assets/004_transformer.html-IlhJtZZ8.js" as="script"><link rel="prefetch" href="/blog/assets/005_llama.html-6j1pSuAF.js" as="script"><link rel="prefetch" href="/blog/assets/006_llm_leaderboard.html-4GpKuXkP.js" as="script"><link rel="prefetch" href="/blog/assets/007_computer_use.html-SJQTak1t.js" as="script"><link rel="prefetch" href="/blog/assets/008_rag_challenge.html-uBK1Hl_j.js" as="script"><link rel="prefetch" href="/blog/assets/009_llm_challenge.html-4Nua2za_.js" as="script"><link rel="prefetch" href="/blog/assets/010_rag_workflow.html-lgNuuMQh.js" as="script"><link rel="prefetch" href="/blog/assets/011_vector_database.html-iWs4PETy.js" as="script"><link rel="prefetch" href="/blog/assets/012_prompt_engineering.html-qld7emOW.js" as="script"><link rel="prefetch" href="/blog/assets/013_optimizing_llm.html-ut-S4jnW.js" as="script"><link rel="prefetch" href="/blog/assets/014_rag_evaluation.html-C3dEh3sn.js" as="script"><link rel="prefetch" href="/blog/assets/015_fine_tune.html-b7rpA4x2.js" as="script"><link rel="prefetch" href="/blog/assets/016_multimodal.html-R0H_4UGQ.js" as="script"><link rel="prefetch" href="/blog/assets/017_agent_and_multiagent.html-5ErjJIPh.js" as="script"><link rel="prefetch" href="/blog/assets/018_huggingface.html-9tAt6j1B.js" as="script"><link rel="prefetch" href="/blog/assets/019_ollama.html-RhwnUEQW.js" as="script"><link rel="prefetch" href="/blog/assets/020_neo4j.html-MtVd1iad.js" as="script"><link rel="prefetch" href="/blog/assets/021_microsoft_graphrag.html-HroaJ8Nm.js" as="script"><link rel="prefetch" href="/blog/assets/022_llamaindex_graphrag.html--3zvXxVM.js" as="script"><link rel="prefetch" href="/blog/assets/023_agent_framework.html-gPIexNfk.js" as="script"><link rel="prefetch" href="/blog/assets/024_distribution_and_parallelism.html-YjdJDlmS.js" as="script"><link rel="prefetch" href="/blog/assets/025_distribution_and_parallelism_1.html-ncYMx1Cs.js" as="script"><link rel="prefetch" href="/blog/assets/026_distribution_and_parallelism_2.html-_X1Y9Tcy.js" as="script"><link rel="prefetch" href="/blog/assets/027_distribution_and_parallelism_3.html-3jR90SDM.js" as="script"><link rel="prefetch" href="/blog/assets/028_distribution_and_parallelism_4.html-KtGtqtof.js" as="script"><link rel="prefetch" href="/blog/assets/029_unsloth_grpo.html-wh9mGnt1.js" as="script"><link rel="prefetch" href="/blog/assets/030_wandb.html-sVoeRX7s.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-BRzkrMxr.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-3TxbfoI1.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-GgN_kDfe.js" as="script"><link rel="prefetch" href="/blog/assets/001_langchain.html-vCuuungV.js" as="script"><link rel="prefetch" href="/blog/assets/002_langchain_sourcecode.html-Z4PqFZVX.js" as="script"><link rel="prefetch" href="/blog/assets/003_streamlit.html-ji1I41JA.js" as="script"><link rel="prefetch" href="/blog/assets/004_transformer.html-uASFqJj9.js" as="script"><link rel="prefetch" href="/blog/assets/005_llama.html-4KIYki3W.js" as="script"><link rel="prefetch" href="/blog/assets/006_llm_leaderboard.html-Zd42A_Cl.js" as="script"><link rel="prefetch" href="/blog/assets/007_computer_use.html-uegEjqAb.js" as="script"><link rel="prefetch" href="/blog/assets/008_rag_challenge.html-Wu-lJzLe.js" as="script"><link rel="prefetch" href="/blog/assets/009_llm_challenge.html-gxyC-ige.js" as="script"><link rel="prefetch" href="/blog/assets/010_rag_workflow.html-kPQIc04V.js" as="script"><link rel="prefetch" href="/blog/assets/011_vector_database.html-cRyDRNn2.js" as="script"><link rel="prefetch" href="/blog/assets/012_prompt_engineering.html-B7VP1Mul.js" as="script"><link rel="prefetch" href="/blog/assets/013_optimizing_llm.html-UN1uCzJw.js" as="script"><link rel="prefetch" href="/blog/assets/014_rag_evaluation.html-0u1ymYlU.js" as="script"><link rel="prefetch" href="/blog/assets/015_fine_tune.html-bKRfi0aA.js" as="script"><link rel="prefetch" href="/blog/assets/016_multimodal.html-wt9p7KOg.js" as="script"><link rel="prefetch" href="/blog/assets/017_agent_and_multiagent.html-6ScleOVP.js" as="script"><link rel="prefetch" href="/blog/assets/018_huggingface.html-oBKa7aX0.js" as="script"><link rel="prefetch" href="/blog/assets/019_ollama.html-lwVpVwuF.js" as="script"><link rel="prefetch" href="/blog/assets/020_neo4j.html-LFZkim3B.js" as="script"><link rel="prefetch" href="/blog/assets/021_microsoft_graphrag.html-Z7tHuMAj.js" as="script"><link rel="prefetch" href="/blog/assets/022_llamaindex_graphrag.html-FxCN2a__.js" as="script"><link rel="prefetch" href="/blog/assets/023_agent_framework.html-MQ5_NUIT.js" as="script"><link rel="prefetch" href="/blog/assets/024_distribution_and_parallelism.html-up7PKGfM.js" as="script"><link rel="prefetch" href="/blog/assets/026_distribution_and_parallelism_2.html-Se82n22F.js" as="script"><link rel="prefetch" href="/blog/assets/027_distribution_and_parallelism_3.html-0WWpxcdz.js" as="script"><link rel="prefetch" href="/blog/assets/028_distribution_and_parallelism_4.html-9QvbwWKn.js" as="script"><link rel="prefetch" href="/blog/assets/029_unsloth_grpo.html-CQKDDasT.js" as="script"><link rel="prefetch" href="/blog/assets/030_wandb.html-oGiGKdMI.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-B0FiYcVA.js" as="script"><link rel="prefetch" href="/blog/assets/404.html-rbMtnioU.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-HmW4Xl_k.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-1eRIhxHA.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-kj-OJZ5i.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-U_E57tpO.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Gcw0Vl6N.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Y1ZTGAdB.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-7CvfpMc9.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-uGYjh70S.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-qqo0LDYr.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-oGx9io5Z.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Gj5nsimF.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-PvS3bTR2.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-W_kdPkV7.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-_FyWdpjv.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-_sEUWGlX.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-SkCJRfD4.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-UBqpAX2e.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-YZHUo8gS.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-V6v6OC4y.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-D4FxzFU2.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-FnXQ0xMc.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-eeGfVoPr.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-z9P94UiB.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-3fIlOf9u.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-l9sUtUk2.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-EQqQBuJ_.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-jdeZsJ0e.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-rUq6TJaz.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-eM_Z7I5_.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-gyRCXWfS.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-3SolUw_e.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-_h9AIW1B.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-p06GBoUr.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-p-pE_ImK.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-tN6ZsL3d.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-AmIVzlO8.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-0hq6SCh2.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-bd0wflYq.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-3TMe4a2K.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-JFE6Me50.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-tORzqJwN.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-1XeXld4i.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-SbaeIJJO.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-o7Yu96yI.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-70s2wVBV.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-JR1I24B1.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-aeYPKQ69.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-8ZIQ5NZ8.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-7M2we1_W.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-z5gMDeef.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-w1NIdGay.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Hw9IFSI3.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-dAhRuavt.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Tqrag93E.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-srkWpsLA.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-CKkA-69k.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-_txKly8k.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-fim46XI3.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-LOFw_Dlc.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-6wXDIoJb.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Gi_pSCJG.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-xxHX3Qh_.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Le641wdT.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ZWZt8rEC.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-wjpj-gvU.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-TbHfq6Ir.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-srd2duHt.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-cKQM0wmA.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Li2tD2hd.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-4Un7h4PI.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-2LQto8V8.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-k_cDECmv.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-07-per9v.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-T-PmgCZo.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-oZW5Es3R.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Iw3kXqPT.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-VYOPELl-.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-kDlQIRMY.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-pCkxSxZx.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-sEOFnfRT.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-dMJfJN7A.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-fzxAKh08.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-JGtTAeZw.js" as="script"><link rel="prefetch" href="/blog/assets/photoswipe.esm-08_zHRDQ.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">跳至主要內容</a><!--]--><!--[--><div class="theme-container no-sidebar has-toc"><!--[--><header id="navbar" class="vp-navbar"><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!--[--><!----><!--]--><!--[--><a class="vp-link vp-brand vp-brand" href="/blog/zh/"><img class="vp-nav-logo" src="/blog/blogger.png" alt><!----><span class="vp-site-name hide-in-pad">Liz</span></a><!--]--><!--[--><!----><!--]--></div><div class="vp-navbar-center"><!--[--><!----><!--]--><!--[--><nav class="vp-nav-links"><div class="nav-item hide-in-mobile"><a aria-label="首页" class="vp-link nav-link nav-link" href="/blog/zh/"><span class="font-icon icon fa-fw fa-sm fas fa-home" style=""></span>首页<!----></a></div><div class="nav-item hide-in-mobile"><a aria-label="项目" class="vp-link nav-link nav-link" href="/blog/zh/demo/"><span class="font-icon icon fa-fw fa-sm fas fa-star" style=""></span>项目<!----></a></div></nav><!--]--><!--[--><!----><!--]--></div><div class="vp-navbar-end"><!--[--><!----><!--]--><!--[--><div class="nav-item"><div class="dropdown-wrapper i18n-dropdown"><button type="button" class="dropdown-title" aria-label="选择语言"><!--[--><svg xmlns="http://www.w3.org/2000/svg" class="icon i18n-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="i18n icon" style="width:1rem;height:1rem;vertical-align:middle;"><path d="M379.392 460.8 494.08 575.488l-42.496 102.4L307.2 532.48 138.24 701.44l-71.68-72.704L234.496 460.8l-45.056-45.056c-27.136-27.136-51.2-66.56-66.56-108.544h112.64c7.68 14.336 16.896 27.136 26.112 35.84l45.568 46.08 45.056-45.056C382.976 312.32 409.6 247.808 409.6 204.8H0V102.4h256V0h102.4v102.4h256v102.4H512c0 70.144-37.888 161.28-87.04 210.944L378.88 460.8zM576 870.4 512 1024H409.6l256-614.4H768l256 614.4H921.6l-64-153.6H576zM618.496 768h196.608L716.8 532.48 618.496 768z"></path></svg><!--]--><span class="arrow"></span><ul class="nav-dropdown"><li class="dropdown-item"><a aria-label="English" class="vp-link nav-link nav-link" href="/blog/posts/llm/025_distribution_and_parallelism_1.html"><!---->English<!----></a></li><li class="dropdown-item"><a aria-label="简体中文" class="vp-link nav-link active nav-link active" href="/blog/zh/posts/llm/025_distribution_and_parallelism_1.html"><!---->简体中文<!----></a></li></ul></button></div></div><div class="nav-item vp-repo"><a class="vp-repo-link" href="https://github.com/liz-in-tech" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><div class="nav-item hide-in-mobile"><button type="button" id="appearance-switch"><svg xmlns="http://www.w3.org/2000/svg" class="icon auto-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="auto icon" style="display:block;"><path d="M512 992C246.92 992 32 777.08 32 512S246.92 32 512 32s480 214.92 480 480-214.92 480-480 480zm0-840c-198.78 0-360 161.22-360 360 0 198.84 161.22 360 360 360s360-161.16 360-360c0-198.78-161.22-360-360-360zm0 660V212c165.72 0 300 134.34 300 300 0 165.72-134.28 300-300 300z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon dark-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="dark icon" style="display:none;"><path d="M524.8 938.667h-4.267a439.893 439.893 0 0 1-313.173-134.4 446.293 446.293 0 0 1-11.093-597.334A432.213 432.213 0 0 1 366.933 90.027a42.667 42.667 0 0 1 45.227 9.386 42.667 42.667 0 0 1 10.24 42.667 358.4 358.4 0 0 0 82.773 375.893 361.387 361.387 0 0 0 376.747 82.774 42.667 42.667 0 0 1 54.187 55.04 433.493 433.493 0 0 1-99.84 154.88 438.613 438.613 0 0 1-311.467 128z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon light-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="light icon" style="display:none;"><path d="M952 552h-80a40 40 0 0 1 0-80h80a40 40 0 0 1 0 80zM801.88 280.08a41 41 0 0 1-57.96-57.96l57.96-58a41.04 41.04 0 0 1 58 58l-58 57.96zM512 752a240 240 0 1 1 0-480 240 240 0 0 1 0 480zm0-560a40 40 0 0 1-40-40V72a40 40 0 0 1 80 0v80a40 40 0 0 1-40 40zm-289.88 88.08-58-57.96a41.04 41.04 0 0 1 58-58l57.96 58a41 41 0 0 1-57.96 57.96zM192 512a40 40 0 0 1-40 40H72a40 40 0 0 1 0-80h80a40 40 0 0 1 40 40zm30.12 231.92a41 41 0 0 1 57.96 57.96l-57.96 58a41.04 41.04 0 0 1-58-58l58-57.96zM512 832a40 40 0 0 1 40 40v80a40 40 0 0 1-80 0v-80a40 40 0 0 1 40-40zm289.88-88.08 58 57.96a41.04 41.04 0 0 1-58 58l-57.96-58a41 41 0 0 1 57.96-57.96z"></path></svg></button></div><form class="search-box" role="search"><input type="search" placeholder="搜索" autocomplete="off" spellcheck="false" value><!----></form><!--]--><!--[--><!----><!--]--><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar"><!--[--><!----><!--]--><ul class="vp-sidebar-links"></ul><!--[--><!----><!--]--></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!--[--><!----><!--]--><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><span class="font-icon icon fa-fw fa-sm fas fa-lightbulb" style=""></span>分布式训练之二：并行编程 Parallel Programming</h1><div class="page-info"><span class="page-author-info" aria-label="作者🖊" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><a class="page-author-item" href="https://github.com/liz-in-tech" target="_blank" rel="noopener noreferrer">Liz</a></span><span property="author" content="Liz"></span></span><!----><span class="page-date-info" aria-label="写作日期📅" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span><!----></span><meta property="datePublished" content="2025-02-28T00:00:00.000Z"></span><!----><span class="page-reading-time-info" aria-label="阅读时间⌛" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>大约 5 分钟</span><meta property="timeRequired" content="PT5M"></span><span class="page-category-info" aria-label="分类🌈" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon category-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="category icon"><path d="M148.41 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H148.41c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.311-40.31zM147.556 553.478H429.73c22.263 0 40.311 18.048 40.311 40.31v282.176c0 22.263-18.048 40.312-40.31 40.312H147.555c-22.263 0-40.311-18.049-40.311-40.312V593.79c0-22.263 18.048-40.311 40.31-40.311zM593.927 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H593.927c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.31-40.31zM730.22 920.502H623.926c-40.925 0-74.22-33.388-74.22-74.425V623.992c0-41.038 33.387-74.424 74.425-74.424h222.085c41.038 0 74.424 33.226 74.424 74.067v114.233c0 10.244-8.304 18.548-18.547 18.548s-18.548-8.304-18.548-18.548V623.635c0-20.388-16.746-36.974-37.33-36.974H624.13c-20.585 0-37.331 16.747-37.331 37.33v222.086c0 20.585 16.654 37.331 37.126 37.331H730.22c10.243 0 18.547 8.304 18.547 18.547 0 10.244-8.304 18.547-18.547 18.547z"></path></svg><!--[--><span class="page-category-item category6 clickable" role="navigation">LLM</span><!--]--><meta property="articleSection" content="LLM"></span><span class="page-tag-info" aria-label="标签🏷" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon tag-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="tag icon"><path d="M939.902 458.563L910.17 144.567c-1.507-16.272-14.465-29.13-30.737-30.737L565.438 84.098h-.402c-3.215 0-5.726 1.005-7.634 2.913l-470.39 470.39a10.004 10.004 0 000 14.164l365.423 365.424c1.909 1.908 4.42 2.913 7.132 2.913s5.223-1.005 7.132-2.913l470.39-470.39c2.01-2.11 3.014-5.023 2.813-8.036zm-240.067-72.121c-35.458 0-64.286-28.828-64.286-64.286s28.828-64.285 64.286-64.285 64.286 28.828 64.286 64.285-28.829 64.286-64.286 64.286z"></path></svg><!--[--><span class="page-tag-item tag4 clickable" role="navigation">分布式</span><span class="page-tag-item tag3 clickable" role="navigation">并行</span><!--]--><meta property="keywords" content="分布式,并行"></span></div><hr></div><div class="toc-place-holder"><aside id="toc"><!--[--><!----><!--]--><div class="toc-header">此页内容<button type="button" class="print-button" title="打印"><svg xmlns="http://www.w3.org/2000/svg" class="icon print-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="print icon"><path d="M819.2 364.8h-44.8V128c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v236.8h-44.8C145.067 364.8 96 413.867 96 473.6v192c0 59.733 49.067 108.8 108.8 108.8h44.8V896c0 17.067 14.933 32 32 32h460.8c17.067 0 32-14.933 32-32V774.4h44.8c59.733 0 108.8-49.067 108.8-108.8v-192c0-59.733-49.067-108.8-108.8-108.8zM313.6 160h396.8v204.8H313.6V160zm396.8 704H313.6V620.8h396.8V864zM864 665.6c0 25.6-19.2 44.8-44.8 44.8h-44.8V588.8c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v121.6h-44.8c-25.6 0-44.8-19.2-44.8-44.8v-192c0-25.6 19.2-44.8 44.8-44.8h614.4c25.6 0 44.8 19.2 44.8 44.8v192z"></path></svg></button></div><div class="toc-wrapper"><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_1-概览">1. 概览</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_2-broadcast">2. Broadcast</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_3-reduce-allreduce">3. Reduce &amp; AllReduce</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_4-gather-allgather">4. Gather &amp; AllGather</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_5-scatter-reducescatter">5. Scatter &amp; ReduceScatter</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_6-barrier">6. Barrier</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_7-pytorch代码实现">7. PyTorch代码实现</a></li><li><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_7-1-nccl是什么">7.1. NCCL是什么</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_7-2-broadcast">7.2. Broadcast</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_7-3-reduce">7.3. Reduce</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_7-4-allreduce">7.4. AllReduce</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_7-5-gather">7.5. Gather</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_7-6-allgather">7.6. AllGather</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_7-7-scatter">7.7. Scatter</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_7-8-reducescatter">7.8. ReduceScatter</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_7-9-barrier">7.9. Barrier</a></li><!----><!--]--></ul></li><!--]--></ul><div class="toc-marker" style="top:-1.7rem;"></div></div><!--[--><!----><!--]--></aside></div><!--[--><!----><!--]--><div class="theme-hope-content"><h1 id="分布式训练之二-并行编程-parallel-programming" tabindex="-1"><a class="header-anchor" href="#分布式训练之二-并行编程-parallel-programming" aria-hidden="true">#</a> 分布式训练之二：并行编程 Parallel Programming</h1><!-- more --><h2 id="_1-概览" tabindex="-1"><a class="header-anchor" href="#_1-概览" aria-hidden="true">#</a> 1. 概览</h2><ul><li>Broadcast</li><li>Reduce</li><li>AllReduce</li><li>Gather</li><li>AllGather</li><li>Scatter</li><li>ReduceScatter</li><li>Barrier</li></ul><p>Note：root节点作为服务器，它是某些操作的目标或源</p><p>关系：AllReduce = ReduceScatter + AllGather</p><figure><img src="/blog/assets/025_allreduce_relation-H8NMiCQn.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h2 id="_2-broadcast" tabindex="-1"><a class="header-anchor" href="#_2-broadcast" aria-hidden="true">#</a> 2. Broadcast</h2><figure><img src="/blog/assets/025_broadcast-uLqUf_wO.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h2 id="_3-reduce-allreduce" tabindex="-1"><a class="header-anchor" href="#_3-reduce-allreduce" aria-hidden="true">#</a> 3. Reduce &amp; AllReduce</h2><p>将每个节点的值通过函数合为一个值</p><p>函数f()常用的为求和（SUM）或求平均值（AVG）</p><ul><li>AVG is only available with the NCCL backend</li></ul><figure><img src="/blog/assets/025_reduce-yXKNy72E.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><ul><li>Reduce: 结果只发送给root节点</li><li>AllReduce: 结果广播发送到每个节点（每个节点的值一样）</li></ul><h2 id="_4-gather-allgather" tabindex="-1"><a class="header-anchor" href="#_4-gather-allgather" aria-hidden="true">#</a> 4. Gather &amp; AllGather</h2><figure><img src="/blog/assets/025_gather-MQZDPrtG.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h2 id="_5-scatter-reducescatter" tabindex="-1"><a class="header-anchor" href="#_5-scatter-reducescatter" aria-hidden="true">#</a> 5. Scatter &amp; ReduceScatter</h2><p><img src="/blog/assets/025_scatter-0m04J2I3.png" alt="" loading="lazy"> Scatter</p><ul><li>scatter不同于broadcast，scatter是将数据分片发送，broadcast是将数据完整发送</li><li>scatter在逻辑上是gather的反向操作</li></ul><p>ReduceScatter</p><ul><li>把每个节点上的数据分片</li><li>每个分片的各节点的数据通过函数进行Reduce</li><li>把每个分片Reduce的结果Scatter到每个节点</li></ul><h2 id="_6-barrier" tabindex="-1"><a class="header-anchor" href="#_6-barrier" aria-hidden="true">#</a> 6. Barrier</h2><p>所有节点到达障碍Barrier之前，Barrier不会解除，都到达Barrier后才能进行后续的计算，用于同步节点</p><figure><img src="/blog/assets/025_barrier-c-EDt2OK.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h2 id="_7-pytorch代码实现" tabindex="-1"><a class="header-anchor" href="#_7-pytorch代码实现" aria-hidden="true">#</a> 7. PyTorch代码实现</h2><h3 id="_7-1-nccl是什么" tabindex="-1"><a class="header-anchor" href="#_7-1-nccl是什么" aria-hidden="true">#</a> 7.1. NCCL是什么</h3><p>NCCL</p><ul><li>NVIDIA Collective Communications Library</li><li>NVIDIA 集体通信库</li><li>NVIDIA的GPU间通信的优化原语</li><li>NCCL 专为高效的 GPU-GPU 通信设计</li></ul><h3 id="_7-2-broadcast" tabindex="-1"><a class="header-anchor" href="#_7-2-broadcast" aria-hidden="true">#</a> 7.2. Broadcast</h3><p>代码</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>import torch
import torch.distributed as dist

def init_process():
    dist.init_process_group(backend=&#39;nccl&#39;)
    torch.cuda.set_device(dist.get_rank())
    
def example_broadcast():
    if dist.get_rank() == 0:
        tensor = torch.tensor([1, 2, 3, 4, 5], dtype=torch.float32).cuda()
    else:
        tensor = torch.zeros(5, dtype=torch.float32).cuda()
    print(f&quot;Before broadcast on rank {dist.get_rank()}: {tensor}&quot;)
    dist.broadcast(tensor, src=0)
    print(f&quot;After broadcast on rank {dist.get_rank()}: {tensor}&quot;)
    
init_process()
example_broadcats()
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>输出</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>Before broadcast on rank 0: tensor([1., 2., 3., 4., 5.], device=&#39;cuda:0&#39;)
Before broadcast on rank 1: tensor([0., 0., 0., 0., 0.], device=&#39;cuda:1&#39;)
Before broadcast on rank 2: tensor([0., 0., 0., 0., 0.], device=&#39;cuda:2&#39;)

After broadcast on rank 0: tensor([1., 2., 3., 4., 5.], device=&#39;cuda:0&#39;)
After broadcast on rank 1: tensor([1., 2., 3., 4., 5.], device=&#39;cuda:1&#39;)
After broadcast on rank 2: tensor([1., 2., 3., 4., 5.], device=&#39;cuda:2&#39;)
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_7-3-reduce" tabindex="-1"><a class="header-anchor" href="#_7-3-reduce" aria-hidden="true">#</a> 7.3. Reduce</h3><p>代码</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>def example_reduce():
    tensor = torch.tensor([dist.get_rank() + 1] * 5, dtype=torch.float32).cuda()
    print(f&quot;Before reduce on rank {dist.get_rank()}: {tensor}&quot;)
    dist.reduce(tensor, dst=0, op=dist.ReduceOp.SUM)
    print(f&quot;After reduce on rank {rank}: {tensor}&quot;)
    
init_process()
example_reduce()
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>输出</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>Before reduce on rank 0: tensor([1., 1., 1., 1., 1.], device=&#39;cuda:0&#39;)
Before reduce on rank 1: tensor([2., 2., 2., 2., 2.], device=&#39;cuda:1&#39;)
Before reduce on rank 2: tensor([3., 3., 3., 3., 3.], device=&#39;cuda:2&#39;)

After reduce on rank 0: tensor([6., 6., 6., 6., 6.], device=&#39;cuda:0&#39;)
After reduce on rank 1: tensor([2., 2., 2., 2., 2.], device=&#39;cuda:1&#39;)
After reduce on rank 2: tensor([3., 3., 3., 3., 3.], device=&#39;cuda:2&#39;)
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_7-4-allreduce" tabindex="-1"><a class="header-anchor" href="#_7-4-allreduce" aria-hidden="true">#</a> 7.4. AllReduce</h3><p>代码</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>def example_all_reduce():
    tensor = torch.tensor([dist.get_rank() + 1] * 5, dtype=torch.float32).cuda()
    print(f&quot;Before all_reduce on rank {dist.get_rank()}: {tensor}&quot;)
    dist.all_reduce(tensor, op=dist.ReduceOp.SUM)
    print(f&quot;After all_reduce on rank {dist.get_rank()}: {tensor}&quot;)
    
init_process()
example_all_reduce()
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>输出</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>Before all_reduce on rank 0: tensor([1., 1., 1., 1., 1.], device=&#39;cuda:0&#39;)
Before all_reduce on rank 1: tensor([2., 2., 2., 2., 2.], device=&#39;cuda:1&#39;)
Before all_reduce on rank 2: tensor([3., 3., 3., 3., 3.], device=&#39;cuda:2&#39;)

After all_reduce on rank 0: tensor([6., 6., 6., 6., 6.], device=&#39;cuda:0&#39;)
After all_reduce on rank 1: tensor([6., 6., 6., 6., 6.], device=&#39;cuda:1&#39;)
After all_reduce on rank 2: tensor([6., 6., 6., 6., 6.], device=&#39;cuda:2&#39;)
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_7-5-gather" tabindex="-1"><a class="header-anchor" href="#_7-5-gather" aria-hidden="true">#</a> 7.5. Gather</h3><p>代码</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>def example_gather():
    tensor = torch.tensor([dist.get_rank() + 1] * 5, dtype=torch.float32).cuda()
    if dist.get_rank() == 0:
        gather_list = [
            torch.zeros(5, dtype=torch.float32).cuda()
            for _ in range(dist.get_world_size())
            ]
    else:
        gather_list = None
    print(f&quot;Before gather on rank {dist.get_rank()}: {tensor}&quot;)
    dist.gather(tensor, gather_list, dst=0)
    if dist.get_rank() == 0:
        print(f&quot;After gather on rank 0: {gather_list}&quot;)
    
init_process()
example_gather()
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>输出</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>Before gather on rank 0: tensor([1., 1., 1., 1., 1.], device=&#39;cuda:0&#39;)
Before gather on rank 1: tensor([2., 2., 2., 2., 2.], device=&#39;cuda:1&#39;)
Before gather on rank 2: tensor([3., 3., 3., 3., 3.], device=&#39;cuda:2&#39;)

After gather on rank 0: [tensor([1., 1., 1., 1., 1.], device=&#39;cuda:0&#39;),
                         tensor([2., 2., 2., 2., 2.], device=&#39;cuda:0&#39;),
                         tensor([3., 3., 3., 3., 3.], device=&#39;cuda:0&#39;)]
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_7-6-allgather" tabindex="-1"><a class="header-anchor" href="#_7-6-allgather" aria-hidden="true">#</a> 7.6. AllGather</h3><p>代码</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>def example_all_gather():
    tensor = torch.tensor([dist.get_rank() + 1] * 5, dtype=torch.float32).cuda()
    gather_list = [
        torch.zeros(5, dtype=torch.float32).cuda()
        for _ in range(dist.get_world_size())
        ]
    print(f&quot;Before all_gather on rank {dist.get_rank()}: {tensor}&quot;)
    dist.all_gather(gather_list, tensor)
    print(f&quot;After all_gather on rank {dist.get_rank()}: {gather_list}&quot;)
    
init_process()
example_all_gather()
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>输出</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>Before all_gather on rank 0: tensor([1., 1., 1., 1., 1.], device=&#39;cuda:0&#39;)
Before all_gather on rank 1: tensor([2., 2., 2., 2., 2.], device=&#39;cuda:1&#39;)
Before all_gather on rank 2: tensor([3., 3., 3., 3., 3.], device=&#39;cuda:2&#39;)

After all_gather on rank 0: [tensor([1., 1., 1., 1., 1.], device=&#39;cuda:0&#39;),
                             tensor([2., 2., 2., 2., 2.], device=&#39;cuda:0&#39;),
                             tensor([3., 3., 3., 3., 3.], device=&#39;cuda:0&#39;)]
After all_gather on rank 1: [tensor([1., 1., 1., 1., 1.], device=&#39;cuda:1&#39;),
                             tensor([2., 2., 2., 2., 2.], device=&#39;cuda:0&#39;),
                             tensor([3., 3., 3., 3., 3.], device=&#39;cuda:0&#39;)]
After all_gather on rank 2: [tensor([1., 1., 1., 1., 1.], device=&#39;cuda:2&#39;),
                             tensor([2., 2., 2., 2., 2.], device=&#39;cuda:2&#39;),
                             tensor([3., 3., 3., 3., 3.], device=&#39;cuda:2&#39;)]
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_7-7-scatter" tabindex="-1"><a class="header-anchor" href="#_7-7-scatter" aria-hidden="true">#</a> 7.7. Scatter</h3><p>代码</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>def example_scatter():
    if dist.get_rank() == 0:
        scatter_list = [
            torch.tensor([i + 1] * 5, dtype=torch.float32).cuda()
            for i in range(dist.get_world_size())
            ]
        print(f&quot;Rank 0: Tensor to scatter: {scatter_list}&quot;)
    else:
        scatter_list = None
    tensor = torch.zeros(5, dtype=torch.float32).cuda()
    print(f&quot;Before scatter on rank {dist.get_rank()}: {tensor}&quot;)
    dist.scatter(tensor, scatter_list, src=0)
    print(f&quot;After scatter on rank {dist.get_rank()}: {tensor}&quot;)
    
init_process()
example_scatter()
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>输出</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>Rank 0: Tensor to scatter: [tensor([1., 1., 1., 1., 1.], device=&#39;cuda:0&#39;),
                            tensor([2., 2., 2., 2., 2.], device=&#39;cuda:0&#39;),
                            tensor([3., 3., 3., 3., 3.], device=&#39;cuda:0&#39;)]
Before scatter on rank 0: tensor([0., 0., 0., 0., 0.], device=&#39;cuda:0&#39;)
Before scatter on rank 1: tensor([0., 0., 0., 0., 0.], device=&#39;cuda:1&#39;)
Before scatter on rank 2: tensor([0., 0., 0., 0., 0.], device=&#39;cuda:2&#39;)

After scatter on rank 0: tensor([1., 1., 1., 1., 1.], device=&#39;cuda:0&#39;)
After scatter on rank 1: tensor([2., 2., 2., 2., 2.], device=&#39;cuda:1&#39;)
After scatter on rank 2: tensor([3., 3., 3., 3., 3.], device=&#39;cuda:2&#39;)
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_7-8-reducescatter" tabindex="-1"><a class="header-anchor" href="#_7-8-reducescatter" aria-hidden="true">#</a> 7.8. ReduceScatter</h3><p>代码</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>def example_reduce_scatter():
    rank = dist.get_rank()
    world_size = dist.get_world_size()
    input_tensor = [
        torch.tensor([(rank + 1) * i for i in range(1, 3)], dtype=torch.float32).cuda()**(j+1) 
        for j in range(world_size)
        ]
    output_tensor = torch.zeros(2, dtype=torch.float32).cuda()
    print(f&quot;Before ReduceScatter on rank {rank}: {input_tensor}&quot;)
    dist.reduce_scatter(output_tensor, input_tensor, op=dist.ReduceOp.SUM)
    print(f&quot;After ReduceScatter on rank {rank}: {output_tensor}&quot;)    
    
init_process()
example_reduce_scatter()
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>输出</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>Before ReduceScatter on rank 0: [tensor([1., 2.], device=&#39;cuda:0&#39;),
											 tensor([1., 4.], device=&#39;cuda:0&#39;),
											 tensor([1., 8.], device=&#39;cuda:0&#39;)]
Before ReduceScatter on rank 1: [tensor([2., 4.], device=&#39;cuda:1&#39;),
                                 tensor([ 4., 16.], device=&#39;cuda:1&#39;),
                                 tensor([ 8., 64.], device=&#39;cuda:1&#39;)]
Before ReduceScatter on rank 2: [tensor([3., 6.], device=&#39;cuda:2&#39;),
                                 tensor([ 9., 36.], device=&#39;cuda:2&#39;),
                                 tensor([ 27., 216.], device=&#39;cuda:2&#39;)]

After ReduceScatter on rank 0: tensor([ 6., 12.], device=&#39;cuda:0&#39;)
After ReduceScatter on rank 1: tensor([14., 56.], device=&#39;cuda:1&#39;)
After ReduceScatter on rank 2: tensor([ 36., 288.], device=&#39;cuda:2&#39;)
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_7-9-barrier" tabindex="-1"><a class="header-anchor" href="#_7-9-barrier" aria-hidden="true">#</a> 7.9. Barrier</h3><p>代码</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>def example_barrier():
    rank = dist.get_rank()
    t_start = time.time()
    print(f&quot;Rank {rank} sleeps {rank} seconds.&quot;)
    time.sleep(rank)  # Simulate different processing times
    dist.barrier()
    print(f&quot;Rank {rank} after barrier time delta: {time.time()-t_start:.4f}&quot;)
    
init_process()
example_barrier()
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>输出</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>Rank 0 sleeps 0 seconds.
Rank 1 sleeps 1 seconds.
Rank 2 sleeps 2 seconds.

Rank 0 after barrier time delta: 2.0025
Rank 1 after barrier time delta: 2.0025
Rank 2 after barrier time delta: 2.0024
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></div><!--[--><!----><!--]--><footer class="page-meta"><!----><div class="meta-item git-info"><!----><!----></div></footer><nav class="vp-page-nav"><a aria-label="分布式训练之三：数据并行 Data Parallelism" class="vp-link nav-link prev nav-link prev" href="/blog/zh/posts/llm/026_distribution_and_parallelism_2.html"><div class="hint"><span class="arrow start"></span>上一页</div><div class="link"><span class="font-icon icon fa-fw fa-sm fas fa-lightbulb" style=""></span>分布式训练之三：数据并行 Data Parallelism</div></a><a aria-label="分布式训练之一：模型训练的内存占用" class="vp-link nav-link next nav-link next" href="/blog/zh/posts/llm/024_distribution_and_parallelism.html"><div class="hint">下一页<span class="arrow end"></span></div><div class="link">分布式训练之一：模型训练的内存占用<span class="font-icon icon fa-fw fa-sm fas fa-lightbulb" style=""></span></div></a></nav><!----><!--[--><!----><!--]--><!--]--></main><!--]--><!----></div><!--]--><!--]--><!----><!--]--></div>
    <script type="module" src="/blog/assets/app-RtLkXOlm.js" defer></script>
  </body>
</html>
