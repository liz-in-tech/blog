<!doctype html>
<html lang="zh-CN" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.0" />
    <meta name="theme" content="VuePress Theme Hope 2.0.0-rc.13" />
    <style>
      html {
        background: var(--bg-color, #fff);
      }

      html[data-theme="dark"] {
        background: var(--bg-color, #1d1e1f);
      }

      body {
        background: var(--bg-color);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <link rel="alternate" hreflang="en-us" href="https://liz-in-tech.github.io/blog/posts/llm/031_qlora.html"><meta property="og:url" content="https://liz-in-tech.github.io/blog/zh/posts/llm/031_qlora.html"><meta property="og:site_name" content="Liz"><meta property="og:title" content="QLoRA ä»£ç å®ç°åŠè¿‡ç¨‹åˆ†æ"><meta property="og:description" content="QLoRA ä»£ç å®ç°åŠè¿‡ç¨‹åˆ†æ èƒŒæ™¯ä»‹ç»: QLoRA/åŸºç¡€æ¨¡å‹/æ•°æ®é›† QLoRA ä»£ç å®ç° QLoRA è¿‡ç¨‹åˆ†æ QLoRA åº”ç”¨ä»·å€¼ QLoRA ç–‘ç‚¹æ€è€ƒ QLoRA ç»†èŠ‚è¡¥å……"><meta property="og:type" content="article"><meta property="og:locale" content="zh-CN"><meta property="og:locale:alternate" content="en-US"><meta property="og:updated_time" content="2025-04-10T08:01:20.000Z"><meta property="article:author" content="Liz"><meta property="article:tag" content="QLoRA"><meta property="article:published_time" content="2025-04-08T00:00:00.000Z"><meta property="article:modified_time" content="2025-04-10T08:01:20.000Z"><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"QLoRA ä»£ç å®ç°åŠè¿‡ç¨‹åˆ†æ","image":[""],"datePublished":"2025-04-08T00:00:00.000Z","dateModified":"2025-04-10T08:01:20.000Z","author":[{"@type":"Person","name":"Liz","url":"https://github.com/liz-in-tech"}]}</script><link rel="icon" herf="/blogger.png"><link rel="icon" href="/blog/blogger.png"><title>QLoRA ä»£ç å®ç°åŠè¿‡ç¨‹åˆ†æ | Liz</title><meta name="description" content="QLoRA ä»£ç å®ç°åŠè¿‡ç¨‹åˆ†æ èƒŒæ™¯ä»‹ç»: QLoRA/åŸºç¡€æ¨¡å‹/æ•°æ®é›† QLoRA ä»£ç å®ç° QLoRA è¿‡ç¨‹åˆ†æ QLoRA åº”ç”¨ä»·å€¼ QLoRA ç–‘ç‚¹æ€è€ƒ QLoRA ç»†èŠ‚è¡¥å……">
    <link rel="preload" href="/blog/assets/style-m_obra2h.css" as="style"><link rel="stylesheet" href="/blog/assets/style-m_obra2h.css">
    <link rel="modulepreload" href="/blog/assets/app-kXW_Y_m4.js"><link rel="modulepreload" href="/blog/assets/031_qlora.html-fQEUG9mQ.js"><link rel="modulepreload" href="/blog/assets/plugin-vue_export-helper-x3n3nnut.js"><link rel="modulepreload" href="/blog/assets/031_qlora.html-vUUfqpgA.js">
    <link rel="prefetch" href="/blog/assets/index.html-YbPtte5_.js" as="script"><link rel="prefetch" href="/blog/assets/intro.html-CGfhr1vY.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-FUMOuem4.js" as="script"><link rel="prefetch" href="/blog/assets/index.html--TTjrkIy.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-g4Nfr7z1.js" as="script"><link rel="prefetch" href="/blog/assets/intro.html-bitGHKd2.js" as="script"><link rel="prefetch" href="/blog/assets/001_langchain.html-pCFuhYHy.js" as="script"><link rel="prefetch" href="/blog/assets/002_langchain_sourcecode.html-0dULq4fV.js" as="script"><link rel="prefetch" href="/blog/assets/003_streamlit.html-rU-ICBCx.js" as="script"><link rel="prefetch" href="/blog/assets/004_transformer.html-rVimVVvM.js" as="script"><link rel="prefetch" href="/blog/assets/005_llama.html-PPnfWd5A.js" as="script"><link rel="prefetch" href="/blog/assets/006_llm_leaderboard.html-IMCQYiuX.js" as="script"><link rel="prefetch" href="/blog/assets/007_computer_use.html-NXAgxCZc.js" as="script"><link rel="prefetch" href="/blog/assets/008_rag_challenge.html-2XihIpNV.js" as="script"><link rel="prefetch" href="/blog/assets/009_llm_challenge.html-c_OZVW4n.js" as="script"><link rel="prefetch" href="/blog/assets/010_rag_workflow.html-VAQDBYt1.js" as="script"><link rel="prefetch" href="/blog/assets/011_vector_database.html-lYSX4LTx.js" as="script"><link rel="prefetch" href="/blog/assets/012_prompt_engineering.html-UWcw4rK7.js" as="script"><link rel="prefetch" href="/blog/assets/013_optimizing_llm.html-6CxOIR84.js" as="script"><link rel="prefetch" href="/blog/assets/014_rag_evaluation.html-GIu-oGwK.js" as="script"><link rel="prefetch" href="/blog/assets/015_fine_tune.html-dGpakwon.js" as="script"><link rel="prefetch" href="/blog/assets/016_multimodal.html-rrs6OqYq.js" as="script"><link rel="prefetch" href="/blog/assets/017_agent_and_multiagent.html-tCPGJV8e.js" as="script"><link rel="prefetch" href="/blog/assets/018_huggingface.html-xa6dHS9r.js" as="script"><link rel="prefetch" href="/blog/assets/019_ollama.html-plb_Orn6.js" as="script"><link rel="prefetch" href="/blog/assets/020_neo4j.html-a2aBhY6q.js" as="script"><link rel="prefetch" href="/blog/assets/021_microsoft_graphrag.html-oPHcVCmi.js" as="script"><link rel="prefetch" href="/blog/assets/022_llamaindex_graphrag.html-h0RgV0s1.js" as="script"><link rel="prefetch" href="/blog/assets/023_agent_framework.html-py7Qkdf7.js" as="script"><link rel="prefetch" href="/blog/assets/024_distribution_and_parallelism.html-CKC7PrZL.js" as="script"><link rel="prefetch" href="/blog/assets/025_distribution_and_parallelism_1.html-beQNseCy.js" as="script"><link rel="prefetch" href="/blog/assets/026_distribution_and_parallelism_2.html-6kfObp4n.js" as="script"><link rel="prefetch" href="/blog/assets/027_distribution_and_parallelism_3.html-jqwUVAB8.js" as="script"><link rel="prefetch" href="/blog/assets/028_distribution_and_parallelism_4.html-P64lj0UC.js" as="script"><link rel="prefetch" href="/blog/assets/029_unsloth_grpo.html-1JeKlSnS.js" as="script"><link rel="prefetch" href="/blog/assets/030_wandb.html-WMD5mJL9.js" as="script"><link rel="prefetch" href="/blog/assets/031_qlora.html-JOYVOncP.js" as="script"><link rel="prefetch" href="/blog/assets/032_sft_trainer_sourcecode_prepare_model.html-zHdm8hdr.js" as="script"><link rel="prefetch" href="/blog/assets/033_sft_trainer_sourcecode_prepare_dataset.html-q1ngNI0S.js" as="script"><link rel="prefetch" href="/blog/assets/034_sft_trainer_sourcecode_prepare_trainer.html-R_OJ2ypq.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ZDCSnlc1.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ZYw6WxxA.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-OavE9BET.js" as="script"><link rel="prefetch" href="/blog/assets/001_langchain.html-tEkJTRMy.js" as="script"><link rel="prefetch" href="/blog/assets/002_langchain_sourcecode.html-Cf9F-5tQ.js" as="script"><link rel="prefetch" href="/blog/assets/003_streamlit.html-HjDyRBtK.js" as="script"><link rel="prefetch" href="/blog/assets/004_transformer.html-LcEZruqw.js" as="script"><link rel="prefetch" href="/blog/assets/005_llama.html-RH03PuTh.js" as="script"><link rel="prefetch" href="/blog/assets/006_llm_leaderboard.html-oHc2EEDF.js" as="script"><link rel="prefetch" href="/blog/assets/007_computer_use.html-9uep80On.js" as="script"><link rel="prefetch" href="/blog/assets/008_rag_challenge.html-n6JQ6oC1.js" as="script"><link rel="prefetch" href="/blog/assets/009_llm_challenge.html-xfwZXlYi.js" as="script"><link rel="prefetch" href="/blog/assets/010_rag_workflow.html-bgEctrLI.js" as="script"><link rel="prefetch" href="/blog/assets/011_vector_database.html-1VYu1fJ-.js" as="script"><link rel="prefetch" href="/blog/assets/012_prompt_engineering.html-tWg28gSw.js" as="script"><link rel="prefetch" href="/blog/assets/013_optimizing_llm.html-W-CdR_ck.js" as="script"><link rel="prefetch" href="/blog/assets/014_rag_evaluation.html-QoGrIyLb.js" as="script"><link rel="prefetch" href="/blog/assets/015_fine_tune.html-B8-mxmmH.js" as="script"><link rel="prefetch" href="/blog/assets/016_multimodal.html-wKLzc0PX.js" as="script"><link rel="prefetch" href="/blog/assets/017_agent_and_multiagent.html-oSXpre05.js" as="script"><link rel="prefetch" href="/blog/assets/018_huggingface.html-z4dUNzIp.js" as="script"><link rel="prefetch" href="/blog/assets/019_ollama.html-BEfb0F5v.js" as="script"><link rel="prefetch" href="/blog/assets/020_neo4j.html-Ss2gFNbK.js" as="script"><link rel="prefetch" href="/blog/assets/021_microsoft_graphrag.html-i7xll12O.js" as="script"><link rel="prefetch" href="/blog/assets/022_llamaindex_graphrag.html-SaWe1p9V.js" as="script"><link rel="prefetch" href="/blog/assets/023_agent_framework.html-SPruHtsV.js" as="script"><link rel="prefetch" href="/blog/assets/024_distribution_and_parallelism.html-7h-MA_ID.js" as="script"><link rel="prefetch" href="/blog/assets/025_distribution_and_parallelism_1.html-L8sqluO4.js" as="script"><link rel="prefetch" href="/blog/assets/026_distribution_and_parallelism_2.html-unSOw2um.js" as="script"><link rel="prefetch" href="/blog/assets/027_distribution_and_parallelism_3.html-lLxN0up_.js" as="script"><link rel="prefetch" href="/blog/assets/028_distribution_and_parallelism_4.html-J-NQUUQ-.js" as="script"><link rel="prefetch" href="/blog/assets/029_unsloth_grpo.html-BWNBotHO.js" as="script"><link rel="prefetch" href="/blog/assets/030_wandb.html-K-PdjuDZ.js" as="script"><link rel="prefetch" href="/blog/assets/032_sft_trainer_sourcecode_prepare_model.html-1k2dTbN6.js" as="script"><link rel="prefetch" href="/blog/assets/033_sft_trainer_sourcecode_prepare_dataset.html-yXer_-iN.js" as="script"><link rel="prefetch" href="/blog/assets/034_sft_trainer_sourcecode_prepare_trainer.html-dD57N9_q.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-wh_dBtOR.js" as="script"><link rel="prefetch" href="/blog/assets/404.html-cxLWDy2T.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-kf4JCRaf.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-RkA-insV.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-4kI_oqSd.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-WhuidxNt.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-OqGkeUA_.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-5GeN-sdD.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-c4Rf4yh1.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-2r0jUs7o.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-BSKRXRQc.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-KjTsJ0Hg.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-TteIwMx3.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-g00XXzrL.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-YxbJgo4L.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-3T79Cy0i.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-A5tlQHan.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-04ff5e0O.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-vgZ6rfFh.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-OmipPplE.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-E1KrJL6a.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-oPH9QkTj.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-cHRqZSs8.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-74SU9ZTn.js" as="script"><link rel="prefetch" href="/blog/assets/index.html--iJiA8oX.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-oZPWb_Fc.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-FUIWSLsp.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-5ERWyusD.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Zjn0JNqd.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-jcvPTrgB.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-9t2TsyuQ.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-CcLVFNIv.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-DVoYOOaL.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-V52ipvRm.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-9If_KW0o.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-df9Mrf2R.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-f9bWoKcO.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-GYH0QUoo.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-JVTfeijx.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-_C1QVNqX.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-L_IXFmna.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-nZWHmXY7.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-x4gPgqE4.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-bWnVyuyA.js" as="script"><link rel="prefetch" href="/blog/assets/index.html--yTU23ka.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-tRnpyzfw.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-7aypos-L.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-1BXcbV1R.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-pu478WKz.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-DFi1VhMA.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-7uaSljkV.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-BULhD4SJ.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-i7RIA9-O.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-NNpPPGUU.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-LHukpLS7.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-howjHe2f.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-DeN_iOWx.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-cnlzR0a7.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-0P_c_pcU.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-dy_CcFmq.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-FzFytZ_p.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-2KSwV7xp.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-F1coElwg.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ffflqCb9.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-F8ZuLYgH.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-HeYWaFeL.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-xKYeJEc5.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-xB-iS7Ql.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-OEUPqfTV.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-EE4iQI9m.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-g1PUF_BG.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-nUBcs85a.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-9Y3la5Sf.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-wufIFDPM.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-bXZQIxRE.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-wd6ZkEHi.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Xlk0AXmC.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Uv7c7pYa.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-FfZqC9tZ.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-mSPhZxqB.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-51HoKD5A.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Q5_K6Vux.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-jkWPo860.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-kTEqch5G.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-y4iBqBqc.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ibHhI9SI.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-3hk_s27_.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-QJ9j3Zl2.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-QvWFHL99.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Pefl6i_g.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-dNHrcQzx.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-tITHrBRq.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-r_IMIQdZ.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-FFF0RGO4.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-9IXcskQt.js" as="script"><link rel="prefetch" href="/blog/assets/index.html--vv6JGdg.js" as="script"><link rel="prefetch" href="/blog/assets/intro.html-YvsAdYxx.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-eb3rY0JS.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-mySahdpU.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-b9L3Yulv.js" as="script"><link rel="prefetch" href="/blog/assets/intro.html-1rtPqIag.js" as="script"><link rel="prefetch" href="/blog/assets/001_langchain.html-u0RDenox.js" as="script"><link rel="prefetch" href="/blog/assets/002_langchain_sourcecode.html-WatFl6W7.js" as="script"><link rel="prefetch" href="/blog/assets/003_streamlit.html-jtSVjIgP.js" as="script"><link rel="prefetch" href="/blog/assets/004_transformer.html-9gOECARp.js" as="script"><link rel="prefetch" href="/blog/assets/005_llama.html-y7jJcJ9i.js" as="script"><link rel="prefetch" href="/blog/assets/006_llm_leaderboard.html-Nm0wyQhM.js" as="script"><link rel="prefetch" href="/blog/assets/007_computer_use.html-t0wOZl_C.js" as="script"><link rel="prefetch" href="/blog/assets/008_rag_challenge.html-XVsVvL4j.js" as="script"><link rel="prefetch" href="/blog/assets/009_llm_challenge.html-NxAiW0a6.js" as="script"><link rel="prefetch" href="/blog/assets/010_rag_workflow.html-R9FUmgH-.js" as="script"><link rel="prefetch" href="/blog/assets/011_vector_database.html-wQT5qFnh.js" as="script"><link rel="prefetch" href="/blog/assets/012_prompt_engineering.html-6JEjQ-kc.js" as="script"><link rel="prefetch" href="/blog/assets/013_optimizing_llm.html-Hj-oim2-.js" as="script"><link rel="prefetch" href="/blog/assets/014_rag_evaluation.html-342TIWnM.js" as="script"><link rel="prefetch" href="/blog/assets/015_fine_tune.html-nSVN6FoD.js" as="script"><link rel="prefetch" href="/blog/assets/016_multimodal.html-n1S4D29K.js" as="script"><link rel="prefetch" href="/blog/assets/017_agent_and_multiagent.html-qO9GAGXk.js" as="script"><link rel="prefetch" href="/blog/assets/018_huggingface.html-O5p-7ZP4.js" as="script"><link rel="prefetch" href="/blog/assets/019_ollama.html-wjeXoczl.js" as="script"><link rel="prefetch" href="/blog/assets/020_neo4j.html-ANtI9KHv.js" as="script"><link rel="prefetch" href="/blog/assets/021_microsoft_graphrag.html-cztMBRXf.js" as="script"><link rel="prefetch" href="/blog/assets/022_llamaindex_graphrag.html-hxfazdpU.js" as="script"><link rel="prefetch" href="/blog/assets/023_agent_framework.html-TNE_e7Ko.js" as="script"><link rel="prefetch" href="/blog/assets/024_distribution_and_parallelism.html-2250dNkH.js" as="script"><link rel="prefetch" href="/blog/assets/025_distribution_and_parallelism_1.html-XZUCp34v.js" as="script"><link rel="prefetch" href="/blog/assets/026_distribution_and_parallelism_2.html-chQN8UEq.js" as="script"><link rel="prefetch" href="/blog/assets/027_distribution_and_parallelism_3.html-0Uoi9GcL.js" as="script"><link rel="prefetch" href="/blog/assets/028_distribution_and_parallelism_4.html-gfN4lwG1.js" as="script"><link rel="prefetch" href="/blog/assets/029_unsloth_grpo.html-yTNsmKtu.js" as="script"><link rel="prefetch" href="/blog/assets/030_wandb.html-5ubs6DMV.js" as="script"><link rel="prefetch" href="/blog/assets/031_qlora.html-SoizIESE.js" as="script"><link rel="prefetch" href="/blog/assets/032_sft_trainer_sourcecode_prepare_model.html-APTXTm8o.js" as="script"><link rel="prefetch" href="/blog/assets/033_sft_trainer_sourcecode_prepare_dataset.html-RoUISmX5.js" as="script"><link rel="prefetch" href="/blog/assets/034_sft_trainer_sourcecode_prepare_trainer.html-n3BuAGze.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-m0ANQlb1.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-6NYkVY7P.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-VWh-VMRn.js" as="script"><link rel="prefetch" href="/blog/assets/001_langchain.html-jR7MnvbH.js" as="script"><link rel="prefetch" href="/blog/assets/002_langchain_sourcecode.html-QnvaYX8S.js" as="script"><link rel="prefetch" href="/blog/assets/003_streamlit.html-yvvRwshv.js" as="script"><link rel="prefetch" href="/blog/assets/004_transformer.html-lD-gg3r4.js" as="script"><link rel="prefetch" href="/blog/assets/005_llama.html-cJJfpF1E.js" as="script"><link rel="prefetch" href="/blog/assets/006_llm_leaderboard.html-ZNgRpXeA.js" as="script"><link rel="prefetch" href="/blog/assets/007_computer_use.html-olgphtpX.js" as="script"><link rel="prefetch" href="/blog/assets/008_rag_challenge.html-qnP9y6an.js" as="script"><link rel="prefetch" href="/blog/assets/009_llm_challenge.html-CN4Qdfzf.js" as="script"><link rel="prefetch" href="/blog/assets/010_rag_workflow.html-t5n89ijV.js" as="script"><link rel="prefetch" href="/blog/assets/011_vector_database.html-Ext8qBK4.js" as="script"><link rel="prefetch" href="/blog/assets/012_prompt_engineering.html-DgFmhAmz.js" as="script"><link rel="prefetch" href="/blog/assets/013_optimizing_llm.html-V8RwrYtw.js" as="script"><link rel="prefetch" href="/blog/assets/014_rag_evaluation.html-8gnsrekE.js" as="script"><link rel="prefetch" href="/blog/assets/015_fine_tune.html-P6p3N9FU.js" as="script"><link rel="prefetch" href="/blog/assets/016_multimodal.html-JunLNeNq.js" as="script"><link rel="prefetch" href="/blog/assets/017_agent_and_multiagent.html-HxOtf7NJ.js" as="script"><link rel="prefetch" href="/blog/assets/018_huggingface.html-jZau-Rer.js" as="script"><link rel="prefetch" href="/blog/assets/019_ollama.html-snxKNrOO.js" as="script"><link rel="prefetch" href="/blog/assets/020_neo4j.html-d843Oc_u.js" as="script"><link rel="prefetch" href="/blog/assets/021_microsoft_graphrag.html-OB6BrwMG.js" as="script"><link rel="prefetch" href="/blog/assets/022_llamaindex_graphrag.html-piyaZZMv.js" as="script"><link rel="prefetch" href="/blog/assets/023_agent_framework.html-Db4bujEY.js" as="script"><link rel="prefetch" href="/blog/assets/024_distribution_and_parallelism.html-gz26Lwy_.js" as="script"><link rel="prefetch" href="/blog/assets/025_distribution_and_parallelism_1.html-U1AbCk1f.js" as="script"><link rel="prefetch" href="/blog/assets/026_distribution_and_parallelism_2.html-Lcr0R0BX.js" as="script"><link rel="prefetch" href="/blog/assets/027_distribution_and_parallelism_3.html-V0xT7zv-.js" as="script"><link rel="prefetch" href="/blog/assets/028_distribution_and_parallelism_4.html-tlVKPUH9.js" as="script"><link rel="prefetch" href="/blog/assets/029_unsloth_grpo.html--YdolqUA.js" as="script"><link rel="prefetch" href="/blog/assets/030_wandb.html-ydOOp5Wd.js" as="script"><link rel="prefetch" href="/blog/assets/032_sft_trainer_sourcecode_prepare_model.html-Twac33Fz.js" as="script"><link rel="prefetch" href="/blog/assets/033_sft_trainer_sourcecode_prepare_dataset.html-NlOuqPei.js" as="script"><link rel="prefetch" href="/blog/assets/034_sft_trainer_sourcecode_prepare_trainer.html-sWIk8upS.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-f256oXCe.js" as="script"><link rel="prefetch" href="/blog/assets/404.html-_ynXrPVJ.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-KpiV2RZz.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Gl6JFTdW.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-S86WhvAg.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-0g2T9BBe.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-8VfnHEti.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-V13AKav4.js" as="script"><link rel="prefetch" href="/blog/assets/index.html--0znw6Jg.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-rUDgnkod.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Ixtz_6gm.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-8tqIo_Lg.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-MZjAI5Ua.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-yy_XHxVn.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-xxChQGkq.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-0X96kPbJ.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-TVlZkaii.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ib-1P8D-.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Yfp0ZYQ2.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-wV_rTQOo.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-BmwFcS5I.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-WPhR4yZO.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-1AuLEwQS.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-t5JEzQSr.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Iu8R6uJH.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Wn8ixjAY.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Ki18f85e.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-WjefiZt5.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-63xcNFpn.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-qs0qFF3o.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-j0fApRBn.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-7nh-_nZc.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-4iOdijQ-.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-TTnq10vf.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ITvv5s67.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-MLj0stui.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-lflu9wkH.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-uXsg2Qms.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Vk5N7WSy.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-nSZN_e3l.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-2mvev2Dv.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-_sQvIyGu.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-7fq0Vgi2.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-yy6Hfbps.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-1euV8Kyn.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-QFnJJUPx.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-bKw0s3tH.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-YglVXsq6.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-LTj1tjv7.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-tjrWLtoj.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ij3lqDMP.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-_olKXUI2.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-6HWH81DY.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-jqbSHvu_.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-DSVuec5V.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-etKhx9jx.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-LblJcp8D.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-sKp0rMKu.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-oFfN1H8M.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Wj1Ml6_D.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-hy7JS5_M.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-46xlHXXB.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-eJwc_Sty.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-jhvadMVJ.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-V0i6juId.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-dsZvhGqF.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-t6Rda_m2.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-bJEZ4q4k.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-i2VN5SxX.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-XzyKaecF.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-TtNUL7su.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Feg0AZzF.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-87rl9up6.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-paP6q3A6.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-C0NU7zNv.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-AyZe6Vnz.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ZKBCLERe.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-QWjjGYjF.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-TjxS4F0D.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-c8l9SA_F.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Miisefi3.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Hcx1AKtm.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Yx9Gv2HW.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Gs7gohuD.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-pfgkam3J.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-nokndBo_.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-e82V4ede.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-iAbJDWKb.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-vCEw4W4i.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-xM1AdLMf.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-yw3VVVGg.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-XOoPS9Dm.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-lx1h2lJu.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-VFSaxyAl.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-VFnMz1F0.js" as="script"><link rel="prefetch" href="/blog/assets/photoswipe.esm-08_zHRDQ.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">è·³è‡³ä¸»è¦å…§å®¹</a><!--]--><!--[--><div class="theme-container no-sidebar has-toc"><!--[--><header id="navbar" class="vp-navbar"><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!--[--><!----><!--]--><!--[--><a class="vp-link vp-brand vp-brand" href="/blog/zh/"><img class="vp-nav-logo" src="/blog/blogger.png" alt><!----><span class="vp-site-name hide-in-pad">Liz</span></a><!--]--><!--[--><!----><!--]--></div><div class="vp-navbar-center"><!--[--><!----><!--]--><!--[--><nav class="vp-nav-links"><div class="nav-item hide-in-mobile"><a aria-label="é¦–é¡µ" class="vp-link nav-link nav-link" href="/blog/zh/"><span class="font-icon icon fa-fw fa-sm fas fa-home" style=""></span>é¦–é¡µ<!----></a></div><div class="nav-item hide-in-mobile"><a aria-label="é¡¹ç›®" class="vp-link nav-link nav-link" href="/blog/zh/demo/"><span class="font-icon icon fa-fw fa-sm fas fa-star" style=""></span>é¡¹ç›®<!----></a></div></nav><!--]--><!--[--><!----><!--]--></div><div class="vp-navbar-end"><!--[--><!----><!--]--><!--[--><div class="nav-item"><div class="dropdown-wrapper i18n-dropdown"><button type="button" class="dropdown-title" aria-label="é€‰æ‹©è¯­è¨€"><!--[--><svg xmlns="http://www.w3.org/2000/svg" class="icon i18n-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="i18n icon" style="width:1rem;height:1rem;vertical-align:middle;"><path d="M379.392 460.8 494.08 575.488l-42.496 102.4L307.2 532.48 138.24 701.44l-71.68-72.704L234.496 460.8l-45.056-45.056c-27.136-27.136-51.2-66.56-66.56-108.544h112.64c7.68 14.336 16.896 27.136 26.112 35.84l45.568 46.08 45.056-45.056C382.976 312.32 409.6 247.808 409.6 204.8H0V102.4h256V0h102.4v102.4h256v102.4H512c0 70.144-37.888 161.28-87.04 210.944L378.88 460.8zM576 870.4 512 1024H409.6l256-614.4H768l256 614.4H921.6l-64-153.6H576zM618.496 768h196.608L716.8 532.48 618.496 768z"></path></svg><!--]--><span class="arrow"></span><ul class="nav-dropdown"><li class="dropdown-item"><a aria-label="English" class="vp-link nav-link nav-link" href="/blog/posts/llm/031_qlora.html"><!---->English<!----></a></li><li class="dropdown-item"><a aria-label="ç®€ä½“ä¸­æ–‡" class="vp-link nav-link active nav-link active" href="/blog/zh/posts/llm/031_qlora.html"><!---->ç®€ä½“ä¸­æ–‡<!----></a></li></ul></button></div></div><div class="nav-item vp-repo"><a class="vp-repo-link" href="https://github.com/liz-in-tech" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><div class="nav-item hide-in-mobile"><button type="button" id="appearance-switch"><svg xmlns="http://www.w3.org/2000/svg" class="icon auto-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="auto icon" style="display:block;"><path d="M512 992C246.92 992 32 777.08 32 512S246.92 32 512 32s480 214.92 480 480-214.92 480-480 480zm0-840c-198.78 0-360 161.22-360 360 0 198.84 161.22 360 360 360s360-161.16 360-360c0-198.78-161.22-360-360-360zm0 660V212c165.72 0 300 134.34 300 300 0 165.72-134.28 300-300 300z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon dark-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="dark icon" style="display:none;"><path d="M524.8 938.667h-4.267a439.893 439.893 0 0 1-313.173-134.4 446.293 446.293 0 0 1-11.093-597.334A432.213 432.213 0 0 1 366.933 90.027a42.667 42.667 0 0 1 45.227 9.386 42.667 42.667 0 0 1 10.24 42.667 358.4 358.4 0 0 0 82.773 375.893 361.387 361.387 0 0 0 376.747 82.774 42.667 42.667 0 0 1 54.187 55.04 433.493 433.493 0 0 1-99.84 154.88 438.613 438.613 0 0 1-311.467 128z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon light-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="light icon" style="display:none;"><path d="M952 552h-80a40 40 0 0 1 0-80h80a40 40 0 0 1 0 80zM801.88 280.08a41 41 0 0 1-57.96-57.96l57.96-58a41.04 41.04 0 0 1 58 58l-58 57.96zM512 752a240 240 0 1 1 0-480 240 240 0 0 1 0 480zm0-560a40 40 0 0 1-40-40V72a40 40 0 0 1 80 0v80a40 40 0 0 1-40 40zm-289.88 88.08-58-57.96a41.04 41.04 0 0 1 58-58l57.96 58a41 41 0 0 1-57.96 57.96zM192 512a40 40 0 0 1-40 40H72a40 40 0 0 1 0-80h80a40 40 0 0 1 40 40zm30.12 231.92a41 41 0 0 1 57.96 57.96l-57.96 58a41.04 41.04 0 0 1-58-58l58-57.96zM512 832a40 40 0 0 1 40 40v80a40 40 0 0 1-80 0v-80a40 40 0 0 1 40-40zm289.88-88.08 58 57.96a41.04 41.04 0 0 1-58 58l-57.96-58a41 41 0 0 1 57.96-57.96z"></path></svg></button></div><form class="search-box" role="search"><input type="search" placeholder="æœç´¢" autocomplete="off" spellcheck="false" value><!----></form><!--]--><!--[--><!----><!--]--><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar"><!--[--><!----><!--]--><ul class="vp-sidebar-links"></ul><!--[--><!----><!--]--></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!--[--><!----><!--]--><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><span class="font-icon icon fa-fw fa-sm fas fa-lightbulb" style=""></span>QLoRA ä»£ç å®ç°åŠè¿‡ç¨‹åˆ†æ</h1><div class="page-info"><span class="page-author-info" aria-label="ä½œè€…ğŸ–Š" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><a class="page-author-item" href="https://github.com/liz-in-tech" target="_blank" rel="noopener noreferrer">Liz</a></span><span property="author" content="Liz"></span></span><!----><span class="page-date-info" aria-label="å†™ä½œæ—¥æœŸğŸ“…" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span><!----></span><meta property="datePublished" content="2025-04-08T00:00:00.000Z"></span><!----><span class="page-reading-time-info" aria-label="é˜…è¯»æ—¶é—´âŒ›" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>å¤§çº¦ 16 åˆ†é’Ÿ</span><meta property="timeRequired" content="PT16M"></span><span class="page-category-info" aria-label="åˆ†ç±»ğŸŒˆ" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon category-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="category icon"><path d="M148.41 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H148.41c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.311-40.31zM147.556 553.478H429.73c22.263 0 40.311 18.048 40.311 40.31v282.176c0 22.263-18.048 40.312-40.31 40.312H147.555c-22.263 0-40.311-18.049-40.311-40.312V593.79c0-22.263 18.048-40.311 40.31-40.311zM593.927 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H593.927c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.31-40.31zM730.22 920.502H623.926c-40.925 0-74.22-33.388-74.22-74.425V623.992c0-41.038 33.387-74.424 74.425-74.424h222.085c41.038 0 74.424 33.226 74.424 74.067v114.233c0 10.244-8.304 18.548-18.547 18.548s-18.548-8.304-18.548-18.548V623.635c0-20.388-16.746-36.974-37.33-36.974H624.13c-20.585 0-37.331 16.747-37.331 37.33v222.086c0 20.585 16.654 37.331 37.126 37.331H730.22c10.243 0 18.547 8.304 18.547 18.547 0 10.244-8.304 18.547-18.547 18.547z"></path></svg><!--[--><span class="page-category-item category6 clickable" role="navigation">LLM</span><!--]--><meta property="articleSection" content="LLM"></span><span class="page-tag-info" aria-label="æ ‡ç­¾ğŸ·" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon tag-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="tag icon"><path d="M939.902 458.563L910.17 144.567c-1.507-16.272-14.465-29.13-30.737-30.737L565.438 84.098h-.402c-3.215 0-5.726 1.005-7.634 2.913l-470.39 470.39a10.004 10.004 0 000 14.164l365.423 365.424c1.909 1.908 4.42 2.913 7.132 2.913s5.223-1.005 7.132-2.913l470.39-470.39c2.01-2.11 3.014-5.023 2.813-8.036zm-240.067-72.121c-35.458 0-64.286-28.828-64.286-64.286s28.828-64.285 64.286-64.285 64.286 28.828 64.286 64.285-28.829 64.286-64.286 64.286z"></path></svg><!--[--><span class="page-tag-item tag8 clickable" role="navigation">QLoRA</span><!--]--><meta property="keywords" content="QLoRA"></span></div><hr></div><div class="toc-place-holder"><aside id="toc"><!--[--><!----><!--]--><div class="toc-header">æ­¤é¡µå†…å®¹<button type="button" class="print-button" title="æ‰“å°"><svg xmlns="http://www.w3.org/2000/svg" class="icon print-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="print icon"><path d="M819.2 364.8h-44.8V128c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v236.8h-44.8C145.067 364.8 96 413.867 96 473.6v192c0 59.733 49.067 108.8 108.8 108.8h44.8V896c0 17.067 14.933 32 32 32h460.8c17.067 0 32-14.933 32-32V774.4h44.8c59.733 0 108.8-49.067 108.8-108.8v-192c0-59.733-49.067-108.8-108.8-108.8zM313.6 160h396.8v204.8H313.6V160zm396.8 704H313.6V620.8h396.8V864zM864 665.6c0 25.6-19.2 44.8-44.8 44.8h-44.8V588.8c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v121.6h-44.8c-25.6 0-44.8-19.2-44.8-44.8v-192c0-25.6 19.2-44.8 44.8-44.8h614.4c25.6 0 44.8 19.2 44.8 44.8v192z"></path></svg></button></div><div class="toc-wrapper"><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_1-èƒŒæ™¯ä»‹ç»-qlora-åŸºç¡€æ¨¡å‹-æ•°æ®é›†">1. èƒŒæ™¯ä»‹ç»: QLoRA/åŸºç¡€æ¨¡å‹/æ•°æ®é›†</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_2-qlora-ä»£ç å®ç°">2. QLoRA ä»£ç å®ç°</a></li><li><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_2-1-load-model">2.1. Load Model</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_2-2-preparing-dataset">2.2. Preparing Dataset</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_2-3-fine-tuning">2.3. Fine-Tuning</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_2-4-save-trained-model">2.4. Save Trained Model</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_3-qlora-è¿‡ç¨‹åˆ†æ">3. QLoRA è¿‡ç¨‹åˆ†æ</a></li><li><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_3-1-åŸå§‹æ¨¡å‹å’Œé‡åŒ–æ¨¡å‹çš„å¯¹æ¯”">3.1. åŸå§‹æ¨¡å‹å’Œé‡åŒ–æ¨¡å‹çš„å¯¹æ¯”</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_3-2-dataset-å¤„ç†æµç¨‹">3.2. Dataset å¤„ç†æµç¨‹</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_3-3-å¯è®­ç»ƒå‚æ•°é‡è®¡ç®—">3.3. å¯è®­ç»ƒå‚æ•°é‡è®¡ç®—</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_4-qlora-åº”ç”¨ä»·å€¼">4. QLoRA åº”ç”¨ä»·å€¼</a></li><li><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_4-1-qlora-å’Œå…¨å‚æ•°å¾®è°ƒæ–¹æ³•å¯¹æ¯”">4.1. QLoRA å’Œå…¨å‚æ•°å¾®è°ƒâ½…æ³•å¯¹æ¯”</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_4-2-qlora-åœ¨è¯¥ä»»åŠ¡ä¸­çš„ä¼˜åŠ¿å’Œæ½œåœ¨å±€é™æ€§">4.2. QLoRA åœ¨è¯¥ä»»åŠ¡ä¸­çš„ä¼˜åŠ¿å’Œæ½œåœ¨å±€é™æ€§</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_5-qlora-ç–‘ç‚¹æ€è€ƒ">5. QLoRA ç–‘ç‚¹æ€è€ƒ</a></li><li><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_5-1-loraå’Œqloraå¾®è°ƒçš„æ–¹å¼æ˜¯ä¸æ˜¯åªæœ‰è®­ç»ƒå‰çš„æ¨¡å‹æ˜¯å¦è¿›è¡Œäº†é‡åŒ–è¿™ä¸€åŒºåˆ«">5.1. loraå’Œqloraå¾®è°ƒçš„æ–¹å¼æ˜¯ä¸æ˜¯åªæœ‰è®­ç»ƒå‰çš„æ¨¡å‹æ˜¯å¦è¿›è¡Œäº†é‡åŒ–è¿™ä¸€åŒºåˆ«ï¼Ÿ</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_5-2-ä¸ºä»€ä¹ˆé‡åŒ–é€šå¸¸åªç”¨äºçº¿æ€§å±‚">5.2. ä¸ºä»€ä¹ˆé‡åŒ–é€šå¸¸åªç”¨äºçº¿æ€§å±‚ï¼Ÿ</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_5-3-ä¸ºä»€ä¹ˆä¸å¯¹-lm-head-å±‚è¿›è¡Œé‡åŒ–-è¿™ä¸ªä¹Ÿæ˜¯çº¿æ€§å±‚">5.3. ä¸ºä»€ä¹ˆä¸å¯¹ lm_head å±‚è¿›è¡Œé‡åŒ–ï¼Œè¿™ä¸ªä¹Ÿæ˜¯çº¿æ€§å±‚?</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_5-4-ä¸ºä»€ä¹ˆéçº¿æ€§å±‚åœ¨é‡åŒ–åçš„dtypeä¹Ÿæœ‰å˜åŒ–-å˜ä¸ºfloat16">5.4. ä¸ºä»€ä¹ˆéçº¿æ€§å±‚åœ¨é‡åŒ–åçš„dtypeä¹Ÿæœ‰å˜åŒ–ï¼Œå˜ä¸ºfloat16ï¼Ÿ</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_5-5-é‡åŒ–æ¨¡å‹ç²¾åº¦å‘ç”Ÿäº†ä»€ä¹ˆå˜åŒ–">5.5. é‡åŒ–æ¨¡å‹ç²¾åº¦å‘ç”Ÿäº†ä»€ä¹ˆå˜åŒ–?</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_5-6-bnb-4bit-compute-dtype-torch-bfloat16æ˜¯åšä»€ä¹ˆçš„-è®¡ç®—ç²¾åº¦å’Œå­˜å‚¨ç²¾åº¦ä¸åŒ">5.6. bnb_4bit_compute_dtype=torch.bfloat16æ˜¯åšä»€ä¹ˆçš„ï¼Œè®¡ç®—ç²¾åº¦å’Œå­˜å‚¨ç²¾åº¦ä¸åŒï¼Ÿ</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_5-7-ä¸´æ—¶æ€§é‡åŒ–ä¸æ°¸ä¹…å­˜å‚¨">5.7. ä¸´æ—¶æ€§é‡åŒ–ä¸æ°¸ä¹…å­˜å‚¨ï¼Ÿ</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_5-8-qloraå­˜å‚¨è®­ç»ƒå¥½çš„æ¨¡å‹æ˜¯æŒ‰ä»€ä¹ˆç²¾åº¦å­˜å‚¨çš„">5.8. qloraå­˜å‚¨è®­ç»ƒå¥½çš„æ¨¡å‹æ˜¯æŒ‰ä»€ä¹ˆç²¾åº¦å­˜å‚¨çš„ï¼Ÿ</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_6-qlora-ç»†èŠ‚è¡¥å……">6. QLoRA ç»†èŠ‚è¡¥å……</a></li><li><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_6-1-device-map">6.1. device_map</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_6-2-seed-42-æ˜¯å¸¸è§-é­”æ³•æ•°å­—">6.2. seed=42 æ˜¯å¸¸è§â€œé­”æ³•æ•°å­—â€</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_7-reference">7. Reference</a></li><!----><!--]--></ul><div class="toc-marker" style="top:-1.7rem;"></div></div><!--[--><!----><!--]--></aside></div><!--[--><!----><!--]--><div class="theme-hope-content"><h1 id="qlora-ä»£ç å®ç°åŠè¿‡ç¨‹åˆ†æ" tabindex="-1"><a class="header-anchor" href="#qlora-ä»£ç å®ç°åŠè¿‡ç¨‹åˆ†æ" aria-hidden="true">#</a> QLoRA ä»£ç å®ç°åŠè¿‡ç¨‹åˆ†æ</h1><ul><li>èƒŒæ™¯ä»‹ç»: QLoRA/åŸºç¡€æ¨¡å‹/æ•°æ®é›†</li><li>QLoRA ä»£ç å®ç°</li><li>QLoRA è¿‡ç¨‹åˆ†æ</li><li>QLoRA åº”ç”¨ä»·å€¼</li><li>QLoRA ç–‘ç‚¹æ€è€ƒ</li><li>QLoRA ç»†èŠ‚è¡¥å……</li></ul><!-- more --><h2 id="_1-èƒŒæ™¯ä»‹ç»-qlora-åŸºç¡€æ¨¡å‹-æ•°æ®é›†" tabindex="-1"><a class="header-anchor" href="#_1-èƒŒæ™¯ä»‹ç»-qlora-åŸºç¡€æ¨¡å‹-æ•°æ®é›†" aria-hidden="true">#</a> 1. èƒŒæ™¯ä»‹ç»: QLoRA/åŸºç¡€æ¨¡å‹/æ•°æ®é›†</h2><ul><li>QLoRA <ul><li>QLoRAï¼ˆQuantized Low-Rank Adaptationï¼‰å¾®è°ƒæ–¹æ³•</li><li>Paper: https://arxiv.org/abs/2305.14314</li><li>QLoRA ç»“åˆäº† 4-bit é‡åŒ–å’Œ LoRA æŠ€æœ¯ï¼Œå…·ä½“å®ç°æ­¥éª¤å¦‚ä¸‹ï¼š <ul><li>4-bit é‡åŒ–ï¼šä½¿ç”¨ bitsandbytes åº“å®ç° 4-bit NormalFloat (NF4) é‡åŒ–ï¼Œå°†é¢„è®­ç»ƒæ¨¡å‹æƒé‡å‹ç¼©è‡³ 4 ä½ï¼Œæ˜¾è‘—é™ä½å†…å­˜å ç”¨</li><li>LoRAï¼šé€šè¿‡ peft åº“å®ç° LoRAï¼Œæ·»åŠ ä½ç§©é€‚é…å™¨ï¼ˆä¾‹å¦‚ç§© r=16ï¼‰ï¼Œä»…æ›´æ–°å°‘é‡å‚æ•°</li><li>ç»“åˆæŠ€æœ¯ï¼šåŠ è½½é‡åŒ–åçš„æ¨¡å‹ï¼Œé™„åŠ  LoRA é€‚é…å™¨ï¼Œä½¿ç”¨ 16-bit (bfloat16) è¿›è¡Œå‰å‘/åå‘ä¼ æ’­è®¡ç®—</li></ul></li></ul></li><li>åŸºç¡€æ¨¡å‹ï¼šDistilGPT-2 <ul><li>https://huggingface.co/distilbert/distilgpt2</li></ul></li><li>AlpacaæŒ‡ä»¤æ•°æ®é›† <ul><li>å®˜æ–¹ç‰ˆæœ¬ <ul><li>https://huggingface.co/datasets/tatsu-lab/alpaca</li><li>ä½¿ç”¨ OpenAI çš„ text-davinci-003 æ¨¡å‹ç”Ÿæˆçš„è¾“å‡ºï¼Œè¯¥æ•°æ®é›†å¯èƒ½åŒ…å«é”™è¯¯æˆ–åè§ï¼Œå»ºè®®ç”¨æˆ·è°¨æ…ä½¿ç”¨å¹¶è€ƒè™‘è¿‡æ»¤æ–¹æ³•ï¼Œè¿™åœ¨æ•°æ®é›†æè¿°ä¸­æœ‰æ‰€æåŠ</li></ul></li><li>yahma/alpaca-cleaned <ul><li>https://huggingface.co/datasets/yahma/alpaca-cleaned</li><li>æ¸…ç†ç‰ˆæœ¬ï¼Œä¿®å¤äº†åŸå§‹æ•°æ®é›†ä¸­çš„å¹»è§‰ã€é”™è¯¯ç­”æ¡ˆç­‰é—®é¢˜ï¼Œæä¾›äº†é«˜è´¨é‡çš„æ•°æ®</li></ul></li><li>vicgalle/alpaca-gpt4 <ul><li>https://huggingface.co/datasets/vicgalle/alpaca-gpt4</li><li>åŸºäº Alpaca æç¤ºï¼Œä½¿ç”¨ GPT-4 ç”Ÿæˆçš„è¾“å‡ºï¼Œï¼Œä½†æœªæåŠæ¸…ç†ï¼Œå¯èƒ½åŒ…å«æœªä¿®æ­£çš„é”™è¯¯</li></ul></li></ul></li></ul><h2 id="_2-qlora-ä»£ç å®ç°" tabindex="-1"><a class="header-anchor" href="#_2-qlora-ä»£ç å®ç°" aria-hidden="true">#</a> 2. QLoRA ä»£ç å®ç°</h2><ul><li>Load Model</li><li>Preparing Dataset</li><li>Fine-Tuning</li><li>Save Trained Model</li></ul><h3 id="_2-1-load-model" tabindex="-1"><a class="header-anchor" href="#_2-1-load-model" aria-hidden="true">#</a> 2.1. Load Model</h3><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># é‡åŒ–é…ç½®</span>
bnb_config <span class="token operator">=</span> BitsAndBytesConfig<span class="token punctuation">(</span>
    load_in_4bit<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> <span class="token comment"># å¯ç”¨ 4bit é‡åŒ–ï¼Œå°†æ¨¡å‹çš„çº¿æ€§å±‚ï¼ˆLinear / Conv1Dï¼‰æ›¿æ¢æˆé‡åŒ–å±‚ Linear4bit</span>
    bnb_4bit_use_double_quant<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> <span class="token comment"># å¯ç”¨åµŒå¥—é‡åŒ–ï¼Œè¿›ä¸€æ­¥å‹ç¼©é‡åŒ–å‚æ•°ï¼Œå‡å°‘å­˜å‚¨å¼€é”€ (Linear4bitå†…éƒ¨è®¡ç®—é€»è¾‘)</span>
    bnb_4bit_quant_type<span class="token operator">=</span><span class="token string">&quot;nf4&quot;</span><span class="token punctuation">,</span> <span class="token comment"># 4bit é‡åŒ–æ ¼å¼æœ‰2ç§ï¼ˆnf4å’Œfp4ï¼‰ï¼Œå…¶ä¸­nf4åŸºäºæ­£æ€åˆ†å¸ƒä¼˜åŒ–ï¼Œé€šå¸¸æ•ˆæœæ›´ä¼˜</span>
    bnb_4bit_compute_dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>bfloat16 <span class="token comment"># è®¾ç½®è®¡ç®—æ—¶çš„æ•°æ®ç±»å‹ï¼Œå®é™…æƒé‡ä»¥ 4bit å­˜å‚¨ä½†ä¼šæ˜ å°„åˆ° bfloat16 è¿›è¡Œè®¡ç®—ï¼Œä¹Ÿå°±æ˜¯ Linear4bit å†…éƒ¨çš„ä¸­é—´è®¡ç®—ä½¿ç”¨ bfloat16</span>
<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># é€‰æ‹© distilbert/distilgpt2 ä½œä¸ºåŸºç¡€æ¨¡å‹</span>
model_id <span class="token operator">=</span> <span class="token string">&quot;distilbert/distilgpt2&quot;</span>

<span class="token comment"># å°†æ•´ä¸ªæ¨¡å‹åŠ è½½åˆ° GPU 0</span>
device_map <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&quot;&quot;</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">}</span>

<span class="token comment"># åŠ è½½åŸå§‹æ¨¡å‹</span>
original_model <span class="token operator">=</span> AutoModelForCausalLM<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_id<span class="token punctuation">)</span>

<span class="token comment"># åŠ è½½é‡åŒ–æ¨¡å‹ï¼ˆå°†é‡åŒ–é…ç½®åº”ç”¨åœ¨æ¨¡å‹ä¸Šï¼‰</span>
quantized_model <span class="token operator">=</span> AutoModelForCausalLM<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_id<span class="token punctuation">,</span>
                    quantization_config<span class="token operator">=</span>bnb_config<span class="token punctuation">,</span>
                    device_map<span class="token operator">=</span>device_map<span class="token punctuation">,</span>
                    use_cache <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># åŠ è½½ä¸æ¨¡å‹å¯¹åº”çš„åˆ†è¯å™¨ï¼Œå¹¶è®¾ç½®å¡«å……æ ‡è®°ä¸ºç»“æŸæ ‡è®°</span>
tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_id<span class="token punctuation">)</span>
tokenizer<span class="token punctuation">.</span>pad_token <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>eos_token
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_2-2-preparing-dataset" tabindex="-1"><a class="header-anchor" href="#_2-2-preparing-dataset" aria-hidden="true">#</a> 2.2. Preparing Dataset</h3><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># é€‰æ‹© yahma/alpaca-cleaned ä½œä¸ºæ•°æ®é›†</span>
dataset_name <span class="token operator">=</span> <span class="token string">&quot;yahma/alpaca-cleaned&quot;</span>

<span class="token comment"># åŠ è½½æ•°æ®é›†</span>
full_dataset <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span>dataset_name<span class="token punctuation">,</span> split<span class="token operator">=</span><span class="token string">&quot;train&quot;</span><span class="token punctuation">)</span>

<span class="token comment"># é€‰å–å°è§„æ¨¡å­é›†ï¼ˆ1000 æ¡ï¼‰</span>
small_subset <span class="token operator">=</span> full_dataset<span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span>seed<span class="token operator">=</span><span class="token number">42</span><span class="token punctuation">)</span><span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># å®šä¹‰ Alpaca æ•°æ®é›†çš„ Prompt æ¨¡ç‰ˆ</span>
alpaca_prompt <span class="token operator">=</span> <span class="token triple-quoted-string string">&quot;&quot;&quot;Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.

### Instruction:
{}

### Input:
{}

### Response:
{}&quot;&quot;&quot;</span>

<span class="token comment"># å®šä¹‰ formatting_prompts_func å‡½æ•°</span>
<span class="token keyword">def</span> <span class="token function">formatting_prompts_func</span><span class="token punctuation">(</span>examples<span class="token punctuation">)</span><span class="token punctuation">:</span>

    instructions <span class="token operator">=</span> examples<span class="token punctuation">[</span><span class="token string">&quot;instruction&quot;</span><span class="token punctuation">]</span>
    inputs       <span class="token operator">=</span> examples<span class="token punctuation">[</span><span class="token string">&quot;input&quot;</span><span class="token punctuation">]</span>
    outputs      <span class="token operator">=</span> examples<span class="token punctuation">[</span><span class="token string">&quot;output&quot;</span><span class="token punctuation">]</span>

    texts <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> instruction<span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token punctuation">,</span> output <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>instructions<span class="token punctuation">,</span> inputs<span class="token punctuation">,</span> outputs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        text <span class="token operator">=</span> alpaca_prompt<span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>instruction<span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token punctuation">,</span> output<span class="token punctuation">)</span>
        texts<span class="token punctuation">.</span>append<span class="token punctuation">(</span>text<span class="token punctuation">)</span>
    <span class="token keyword">return</span> <span class="token punctuation">{</span> <span class="token string">&quot;text&quot;</span> <span class="token punctuation">:</span> texts <span class="token punctuation">}</span>


<span class="token comment"># åº”ç”¨ formatting_prompts_func å‡½æ•°</span>
small_subset <span class="token operator">=</span> small_subset<span class="token punctuation">.</span><span class="token builtin">map</span><span class="token punctuation">(</span>formatting_prompts_func<span class="token punctuation">,</span> batched<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># å¯¹ &quot;text&quot; åº”ç”¨ tokenizerï¼›å¦‚æœè¶…é•¿ï¼Œæˆªæ–­åˆ°æ¨¡å‹æœ€å¤§é•¿åº¦ï¼›æ‰€æœ‰æ ·æœ¬ pad åˆ°ç›¸åŒé•¿åº¦ï¼Œæ–¹ä¾¿ batch è®­ç»ƒ</span>
small_subset <span class="token operator">=</span> small_subset<span class="token punctuation">.</span><span class="token builtin">map</span><span class="token punctuation">(</span><span class="token keyword">lambda</span> samples<span class="token punctuation">:</span> tokenizer<span class="token punctuation">(</span>samples<span class="token punctuation">[</span><span class="token string">&quot;text&quot;</span><span class="token punctuation">]</span><span class="token punctuation">,</span> truncation<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">&quot;max_length&quot;</span><span class="token punctuation">)</span><span class="token punctuation">,</span> batched<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_2-3-fine-tuning" tabindex="-1"><a class="header-anchor" href="#_2-3-fine-tuning" aria-hidden="true">#</a> 2.3. Fine-Tuning</h3><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># LoRA å‚æ•°é…ç½®</span>
peft_config <span class="token operator">=</span> LoraConfig<span class="token punctuation">(</span>
    r<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">,</span> <span class="token comment"># ç§©ï¼Œè¶Šå¤§è¡¨è¾¾èƒ½åŠ›è¶Šå¼ºï¼Œä½†å‚æ•°ä¹Ÿæ›´å¤š</span>
    lora_alpha<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token comment"># ç¼©æ”¾å› å­</span>
    lora_dropout<span class="token operator">=</span><span class="token number">0.05</span><span class="token punctuation">,</span> <span class="token comment"># dropout æ¦‚ç‡</span>
    target_modules<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">&quot;c_attn&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;c_proj&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;c_fc&quot;</span><span class="token punctuation">]</span><span class="token punctuation">,</span>  <span class="token comment"># éœ€è¦æ’å…¥ LoRA çš„æ¨¡å—</span>
    bias<span class="token operator">=</span><span class="token string">&quot;none&quot;</span><span class="token punctuation">,</span> <span class="token comment"># æ˜¯å¦è®­ç»ƒ bias é¡¹ï¼šå¦</span>
    task_type<span class="token operator">=</span><span class="token string">&quot;CAUSAL_LM&quot;</span><span class="token punctuation">,</span> <span class="token comment"># ä»»åŠ¡ç±»å‹ï¼šå› æœè¯­è¨€å»ºæ¨¡</span>
<span class="token punctuation">)</span>

<span class="token comment"># è®­ç»ƒå‚æ•°é…ç½®</span>
training_args <span class="token operator">=</span> SFTConfig<span class="token punctuation">(</span>
    output_dir<span class="token operator">=</span><span class="token string">&quot;outputs&quot;</span><span class="token punctuation">,</span> <span class="token comment"># è¾“å‡ºè·¯å¾„</span>
    logging_steps<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token comment"># å¤šå°‘stepsè®°å½•ä¸€æ¬¡æ—¥å¿—</span>
    num_train_epochs<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token comment"># è®­ç»ƒè½®æ•°</span>
    per_device_train_batch_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token comment"># æ¯ä¸ªè®¾å¤‡çš„è®­ç»ƒæ‰¹æ¬¡å¤§å°</span>
    per_device_eval_batch_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token comment"># æ¯ä¸ªè®¾å¤‡çš„éªŒè¯æ‰¹æ¬¡å¤§å°</span>
    gradient_accumulation_steps<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token comment"># æ¢¯åº¦ç´¯ç§¯</span>
    gradient_checkpointing<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> <span class="token comment"># å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹</span>
    learning_rate<span class="token operator">=</span><span class="token number">2e-4</span><span class="token punctuation">,</span> <span class="token comment"># å­¦ä¹ ç‡</span>
    optim<span class="token operator">=</span><span class="token string">&quot;adamw_8bit&quot;</span><span class="token punctuation">,</span> <span class="token comment"># ä¼˜åŒ–å™¨</span>
    weight_decay<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">,</span> <span class="token comment"># æƒé‡è¡°å‡</span>
    max_grad_norm<span class="token operator">=</span><span class="token number">0.3</span><span class="token punctuation">,</span> <span class="token comment"># æ¢¯åº¦è£å‰ª</span>
    warmup_ratio<span class="token operator">=</span><span class="token number">0.03</span><span class="token punctuation">,</span> <span class="token comment"># é¢„çƒ­æ¯”ä¾‹</span>
    fp16<span class="token operator">=</span><span class="token keyword">not</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_bf16_supported<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token comment"># ä½¿ç”¨åŠç²¾åº¦è®­ç»ƒ</span>
    bf16<span class="token operator">=</span>torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_bf16_supported<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    dataset_text_field<span class="token operator">=</span><span class="token string">&quot;text&quot;</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>

<span class="token comment"># å®ä¾‹åŒ– SFTTrainer</span>
trainer <span class="token operator">=</span> SFTTrainer<span class="token punctuation">(</span>
    model<span class="token operator">=</span>quantized_model<span class="token punctuation">,</span>
    train_dataset<span class="token operator">=</span>small_subset<span class="token punctuation">,</span>
    peft_config<span class="token operator">=</span>peft_config<span class="token punctuation">,</span>
    args<span class="token operator">=</span>training_args<span class="token punctuation">,</span>
<span class="token punctuation">)</span>

<span class="token comment"># è¾“å‡ºå¯è®­ç»ƒå‚æ•°é‡</span>
trainer<span class="token punctuation">.</span>model<span class="token punctuation">.</span>print_trainable_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># å¼€å§‹è®­ç»ƒ</span>
trainer<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_2-4-save-trained-model" tabindex="-1"><a class="header-anchor" href="#_2-4-save-trained-model" aria-hidden="true">#</a> 2.4. Save Trained Model</h3><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># Save trained model</span>
peft_model <span class="token operator">=</span> <span class="token string">&quot;distilgpt2-qlora&quot;</span>

trainer<span class="token punctuation">.</span>model<span class="token punctuation">.</span>save_pretrained<span class="token punctuation">(</span>peft_model<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>base_model <span class="token operator">=</span> AutoModelForCausalLM<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>
    model_id<span class="token punctuation">,</span>
    low_cpu_mem_usage<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
    return_dict<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
    torch_dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float16<span class="token punctuation">,</span>
    device_map<span class="token operator">=</span>device_map<span class="token punctuation">,</span>
<span class="token punctuation">)</span>

peft_model <span class="token operator">=</span> PeftModel<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>base_model<span class="token punctuation">,</span> peft_model<span class="token punctuation">)</span>
merged_model <span class="token operator">=</span> peft_model<span class="token punctuation">.</span>merge_and_unload<span class="token punctuation">(</span><span class="token punctuation">)</span>
merged_model<span class="token punctuation">.</span>save_pretrained<span class="token punctuation">(</span><span class="token string">&quot;merged_model&quot;</span><span class="token punctuation">,</span> safe_serialization<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> max_shard_size<span class="token operator">=</span><span class="token string">&quot;2GB&quot;</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="_3-qlora-è¿‡ç¨‹åˆ†æ" tabindex="-1"><a class="header-anchor" href="#_3-qlora-è¿‡ç¨‹åˆ†æ" aria-hidden="true">#</a> 3. QLoRA è¿‡ç¨‹åˆ†æ</h2><ul><li>åŸå§‹æ¨¡å‹å’Œé‡åŒ–æ¨¡å‹çš„å¯¹æ¯”</li><li>Dataset å¤„ç†æµç¨‹</li><li>å¯è®­ç»ƒå‚æ•°é‡è®¡ç®—</li></ul><h3 id="_3-1-åŸå§‹æ¨¡å‹å’Œé‡åŒ–æ¨¡å‹çš„å¯¹æ¯”" tabindex="-1"><a class="header-anchor" href="#_3-1-åŸå§‹æ¨¡å‹å’Œé‡åŒ–æ¨¡å‹çš„å¯¹æ¯”" aria-hidden="true">#</a> 3.1. åŸå§‹æ¨¡å‹å’Œé‡åŒ–æ¨¡å‹çš„å¯¹æ¯”</h3><ul><li>å‚æ•°æ•°é‡ä¸ä¼šå˜ï¼ˆè¿˜æ˜¯é‚£ä¹ˆå¤šçŸ©é˜µå…ƒç´ ï¼‰ <ul><li>81912576</li></ul></li><li>å‚æ•°ç²¾åº¦å’Œå¤§å°å˜äº†ï¼ˆç”¨ 4-bit è¡¨ç¤ºï¼‰ <ul><li>å‚æ•°å¤§å°å˜åŒ– <ul><li>Original size: 318.47 MB <ul><li>ä¼°ç®—ï¼š81912576 * 4 bytes / (1024^2) = 308.66 MB</li></ul></li><li>Quantized size: 101.49 MB <ul><li>ä¼°ç®— <ul><li>0.5 bytes çš„å‚æ•°ä¸ªæ•°ï¼š42467328 = 6 layers * (768 * 2304 + 768 * 768 + 2 * 768 * 3072)</li><li>2 bytes çš„å‚æ•°ä¸ªæ•°ï¼š39445248 = 81912576 - 42467328</li><li>ï¼ˆ0.5 * 42467328 + 2 * 39445248 ï¼‰ / (1024^2) = 95.49 MB</li></ul></li></ul></li></ul></li><li>æ¨¡å‹ç»“æ„å˜åŒ– <ul><li>attn <ul><li>(c_attn): Conv1D(nf=2304, nx=768) -&gt; (c_attn): Linear4bit(in_features=768, out_features=2304, bias=True)</li><li>(c_proj): Conv1D(nf=768, nx=768) -&gt; (c_proj): Linear4bit(in_features=768, out_features=768, bias=True)</li></ul></li><li>mlp <ul><li>(c_fc): Conv1D(nf=3072, nx=768) -&gt; (c_fc): Linear4bit(in_features=768, out_features=3072, bias=True)</li><li>(c_proj): Conv1D(nf=768, nx=3072) -&gt; (c_proj): Linear4bit(in_features=3072, out_features=768, bias=True)</li></ul></li></ul></li><li>å‚æ•°ç²¾åº¦å˜åŒ– <ul><li>é‡åŒ–å‰ï¼š <ul><li>æ‰€æœ‰å‚æ•°å…¨éƒ½æ˜¯dtype=torch.float32ï¼ˆ32ä½ï¼‰ <ul><li>transformer.h.0.attn.c_attn.weight: torch.Size([768, 2304]), dtype=torch.float32</li><li>transformer.h.0.attn.c_proj.weight: torch.Size([768, 768]), dtype=torch.float32</li><li>transformer.h.0.mlp.c_fc.weight: torch.Size([768, 3072]), dtype=torch.float32</li><li>transformer.h.0.mlp.c_proj.weight: torch.Size([3072, 768]), dtype=torch.float32</li></ul></li></ul></li><li>é‡åŒ–åï¼š <ul><li>dtype=torch.uint8ï¼ˆæ¯å±‚çš„4ä¸ªåœ°æ–¹å˜ä¸º4bitï¼‰å®é™…å­˜å‚¨ä¸­ä½¿ç”¨å‹ç¼©æŠ€æœ¯ï¼Œå°†2ä¸ª4bitç»„åˆä¸ºint8 <ul><li>transformer.h.0.attn.c_attn.weight: torch.Size([884736, 1]), dtype=torch.uint8</li><li>transformer.h.0.attn.c_proj.weight: torch.Size([294912, 1]), dtype=torch.uint8</li><li>transformer.h.0.mlp.c_fc.weight: torch.Size([1179648, 1]), dtype=torch.uint8</li><li>transformer.h.0.mlp.c_proj.weight: torch.Size([1179648, 1]), dtype=torch.uint8</li></ul></li><li>dtype=torch.float16ï¼ˆå…¶ä½™å‚æ•°éƒ½å˜ä¸ºfloat16ï¼‰</li></ul></li></ul></li></ul></li></ul><p>å˜åŒ–è§£é‡Š</p><ul><li>å˜åŒ– <ul><li>é‡åŒ–å‰ï¼štransformer.h.0.attn.c_attn.weight: torch.Size([768, 2304]), dtype=torch.float32</li><li>é‡åŒ–åï¼štransformer.h.0.attn.c_attn.weight: torch.Size([884736, 1]), dtype=torch.uint8</li></ul></li><li>è§£é‡Š <ul><li>åŸå§‹ float32 çš„çŸ©é˜µ [768, 2304] â†’ æ€»å…±å‚æ•°æ•°é‡æ˜¯ 768 * 2304 = 1,769,472</li><li>ç”¨ 4-bit è¡¨ç¤ºå°±æ˜¯ 1,769,472 * 0.5 byte = 884,736 bytes = 884736 uint8 ï¼ˆå­˜å‚¨ä¸º packed çš„ uint8ï¼Œæ¯ byte å­˜ä¸¤ä¸ª 4-bit æƒé‡ï¼‰</li><li>[884736, 1]æ­£æ˜¯æŠŠåŸæ¥çš„æƒé‡å±•å¼€æˆ1ç»´åé‡åŒ–å­˜å‚¨çš„ç»“æœ</li></ul></li></ul><h3 id="_3-2-dataset-å¤„ç†æµç¨‹" tabindex="-1"><a class="header-anchor" href="#_3-2-dataset-å¤„ç†æµç¨‹" aria-hidden="true">#</a> 3.2. Dataset å¤„ç†æµç¨‹</h3><ul><li>1.åŠ è½½æ•°æ®é›† <ul><li>æ•°æ®é›†æœ‰3åˆ— <ul><li>instruction</li><li>input</li><li>output</li></ul></li><li>æ•°æ®é›†æœ‰ 51760 æ¡æ•°æ®</li></ul></li></ul><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>Dataset({
    features: [&#39;output&#39;, &#39;input&#39;, &#39;instruction&#39;],
    num_rows: 51760
})
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>2.é€‰å–å°è§„æ¨¡å­é›† <ul><li>éšæœºé€‰å– 1000 æ¡æ•°æ®</li></ul></li></ul><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>Dataset({
    features: [&#39;output&#39;, &#39;input&#39;, &#39;instruction&#39;],
    num_rows: 1000
})
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>3.æ‹¼æ¥ &#39;output&#39;, &#39;input&#39;, &#39;instruction&#39; è¿™3ä¸ªå­—æ®µä¸ºä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œä½œä¸º &#39;text&#39; å­—æ®µ</li></ul><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>Dataset({
    features: [&#39;output&#39;, &#39;input&#39;, &#39;instruction&#39;, &#39;text&#39;],
    num_rows: 1000
})
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>4.å°† &quot;text&quot; å­—æ®µé‡‡ç”¨ tokenizer è¿›è¡Œ token åŒ–ï¼Œç”Ÿæˆ &quot;input_ids&quot; å’Œ &quot;attention_mask&quot; å­—æ®µ</li></ul><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>Dataset({
    features: [&#39;output&#39;, &#39;input&#39;, &#39;instruction&#39;, &#39;text&#39;, &#39;input_ids&#39;, &#39;attention_mask&#39;],
    num_rows: 1000
})
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_3-3-å¯è®­ç»ƒå‚æ•°é‡è®¡ç®—" tabindex="-1"><a class="header-anchor" href="#_3-3-å¯è®­ç»ƒå‚æ•°é‡è®¡ç®—" aria-hidden="true">#</a> 3.3. å¯è®­ç»ƒå‚æ•°é‡è®¡ç®—</h3><ul><li>åŸºç¡€æ¨¡å‹å‚æ•°é‡ <ul><li>81912576</li></ul></li><li>æ¨¡å‹ç»“æ„ä¸­çš„ç›®æ ‡æ¨¡å— <ul><li>attn <ul><li>(c_attn): Conv1D(nf=2304, nx=768) -&gt; (c_attn): Linear4bit(in_features=768, out_features=2304, bias=True)</li><li>(c_proj): Conv1D(nf=768, nx=768) -&gt; (c_proj): Linear4bit(in_features=768, out_features=768, bias=True)</li></ul></li><li>mlp <ul><li>(c_fc): Conv1D(nf=3072, nx=768) -&gt; (c_fc): Linear4bit(in_features=768, out_features=3072, bias=True)</li><li>(c_proj): Conv1D(nf=768, nx=3072) -&gt; (c_proj): Linear4bit(in_features=3072, out_features=768, bias=True)</li></ul></li></ul></li><li>å‚æ•°ä¹‹é—´çš„å…³ç³» <ul><li>æ€»å‚æ•°é‡ 82,502,400 - QLoRAå¯è®­ç»ƒå‚æ•°é‡ 589,824 = åŸºç¡€æ¨¡å‹å‚æ•°é‡ 81912576</li><li>QLoRAå¯è®­ç»ƒå‚æ•°é‡ 589,824 = 6å±‚ * (24576 + 12288 + 30720 + 30720) = 6 * 98304 <ul><li>å…±6å±‚ï¼Œæ¯å±‚4ä¸ªç›®æ ‡æ¨¡å— <ul><li>c_attn: 768 * 8 + 2304 * 8 = 24576</li><li>c_proj: 768 * 8 + 768 * 8 = 12288</li><li>c_fc: 3072 * 8 + 768 * 8 = 30720</li><li>c_proj: 768 * 8 + 3072 * 8 = 30720</li></ul></li></ul></li></ul></li></ul><h2 id="_4-qlora-åº”ç”¨ä»·å€¼" tabindex="-1"><a class="header-anchor" href="#_4-qlora-åº”ç”¨ä»·å€¼" aria-hidden="true">#</a> 4. QLoRA åº”ç”¨ä»·å€¼</h2><h3 id="_4-1-qlora-å’Œå…¨å‚æ•°å¾®è°ƒæ–¹æ³•å¯¹æ¯”" tabindex="-1"><a class="header-anchor" href="#_4-1-qlora-å’Œå…¨å‚æ•°å¾®è°ƒæ–¹æ³•å¯¹æ¯”" aria-hidden="true">#</a> 4.1. QLoRA å’Œå…¨å‚æ•°å¾®è°ƒâ½…æ³•å¯¹æ¯”</h3><ul><li>å¾®è°ƒå‚æ•°é‡ï¼š <ul><li>QLoRAï¼šä»…å¾®è°ƒä¸€å°éƒ¨åˆ†å‚æ•°ï¼ˆLoRA Adapterï¼‰ï¼Œåœ¨æœ¬ä¾‹ä¸­ï¼Œå¯è®­ç»ƒå‚æ•°ä»…å æ€»å‚æ•°çš„ 0.7149%</li><li>å…¨å‚æ•°å¾®è°ƒï¼šæ›´æ–°æ‰€æœ‰æ¨¡å‹å‚æ•°ï¼Œéœ€è¦æ›´å¤šå†…å­˜å’Œè®¡ç®—èµ„æº</li></ul></li><li>å†…å­˜ä½¿ç”¨ï¼š <ul><li>QLoRAï¼šä½¿ç”¨ 4-bit é‡åŒ–ï¼Œå†…å­˜å ç”¨å¤§å¹…å‡å°‘</li><li>å…¨å‚æ•°å¾®è°ƒï¼šéœ€è¦å…¨ç²¾åº¦ï¼ˆä¾‹å¦‚ 16 ä½æˆ– 32 ä½ï¼‰ï¼Œé€šå¸¸éœ€è¦è¾ƒå¤§çš„ GPU å†…å­˜</li></ul></li><li>è®­ç»ƒé€Ÿåº¦ï¼š <ul><li>QLoRAï¼šç”±äºå‚æ•°å°‘ä¸”ç²¾åº¦ä½ï¼Œè®­ç»ƒæ›´å¿«</li><li>å…¨å‚æ•°å¾®è°ƒï¼šæ›´æ–°æ‰€æœ‰æƒé‡ï¼Œè®­ç»ƒæ—¶é—´è¾ƒé•¿</li></ul></li><li>æ€§èƒ½ï¼š <ul><li>QLoRAï¼šç”±äºé‡åŒ–å’Œæœ‰é™çš„å‚æ•°æ›´æ–°ï¼Œæ€§èƒ½å¯èƒ½ç•¥ä½äºå…¨å‚æ•°å¾®è°ƒï¼Œä½†ä»ä¿ç•™å¤§éƒ¨åˆ†èƒ½åŠ›</li><li>å…¨å‚æ•°å¾®è°ƒï¼šå› æ‰€æœ‰æƒé‡éƒ½è¢«ä¼˜åŒ–ï¼Œæ€§èƒ½å¯èƒ½æ›´é«˜</li></ul></li><li>é€‚ç”¨åœºæ™¯ï¼š <ul><li>QLoRAï¼šé€‚åˆèµ„æºå—é™ç¯å¢ƒæˆ–å¿«é€Ÿå®éªŒ</li><li>å…¨å‚æ•°å¾®è°ƒï¼šé€‚åˆèµ„æºå……è¶³ä¸”éœ€æœ€å¤§ç²¾åº¦çš„åœºæ™¯</li></ul></li></ul><h3 id="_4-2-qlora-åœ¨è¯¥ä»»åŠ¡ä¸­çš„ä¼˜åŠ¿å’Œæ½œåœ¨å±€é™æ€§" tabindex="-1"><a class="header-anchor" href="#_4-2-qlora-åœ¨è¯¥ä»»åŠ¡ä¸­çš„ä¼˜åŠ¿å’Œæ½œåœ¨å±€é™æ€§" aria-hidden="true">#</a> 4.2. QLoRA åœ¨è¯¥ä»»åŠ¡ä¸­çš„ä¼˜åŠ¿å’Œæ½œåœ¨å±€é™æ€§</h3><p>ä¼˜åŠ¿ï¼š</p><ul><li>å†…å­˜æ•ˆç‡ï¼š4 ä½é‡åŒ–å’Œ LoRA å‡å°‘äº†å†…å­˜ä½¿ç”¨ï¼Œä½¿å¾®è°ƒèƒ½åœ¨è¾ƒå°çš„ GPU ä¸Šè¿è¡Œï¼ˆä¾‹å¦‚ Colab å…è´¹ç‰ˆï¼‰</li><li>é€Ÿåº¦ï¼šç”±äºå‚æ•°å°‘ä¸”ç²¾åº¦ä½ï¼Œè®­ç»ƒé€Ÿåº¦æ›´å¿«ï¼Œé€‚åˆå¿«é€Ÿè¿­ä»£</li><li>ä¿ç•™é¢„è®­ç»ƒçŸ¥è¯†ï¼šå†»ç»“å¤§éƒ¨åˆ†æƒé‡ä¿ç•™äº†åŸºç¡€æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ï¼ŒåŒæ—¶é€‚é…ä»»åŠ¡</li><li>é€‚ç”¨äºå°æ•°æ®é›†ï¼šå¯¹åƒ 1,000 æ¡ Alpaca å­é›†è¿™æ ·çš„å°æ•°æ®é›†æ•ˆæœè‰¯å¥½ï¼Œä¸æ˜“è¿‡æ‹Ÿåˆ</li></ul><p>å±€é™æ€§ï¼š</p><ul><li>æ€§èƒ½æƒè¡¡ï¼šé‡åŒ–å’Œ LoRA å¯èƒ½å¯¼è‡´æ€§èƒ½ç•¥ä½äºå…¨å‚æ•°å¾®è°ƒï¼Œå°¤å…¶åœ¨å¤æ‚ä»»åŠ¡ä¸­</li><li>ä»»åŠ¡ç‰¹å®šæ€§ï¼šLoRA é€‚é…å™¨æ˜¯ä»»åŠ¡ç‰¹å®šçš„ï¼Œåˆ‡æ¢ä»»åŠ¡éœ€é‡æ–°è®­ç»ƒæˆ–ç»´æŠ¤å¤šä¸ªé€‚é…å™¨</li><li>é‡åŒ–å™ªå£°ï¼š4-bit ç²¾åº¦å¼•å…¥å™ªå£°ï¼Œå¯èƒ½å½±å“è¾“å‡ºè´¨é‡</li><li>è¶…å‚æ•°æ•æ„Ÿæ€§ï¼šè°ƒæ•´ <code>r</code>ã€<code>lora_alpha</code> å’Œé‡åŒ–è®¾ç½®éœ€è¦å®éªŒï¼Œå¢åŠ äº†å¤æ‚æ€§</li></ul><h2 id="_5-qlora-ç–‘ç‚¹æ€è€ƒ" tabindex="-1"><a class="header-anchor" href="#_5-qlora-ç–‘ç‚¹æ€è€ƒ" aria-hidden="true">#</a> 5. QLoRA ç–‘ç‚¹æ€è€ƒ</h2><h3 id="_5-1-loraå’Œqloraå¾®è°ƒçš„æ–¹å¼æ˜¯ä¸æ˜¯åªæœ‰è®­ç»ƒå‰çš„æ¨¡å‹æ˜¯å¦è¿›è¡Œäº†é‡åŒ–è¿™ä¸€åŒºåˆ«" tabindex="-1"><a class="header-anchor" href="#_5-1-loraå’Œqloraå¾®è°ƒçš„æ–¹å¼æ˜¯ä¸æ˜¯åªæœ‰è®­ç»ƒå‰çš„æ¨¡å‹æ˜¯å¦è¿›è¡Œäº†é‡åŒ–è¿™ä¸€åŒºåˆ«" aria-hidden="true">#</a> 5.1. loraå’Œqloraå¾®è°ƒçš„æ–¹å¼æ˜¯ä¸æ˜¯åªæœ‰è®­ç»ƒå‰çš„æ¨¡å‹æ˜¯å¦è¿›è¡Œäº†é‡åŒ–è¿™ä¸€åŒºåˆ«ï¼Ÿ</h3><p>æ˜¯çš„ï¼Œä¸»è¦çš„åŒºåˆ«å°±æ˜¯è®­ç»ƒå‰çš„æ¨¡å‹æ˜¯å¦å·²ç»è¿›è¡Œäº†é‡åŒ–</p><ul><li>LoRA å¾®è°ƒçš„æ˜¯ä¸€ä¸ª æœªé‡åŒ–çš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œæƒé‡é€šå¸¸æ˜¯ float32ã€‚</li><li>QLoRA å¾®è°ƒçš„æ˜¯ä¸€ä¸ª å·²é‡åŒ–çš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œä¾‹å¦‚ 4bit æˆ– 8bitã€‚æƒé‡æ˜¯ é‡åŒ–åçš„ uint8 æˆ– int8 æ ¼å¼ã€‚</li></ul><p>å†…å­˜ä¸æ¨ç†æ•ˆç‡ï¼š</p><ul><li>LoRA åœ¨å¾®è°ƒæ—¶å ç”¨çš„å†…å­˜è¾ƒå¤§ï¼Œå› ä¸ºå®ƒä½¿ç”¨çš„æ˜¯ å…¨ç²¾åº¦ çš„é¢„è®­ç»ƒæ¨¡å‹ï¼ˆé€šå¸¸æ˜¯ float32ï¼‰ã€‚</li><li>QLoRA çš„ä¼˜åŠ¿åœ¨äº å†…å­˜å ç”¨å¤§å¤§é™ä½ï¼Œå› ä¸ºæ¨¡å‹å·²ç»é‡åŒ–åˆ° 4bitã€‚å³ä½¿æ˜¯å¤§æ¨¡å‹ï¼Œä¹Ÿèƒ½åœ¨æœ‰é™çš„æ˜¾å­˜ä¸­è¿è¡Œã€‚</li></ul><p>ç›¸åŒç‚¹</p><ul><li>LoRA å’Œ QLoRA éƒ½æ˜¯é€šè¿‡è®­ç»ƒä¸€ä¸ª ä½ç§©é€‚é…çŸ©é˜µ æ¥å¾®è°ƒåŸå§‹æ¨¡å‹ï¼Œæ— éœ€ä¿®æ”¹åŸå§‹çš„é¢„è®­ç»ƒæƒé‡</li><li>ä¸¤è€…éƒ½åªè®­ç»ƒé€‚é…å±‚ï¼Œå› æ­¤å‚æ•°é‡ç›¸å¯¹è¾ƒå°‘ï¼Œé€‚åˆèµ„æºæœ‰é™çš„åœºæ™¯</li></ul><p>LoRAï¼ˆLow-Rank Adaptationï¼‰å¾®è°ƒæ­¥éª¤</p><ul><li>åŠ è½½ä¸€ä¸ª é¢„è®­ç»ƒæ¨¡å‹ï¼ˆé€šå¸¸æ˜¯ float32 æƒé‡ï¼‰ã€‚</li><li>å†»ç»“åŸå§‹æƒé‡ï¼Œåªè®­ç»ƒ LoRA çš„é€‚é…çŸ©é˜µã€‚</li><li>å¾®è°ƒæ—¶ï¼Œé€šè¿‡è®­ç»ƒ LoRA å±‚æ¥ä½¿æ¨¡å‹é€‚åº”ç‰¹å®šä»»åŠ¡ã€‚</li><li>æ¨ç†æ—¶ï¼Œä½¿ç”¨ åŸå§‹æƒé‡ åŠ ä¸Šè®­ç»ƒå¥½çš„ LoRA å±‚çš„é€‚é…çŸ©é˜µ</li></ul><p>QLoRAï¼ˆQuantized LoRAï¼‰å¾®è°ƒæ­¥éª¤</p><ul><li>é‡åŒ–é¢„è®­ç»ƒæ¨¡å‹ï¼šåŠ è½½ä¸€ä¸ª å·²ç»é‡åŒ–çš„æ¨¡å‹ï¼Œä¾‹å¦‚ 4bit æˆ– 8bit æ¨¡å‹ã€‚</li><li>å†»ç»“é‡åŒ–åçš„æƒé‡ï¼Œåªè®­ç»ƒ LoRA é€‚é…çŸ©é˜µã€‚</li><li>åœ¨ é‡åŒ–åçš„æ¨¡å‹ ä¸Šè¿›è¡Œå¾®è°ƒï¼Œä¼˜åŒ– LoRA å±‚çš„é€‚é…çŸ©é˜µã€‚</li><li>æ¨ç†æ—¶ï¼Œä»ç„¶ä½¿ç”¨ é‡åŒ–åçš„æƒé‡ï¼ŒåŠ ä¸Šè®­ç»ƒå¥½çš„ LoRA é€‚é…çŸ©é˜µã€‚</li></ul><h3 id="_5-2-ä¸ºä»€ä¹ˆé‡åŒ–é€šå¸¸åªç”¨äºçº¿æ€§å±‚" tabindex="-1"><a class="header-anchor" href="#_5-2-ä¸ºä»€ä¹ˆé‡åŒ–é€šå¸¸åªç”¨äºçº¿æ€§å±‚" aria-hidden="true">#</a> 5.2. ä¸ºä»€ä¹ˆé‡åŒ–é€šå¸¸åªç”¨äºçº¿æ€§å±‚ï¼Ÿ</h3><p>åŸå› å¯ä»¥ä»ä»¥ä¸‹å‡ ä¸ªè§’åº¦æ¥è§£é‡Šï¼šæ•°å­¦ã€å·¥ç¨‹å®ç°ã€å¯¹æ¨¡å‹å½±å“</p><ul><li>1.çº¿æ€§å±‚æ˜¯å‚æ•°æœ€å¤šã€è®¡ç®—é‡æœ€å¤§çš„éƒ¨åˆ†ï¼ˆå‚æ•°é›†ä¸­ï¼‰ <ul><li>å±‚å½’ä¸€åŒ–ï¼ˆLayerNormï¼‰ã€æ¿€æ´»å‡½æ•°ï¼ˆGELUï¼‰ã€Dropout ç­‰å‡ ä¹ä¸å«æƒé‡æˆ–åªæœ‰æå°‘é‡å‚æ•°</li><li>æ‰€ä»¥ä¼˜å…ˆé‡åŒ–çº¿æ€§å±‚ï¼Œæ”¶ç›Šæœ€å¤§ï¼Œä¸”å¯¹æ¨¡å‹ç»“æ„æ”¹åŠ¨æœ€å°</li></ul></li><li>2.çº¿æ€§å±‚ç»“æ„ç®€å•ã€ä¾¿äºé‡åŒ–å’Œè§£ç ï¼ˆæ•°å­¦ç»“æ„ç®€å•ï¼‰ <ul><li>çº¿æ€§å±‚æ˜¯å°‘æ•°å¯ä»¥åŒæ—¶é‡åŒ–æƒé‡ + æ¿€æ´» + æ¢¯åº¦çš„å±‚ï¼ˆå¦‚æœéœ€è¦ï¼‰ï¼Œæ‰€ä»¥å®ƒæˆä¸ºäº†ä¸»æˆ˜åœº</li><li>é‡åŒ–é€šå¸¸åˆ†ä¸ºä¸¤ç§ <ul><li>æƒé‡é‡åŒ–ï¼ˆWeight Quantizationï¼‰ï¼šå°† weight ä½ç²¾åº¦å­˜å‚¨ï¼ˆæœ€å¸¸è§ï¼‰</li><li>æ¿€æ´»é‡åŒ–ï¼ˆActivation Quantizationï¼‰ï¼šå¯¹ä¸­é—´å€¼è¿›è¡Œé‡åŒ–ï¼ˆæ›´å¤æ‚ï¼‰</li></ul></li><li>çº¿æ€§å˜æ¢æ˜¯ä¸€ä¸ªéå¸¸æ¸…æ™°ã€å›ºå®šçš„æ•°å­¦ç»“æ„ï¼Œé€‚åˆè¢«ï¼š <ul><li>ç¼–ç ä¸º 4-bit / 8-bit æ•°ç»„</li><li>è§£ç æ—¶ç”¨ scale + zero_point è¿›è¡Œæ¢å¤</li><li>ç”¨ kernel-fusion åŠ é€Ÿï¼ˆæ¯”å¦‚ bitsandbytes æä¾›çš„ CUDA å®ç°ï¼‰</li></ul></li></ul></li><li>3.éçº¿æ€§æ“ä½œä¸å¥½é‡åŒ–ï¼ˆå…¶ä»–å±‚ä¸é€‚åˆï¼Œé‡åŒ–çº¿æ€§å±‚å½±å“è¾ƒå°ï¼‰ <ul><li>è¿™äº›å±‚è¦ä¹ˆä¸å«å‚æ•°ï¼Œè¦ä¹ˆè¡Œä¸ºå˜åŒ–å¤§ï¼Œé‡åŒ–è¿™äº›éƒ¨åˆ†å¸¦æ¥çš„æ”¶ç›Šä¸æ˜æ˜¾ï¼Œåè€Œå¢åŠ å¤æ‚åº¦å’Œè¯¯å·® <ul><li>éçº¿æ€§å‡½æ•°ï¼ˆGELU, ReLUï¼‰æ²¡æœ‰å›ºå®šæƒé‡ï¼Œä¸å¥½æå‰ç¼–ç </li><li>å½’ä¸€åŒ–ï¼ˆLayerNorm, BatchNormï¼‰æ¶‰åŠåŠ¨æ€è®¡ç®—å‡å€¼ã€æ–¹å·®ã€é™¤æ³•ï¼Œä¸å¥½é™æ€é‡åŒ–</li><li>æ§åˆ¶ç»“æ„ï¼ˆDropout, Maskï¼‰è¡Œä¸ºåœ¨è®­ç»ƒ/æ¨ç†ä¸åŒï¼Œé‡åŒ–æ„ä¹‰ä¸å¤§</li></ul></li></ul></li><li>4.å·¥ç¨‹ä¸Šå·²ç»é«˜åº¦ä¼˜åŒ–äº†çº¿æ€§å±‚é‡åŒ–ï¼ˆå·¥ç¨‹å·²ä¼˜åŒ–ï¼‰ <ul><li>ç°æœ‰æ¡†æ¶éƒ½ä¸“æ³¨ä¼˜åŒ–äº† Linear, Conv è¿™äº›ç®—å­ï¼Œå¯¹éçº¿æ€§æ“ä½œæ”¯æŒå¾ˆå·®ç”šè‡³æ²¡æœ‰ <ul><li>bitsandbytes</li><li>Intel Neural Compressor</li><li>NVIDIA TensorRT</li><li>ONNX Runtime + QNNPACK</li></ul></li></ul></li></ul><h3 id="_5-3-ä¸ºä»€ä¹ˆä¸å¯¹-lm-head-å±‚è¿›è¡Œé‡åŒ–-è¿™ä¸ªä¹Ÿæ˜¯çº¿æ€§å±‚" tabindex="-1"><a class="header-anchor" href="#_5-3-ä¸ºä»€ä¹ˆä¸å¯¹-lm-head-å±‚è¿›è¡Œé‡åŒ–-è¿™ä¸ªä¹Ÿæ˜¯çº¿æ€§å±‚" aria-hidden="true">#</a> 5.3. ä¸ºä»€ä¹ˆä¸å¯¹ lm_head å±‚è¿›è¡Œé‡åŒ–ï¼Œè¿™ä¸ªä¹Ÿæ˜¯çº¿æ€§å±‚?</h3><p>æŒ‰é“ç†è®²ï¼Œè¿™ä¸ªå±‚ä¹Ÿå¯ä»¥é‡åŒ–ï¼Œä½†å®ƒé»˜è®¤å¹¶æ²¡æœ‰è¢«é‡åŒ–</p><p>åŸå› ä¸»è¦æ˜¯ä»¥ä¸‹å‡ ä¸ªï¼š</p><ul><li>1.lm_head ç”¨äºè¾“å‡º â†’ ç²¾åº¦å½±å“æ›´æ•æ„Ÿ ï¼ˆç²¾åº¦æ•æ„Ÿï¼‰ <ul><li>lm_head æ˜¯æ¨¡å‹çš„æœ€åä¸€å±‚ï¼Œç”¨äºå°†éšè—çŠ¶æ€æŠ•å½±åˆ°è¯è¡¨ï¼ˆvocabï¼‰ç©ºé—´ï¼Œè¾“å‡º logits</li><li>è¿™ä¸€å±‚çš„è¾“å‡ºç›´æ¥å½±å“ï¼š <ul><li>softmax çš„åˆ†å¸ƒ</li><li>é¢„æµ‹çš„ token æ’åº</li><li>æœ€ç»ˆç”Ÿæˆæ–‡æœ¬çš„è´¨é‡</li></ul></li><li>æ‰€ä»¥ï¼Œå®ƒå¯¹ç²¾åº¦éå¸¸æ•æ„Ÿã€‚è½»å¾®çš„æƒé‡è¯¯å·®å¯èƒ½å°±ä¼šå¯¼è‡´ token æ’åºé”™è¯¯ï¼Œç”Ÿæˆå®Œå…¨ä¸åŒçš„ç»“æœ</li></ul></li><li>2.å¤§å¤šæ•°é‡åŒ–æ¡†æ¶é»˜è®¤è·³è¿‡ lm_head ï¼ˆæ¡†æ¶é»˜è®¤è¡Œä¸ºï¼Œç©ºé—´èŠ‚çœæœ‰é™ï¼‰ <ul><li>æ¯”å¦‚ bitsandbytesã€AutoGPTQ ç­‰ï¼Œåœ¨é‡åŒ– Transformer æ¨¡å‹æ—¶é»˜è®¤ä¸å¯¹ lm_head åš 4-bit é‡åŒ–ï¼Œå› ä¸ºï¼š <ul><li>è¿™ä¸€å±‚é€šå¸¸åªæœ‰ä¸€ä»½ï¼ˆä¸åƒ attention å’Œ MLP æœ‰å¾ˆå¤šå±‚ï¼‰</li><li>ç²¾åº¦å½±å“æ›´å¤§</li><li>èŠ‚çœç©ºé—´æœ‰é™ï¼ˆç›¸å¯¹æ•´æ¨¡å‹æ¥è¯´ï¼‰ï¼Œé‡åŒ–æ„ä¹‰ä¸å¤§</li></ul></li></ul></li><li>3.å¯èƒ½ç”¨äºæƒé‡å…±äº«ï¼ˆtie_weightsï¼‰ï¼ˆæƒé‡å…±äº«ï¼Œä¸ embedding æƒé‡ç»‘å®šï¼Œé‡åŒ–å¯èƒ½ä¸å…¼å®¹ï¼‰ <ul><li>æœ‰äº›æ¨¡å‹ä¸­ï¼Œlm_head.weight æ˜¯å’ŒåµŒå…¥å±‚ wte.weight å…±äº«æƒé‡çš„ï¼ˆtie-weightsï¼‰</li><li>æ­¤æ—¶é‡åŒ– lm_head å°±ä¼šå½±å“åµŒå…¥ â†’ ç¼–ç  â†’ è§£ç çš„æ•´ä¸ªé—­ç¯</li><li>å¦‚æœä½ é‡åŒ–äº† lm_headï¼Œä½†æ²¡åŒæ­¥é‡åŒ– wteï¼Œæˆ–è€…åä¹‹ï¼Œå¯èƒ½å¯¼è‡´ä¸ä¸€è‡´ç”šè‡³æŠ¥é”™</li></ul></li></ul><h3 id="_5-4-ä¸ºä»€ä¹ˆéçº¿æ€§å±‚åœ¨é‡åŒ–åçš„dtypeä¹Ÿæœ‰å˜åŒ–-å˜ä¸ºfloat16" tabindex="-1"><a class="header-anchor" href="#_5-4-ä¸ºä»€ä¹ˆéçº¿æ€§å±‚åœ¨é‡åŒ–åçš„dtypeä¹Ÿæœ‰å˜åŒ–-å˜ä¸ºfloat16" aria-hidden="true">#</a> 5.4. ä¸ºä»€ä¹ˆéçº¿æ€§å±‚åœ¨é‡åŒ–åçš„dtypeä¹Ÿæœ‰å˜åŒ–ï¼Œå˜ä¸ºfloat16ï¼Ÿ</h3><p>è™½ç„¶æ²¡æœ‰æ˜¾å¼è®¾ç½®è¿™äº›å±‚çš„ dtypeï¼Œä½†å®ƒä»¬ä¼šåœ¨ load_in_4bit=True æ—¶è‡ªåŠ¨è¢«è½¬æ¢æˆæ›´è½»é‡çš„ç²¾åº¦</p><p>è¿™å…¶å®æ˜¯ transformers çš„ AutoPrecision æ¨ç†æœºåˆ¶ï¼ˆè‡ªåŠ¨è°ƒåº¦ï¼‰çš„ä¸€éƒ¨åˆ†ï¼Œå’Œ bitsandbytes ä¸€èµ·é…åˆä½¿ç”¨</p><h3 id="_5-5-é‡åŒ–æ¨¡å‹ç²¾åº¦å‘ç”Ÿäº†ä»€ä¹ˆå˜åŒ–" tabindex="-1"><a class="header-anchor" href="#_5-5-é‡åŒ–æ¨¡å‹ç²¾åº¦å‘ç”Ÿäº†ä»€ä¹ˆå˜åŒ–" aria-hidden="true">#</a> 5.5. é‡åŒ–æ¨¡å‹ç²¾åº¦å‘ç”Ÿäº†ä»€ä¹ˆå˜åŒ–?</h3><ul><li>åŸå§‹æ¨¡å‹ç²¾åº¦ä¸º float32 (ç£ç›˜)</li><li>é‡åŒ–æ¨¡å‹çš„æƒé‡ä»¥ int4 å­˜å‚¨ï¼ˆpacked uint8ï¼‰ ï¼ˆæ˜¾å­˜ï¼‰</li><li>input float32/bfloat16 (å¤–éƒ¨ä¼ å…¥)</li><li>æƒé‡ int4 ä¸´æ—¶è§£ç æˆ bfloat16 è®¡ç®—</li><li>double quant â†’ å†å‹ç¼© scaleï¼Œå‡å°‘è´Ÿæ‹…</li><li>output bfloat16 â†’ åç»­å±‚å¯ä»¥ç»§ç»­ä½ç²¾åº¦æ‰§è¡Œ</li></ul><p>Note1ï¼šåªæœ‰çº¿æ€§å±‚çš„å­˜å‚¨ä¸º4bitï¼Œå…¶ä»–å±‚çš„å­˜å‚¨ã€è®¡ç®—ã€è§£ç è¾“å‡ºè¿™äº›éƒ½æ˜¯bfloat16/float16</p><p>Note2ï¼šæ¨ç†æ—¶ä¸ä¼šæ”¹å˜æ¨¡å‹çš„å‚æ•°ï¼Œåªæœ‰åå‘ä¼ æ’­æ—¶æ‰ä¼šæ”¹å˜ï¼Œæ¨ç†æ—¶bit4çš„ä¸´æ—¶å˜ä¸ºbfloat16è¿›è¡Œè®¡ç®—ï¼Œç„¶åè¾“å‡ºç»“æœoutputä¹Ÿæ˜¯bfloat16ç±»å‹çš„</p><p>Note3ï¼šå¾®è°ƒé‡åŒ–æ¨¡å‹ï¼ˆæ¯”å¦‚ LoRA + 4bitï¼‰ï¼Œä¹Ÿæ˜¯åªæ›´æ–°éƒ¨åˆ† float å‚æ•°ï¼ˆå¦‚ LoRA adapterï¼‰ï¼Œ4bit æƒé‡æœ¬èº«ä¸ä¼šç›´æ¥ä¿®æ”¹</p><h3 id="_5-6-bnb-4bit-compute-dtype-torch-bfloat16æ˜¯åšä»€ä¹ˆçš„-è®¡ç®—ç²¾åº¦å’Œå­˜å‚¨ç²¾åº¦ä¸åŒ" tabindex="-1"><a class="header-anchor" href="#_5-6-bnb-4bit-compute-dtype-torch-bfloat16æ˜¯åšä»€ä¹ˆçš„-è®¡ç®—ç²¾åº¦å’Œå­˜å‚¨ç²¾åº¦ä¸åŒ" aria-hidden="true">#</a> 5.6. bnb_4bit_compute_dtype=torch.bfloat16æ˜¯åšä»€ä¹ˆçš„ï¼Œè®¡ç®—ç²¾åº¦å’Œå­˜å‚¨ç²¾åº¦ä¸åŒï¼Ÿ</h3><p>é»˜è®¤æƒ…å†µï¼Œå³ä½¿ä½ é‡åŒ–äº†å‚æ•°ï¼Œè®¡ç®—æ—¶è¿˜æ˜¯ float32</p><p>æ‰€ä»¥å¯ä»¥è®¾ç½®è®¡ç®—ç²¾åº¦ä¸ºtorch.bfloat16 æˆ– torch.float16æ¥åŠ é€Ÿè®¡ç®—è¿‡ç¨‹ï¼Œå‡å°‘æ˜¾å­˜å ç”¨</p><p>è®¡ç®—ç²¾åº¦è¿™ä¸ª dtype æ˜¯åœ¨ Linear4bit å†…éƒ¨è¿è¡Œæ—¶è®¾ç½®çš„ï¼Œå±äºå†…éƒ¨è®¡ç®—é€»è¾‘</p><h3 id="_5-7-ä¸´æ—¶æ€§é‡åŒ–ä¸æ°¸ä¹…å­˜å‚¨" tabindex="-1"><a class="header-anchor" href="#_5-7-ä¸´æ—¶æ€§é‡åŒ–ä¸æ°¸ä¹…å­˜å‚¨" aria-hidden="true">#</a> 5.7. ä¸´æ—¶æ€§é‡åŒ–ä¸æ°¸ä¹…å­˜å‚¨ï¼Ÿ</h3><ul><li>ä¸´æ—¶æ€§é‡åŒ– <ul><li>åŠ è½½åŸå§‹çš„ float32 æƒé‡æ¨¡å‹ï¼Œæ ¹æ®é‡åŒ–é…ç½®è¿›è¡Œé‡åŒ–å­˜åœ¨å†…å­˜ä¸­</li><li>æ¨ç†æ—¶ä»å†…å­˜ä¸­è·å–4bitä¸´æ—¶è½¬ä¸ºbfloat16è¿›è¡Œè®¡ç®—</li><li>å…³é”® <ul><li>é‡åŒ–æ¨¡å‹çš„ 4bit æƒé‡åªåœ¨å†…å­˜ä¸­å­˜åœ¨ï¼Œå®ƒä»¬æ˜¯ä¸´æ—¶çš„ï¼Œä¸ä¼šè¢«æ°¸ä¹…ä¿å­˜</li><li>å¹¶æ²¡æœ‰æ”¹å˜ç£ç›˜ä¸Šçš„åŸå§‹æ¨¡å‹æ–‡ä»¶ï¼Œè€Œæ˜¯åªå½±å“äº†å†…å­˜ä¸­çš„è®¡ç®—æ–¹å¼</li></ul></li></ul></li><li>æ°¸ä¹…ä¿å­˜ <ul><li>ä¿å­˜æ¨¡å‹çš„é‡åŒ–ç‰ˆæœ¬ï¼ŒåŠ è½½æ¨¡å‹æ—¶ç›´æ¥åŠ è½½é‡åŒ–åçš„æ¨¡å‹ï¼Œä¸éœ€è¦è¿›è¡Œé‡åŒ–é…ç½®</li></ul></li></ul><h3 id="_5-8-qloraå­˜å‚¨è®­ç»ƒå¥½çš„æ¨¡å‹æ˜¯æŒ‰ä»€ä¹ˆç²¾åº¦å­˜å‚¨çš„" tabindex="-1"><a class="header-anchor" href="#_5-8-qloraå­˜å‚¨è®­ç»ƒå¥½çš„æ¨¡å‹æ˜¯æŒ‰ä»€ä¹ˆç²¾åº¦å­˜å‚¨çš„" aria-hidden="true">#</a> 5.8. qloraå­˜å‚¨è®­ç»ƒå¥½çš„æ¨¡å‹æ˜¯æŒ‰ä»€ä¹ˆç²¾åº¦å­˜å‚¨çš„ï¼Ÿ</h3><p>QLoRA åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­çš„é‡åŒ–å’Œå­˜å‚¨è¿‡ç¨‹æœ‰ä¸¤ç§å¸¸è§çš„ç­–ç•¥</p><ul><li>æƒ…å†µ 1ï¼šè®­ç»ƒæ—¶é‡åŒ–ï¼Œå­˜å‚¨æ—¶ä¿ç•™åŸå§‹æ¨¡å‹çš„ float32 æƒé‡ <ul><li>åŸå§‹æ¨¡å‹çš„æƒé‡ä»ç„¶ä¼šæ¢å¤ä¸º float32 æ ¼å¼ï¼Œè€Œä¸æ˜¯ä»¥é‡åŒ–åçš„æ ¼å¼ä¿å­˜</li><li>é‡åŒ–æ“ä½œé€šå¸¸æ˜¯åœ¨æ¨ç†æ—¶ä¸´æ—¶åº”ç”¨çš„ï¼Œé‡åŒ–æƒé‡åœ¨è®­ç»ƒæ—¶åªæ˜¯ä¸ºäº†èŠ‚çœå†…å­˜å’ŒåŠ é€Ÿè®¡ç®—ï¼Œä½†ä¸ä¸€å®šè¦æ°¸ä¹…å­˜å‚¨</li><li>å°†åŸå§‹æ¨¡å‹ä¿å­˜åœ¨ float32 æ ¼å¼ å¯ä»¥ç¡®ä¿æ›´å¥½çš„æ¨¡å‹å…¼å®¹æ€§å’Œåç»­çš„æ˜“ç”¨æ€§</li><li>LoRA é€‚é…å±‚ï¼šLoRA å±‚çš„é€‚é…æƒé‡ ä»ç„¶æ˜¯ float32 æ ¼å¼ï¼Œä¼šå’ŒåŸå§‹æ¨¡å‹ä¸€èµ·å­˜å‚¨</li><li>QLoRA ä¿å­˜çš„æ¨¡å‹æ˜¯ï¼š <ul><li>å­˜å‚¨çš„æ˜¯åŸå§‹æ¨¡å‹çš„æƒé‡float32æ ¼å¼ã€‚</li><li>å­˜å‚¨çš„æ˜¯ LoRA é€‚é…å±‚çš„æƒé‡ï¼Œè¿™äº›é€‚é…å±‚ä¾ç„¶æ˜¯ float32 ç²¾åº¦çš„ã€‚</li></ul></li></ul></li><li>æƒ…å†µ 2ï¼šè®­ç»ƒå’Œå­˜å‚¨æ—¶éƒ½é‡åŒ– <ul><li>è¿™ç§æ–¹æ³•ä¸»è¦ç”¨äº èŠ‚çœå­˜å‚¨ç©ºé—´ å’Œ åŠ é€Ÿæ¨ç†</li><li>QLoRA ä¿å­˜çš„æ¨¡å‹æ˜¯ï¼š <ul><li>å­˜å‚¨çš„æ˜¯ é‡åŒ–åçš„æ¨¡å‹ï¼Œå³ 4bitï¼ˆé€šå¸¸æ˜¯ uint8ï¼‰æƒé‡ã€‚</li><li>å­˜å‚¨çš„æ˜¯ LoRA é€‚é…å±‚çš„æƒé‡ï¼Œè¿™äº›é€‚é…å±‚ä¾ç„¶æ˜¯ float32 ç²¾åº¦çš„ã€‚</li></ul></li></ul></li></ul><p>ä¸éœ€è¦å°† LoRA é€‚é…å±‚æƒé‡å’Œæ¨¡å‹æƒé‡çš„æ•°æ®ç±»å‹ä¿æŒä¸€è‡´å—ï¼Ÿç­”ï¼šæ•°æ®ç±»å‹ä¸å¿…å®Œå…¨ä¸€è‡´ï¼ŒåŸå› å¦‚ä¸‹</p><ul><li>LoRA é€‚é…å±‚ä¸åŸå§‹æ¨¡å‹æƒé‡çš„ç‹¬ç«‹æ€§</li><li>LoRA å±‚æƒé‡å’Œé‡åŒ–åçš„æ¨¡å‹æƒé‡çš„æ•°æ®ç±»å‹ä¸ä¸€è‡´å¹¶ä¸å†²çª <ul><li>æ¨ç†æ—¶ï¼Œé‡åŒ–çš„æƒé‡ï¼ˆä¾‹å¦‚ 4bitï¼‰ä¼šé€šè¿‡åé‡åŒ–è¿‡ç¨‹æ¢å¤ä¸º float16 æˆ– bfloat16 æ ¼å¼è¿›è¡Œè®¡ç®—ï¼Œè€Œ LoRA å±‚çš„æƒé‡ï¼ˆfloat32ï¼‰ä¾ç„¶å‚ä¸è®¡ç®—ï¼ŒäºŒè€…çš„ç²¾åº¦ä¸ä¸€è‡´ä¸ä¼šå¯¼è‡´é—®é¢˜</li></ul></li></ul><h2 id="_6-qlora-ç»†èŠ‚è¡¥å……" tabindex="-1"><a class="header-anchor" href="#_6-qlora-ç»†èŠ‚è¡¥å……" aria-hidden="true">#</a> 6. QLoRA ç»†èŠ‚è¡¥å……</h2><h3 id="_6-1-device-map" tabindex="-1"><a class="header-anchor" href="#_6-1-device-map" aria-hidden="true">#</a> 6.1. device_map</h3><p>device_map æ˜¯ä¸€ä¸ªå­—å…¸ï¼Œç”¨äºå‘Šè¯‰æ¨¡å‹åŠ è½½å™¨ï¼ˆæ¯”å¦‚ transformers ä¸­çš„ AutoModel.from_pretrainedï¼‰å°†æ¨¡å‹çš„å„ä¸ªéƒ¨åˆ†åŠ è½½åˆ°å“ªäº›è®¾å¤‡ä¸Šã€‚é”®ï¼ˆkeyï¼‰é€šå¸¸è¡¨ç¤ºæ¨¡å‹çš„æŸä¸ªéƒ¨åˆ†ï¼ˆä¾‹å¦‚å±‚æˆ–æ¨¡å—çš„åç§°ï¼‰ï¼Œå€¼ï¼ˆvalueï¼‰è¡¨ç¤ºè®¾å¤‡ç¼–å·æˆ–è®¾å¤‡åç§°ï¼ˆä¾‹å¦‚ GPU çš„ç´¢å¼•å· 0ã€1ï¼Œæˆ–è€… &quot;cpu&quot;ï¼‰ã€‚</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>device_map={&quot;&quot;: 0}  # å°†æ•´ä¸ªæ¨¡å‹åŠ è½½åˆ° GPU 0ï¼ˆè®¾å¤‡ç¼–å·ä¸º 0 çš„è®¾å¤‡ä¸Šï¼‰ï¼ˆç©ºå­—ç¬¦ä¸²è¡¨ç¤ºæ•´ä¸ªæ¨¡å‹ï¼›åœ¨ PyTorch ä¸­ï¼Œ0 é€šå¸¸å¯¹åº”äºç¬¬ä¸€ä¸ª GPUï¼ˆå³ cuda:0ï¼‰ï¼‰
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>device_map = {
    &quot;transformer.layer.0&quot;: 0,  # ç¬¬ 0 å±‚åŠ è½½åˆ° GPU 0
    &quot;transformer.layer.1&quot;: 1   # ç¬¬ 1 å±‚åŠ è½½åˆ° GPU 1
}
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>device_map = &quot;auto&quot; # æ ¹æ®å¯ç”¨è®¾å¤‡è‡ªåŠ¨åˆ†é…æ¨¡å‹ï¼ˆéœ€è¦ accelerate åº“æ”¯æŒï¼‰
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>å»¶ä¼¸ï¼šå¦‚ä½•æ£€æŸ¥ GPU å¯ç”¨è®¾å¤‡</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>import torch
print(torch.cuda.is_available())  # æ£€æŸ¥æ˜¯å¦æœ‰ GPU
print(torch.cuda.device_count())  # æ£€æŸ¥ GPU æ•°é‡
print(torch.cuda.current_device())  # å½“å‰é»˜è®¤ GPU ç¼–å·
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_6-2-seed-42-æ˜¯å¸¸è§-é­”æ³•æ•°å­—" tabindex="-1"><a class="header-anchor" href="#_6-2-seed-42-æ˜¯å¸¸è§-é­”æ³•æ•°å­—" aria-hidden="true">#</a> 6.2. seed=42 æ˜¯å¸¸è§â€œé­”æ³•æ•°å­—â€</h3><p>42 æ˜¯ä¸ªæƒ¯ä¾‹å€¼ï¼Œå‡ºè‡ªã€Šé“¶æ²³ç³»æ¼«æ¸¸æŒ‡å—ã€‹ï¼Œè¡¨ç¤ºâ€œç”Ÿå‘½ã€å®‡å®™ä»¥åŠä¸€åˆ‡é—®é¢˜çš„ç»ˆæç­”æ¡ˆâ€ã€‚å½“ç„¶ä½ ç”¨ 123 æˆ–åˆ«çš„å€¼ä¹Ÿå®Œå…¨æ²¡é—®é¢˜ï¼Œåªè¦ä¿è¯æ¯æ¬¡ç”¨ä¸€æ ·çš„ seedå°±èƒ½å¤ç°</p><h2 id="_7-reference" tabindex="-1"><a class="header-anchor" href="#_7-reference" aria-hidden="true">#</a> 7. Reference</h2><ul><li>huggingface SFTTrainer: https://huggingface.co/docs/trl/v0.7.4/en/sft_trainer</li><li>google: https://ai.google.dev/gemma/docs/core/huggingface_text_finetune_qlora</li><li>unsloth: https://huggingface.co/blog/Andyrasika/finetune-unsloth-qlora</li></ul></div><!--[--><!----><!--]--><footer class="page-meta"><!----><div class="meta-item git-info"><!----><!----></div></footer><nav class="vp-page-nav"><a aria-label="SFTTrainer Sourcecode -- Prepare Model" class="vp-link nav-link prev nav-link prev" href="/blog/zh/posts/llm/032_sft_trainer_sourcecode_prepare_model.html"><div class="hint"><span class="arrow start"></span>ä¸Šä¸€é¡µ</div><div class="link"><span class="font-icon icon fa-fw fa-sm fas fa-lightbulb" style=""></span>SFTTrainer Sourcecode -- Prepare Model</div></a><a aria-label="æ·±åº¦å­¦ä¹ è½»é‡çº§å¯è§†åŒ–å·¥å…·wandb" class="vp-link nav-link next nav-link next" href="/blog/zh/posts/llm/030_wandb.html"><div class="hint">ä¸‹ä¸€é¡µ<span class="arrow end"></span></div><div class="link">æ·±åº¦å­¦ä¹ è½»é‡çº§å¯è§†åŒ–å·¥å…·wandb<span class="font-icon icon fa-fw fa-sm fas fa-lightbulb" style=""></span></div></a></nav><!----><!--[--><!----><!--]--><!--]--></main><!--]--><!----></div><!--]--><!--]--><!----><!--]--></div>
    <script type="module" src="/blog/assets/app-kXW_Y_m4.js" defer></script>
  </body>
</html>
