<!doctype html>
<html lang="en-US" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.0" />
    <meta name="theme" content="VuePress Theme Hope 2.0.0-rc.13" />
    <style>
      html {
        background: var(--bg-color, #fff);
      }

      html[data-theme="dark"] {
        background: var(--bg-color, #1d1e1f);
      }

      body {
        background: var(--bg-color);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <link rel="alternate" hreflang="zh-cn" href="https://liz-starfield.github.io/blog/zh/posts/pytorch/04_pytorch_practice_nn.html"><meta property="og:url" content="https://liz-starfield.github.io/blog/posts/pytorch/04_pytorch_practice_nn.html"><meta property="og:site_name" content="Liz"><meta property="og:title" content="Deep Learning Practice with PyTorch"><meta property="og:description" content="Deep Learning Practice with PyTorch PyTorch's APIs Data Loading and Preprocessing Defining Network Models Defining Loss Function and Optimizer Training the Network Testing the Network Saving and Loading Models GPU Acceleration Visualization with TensorBoard"><meta property="og:type" content="article"><meta property="og:locale" content="en-US"><meta property="og:locale:alternate" content="zh-CN"><meta property="og:updated_time" content="2024-02-29T04:35:55.000Z"><meta property="article:author" content="Liz"><meta property="article:tag" content="Pytorch"><meta property="article:published_time" content="2022-07-23T00:00:00.000Z"><meta property="article:modified_time" content="2024-02-29T04:35:55.000Z"><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"Deep Learning Practice with PyTorch","image":[""],"datePublished":"2022-07-23T00:00:00.000Z","dateModified":"2024-02-29T04:35:55.000Z","author":[{"@type":"Person","name":"Liz","url":"https://github.com/liz-starfield"}]}</script><link rel="icon" herf="/blogger.png"><link rel="icon" href="/blog/blogger.png"><title>Deep Learning Practice with PyTorch | Liz</title><meta name="description" content="Deep Learning Practice with PyTorch PyTorch's APIs Data Loading and Preprocessing Defining Network Models Defining Loss Function and Optimizer Training the Network Testing the Network Saving and Loading Models GPU Acceleration Visualization with TensorBoard">
    <link rel="preload" href="/blog/assets/style-mq-Wkm9q.css" as="style"><link rel="stylesheet" href="/blog/assets/style-mq-Wkm9q.css">
    <link rel="modulepreload" href="/blog/assets/app-KJHtdF_7.js"><link rel="modulepreload" href="/blog/assets/04_pytorch_practice_nn.html-mWwWmcJ8.js"><link rel="modulepreload" href="/blog/assets/plugin-vue_export-helper-x3n3nnut.js"><link rel="modulepreload" href="/blog/assets/04_pytorch_practice_nn.html-k-oRm6yz.js">
    <link rel="prefetch" href="/blog/assets/index.html-LFD91XO_.js" as="script"><link rel="prefetch" href="/blog/assets/intro.html-E6FIGQFr.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-8pZ41A_w.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-PxUfOlrM.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-s_datAw3.js" as="script"><link rel="prefetch" href="/blog/assets/intro.html-3kAZxSDz.js" as="script"><link rel="prefetch" href="/blog/assets/langchain.html-zKUtrlMr.js" as="script"><link rel="prefetch" href="/blog/assets/langchain_source_code.html-hLzF0c4R.js" as="script"><link rel="prefetch" href="/blog/assets/streamlit.html-EoCnwOlO.js" as="script"><link rel="prefetch" href="/blog/assets/01_python_environment.html-5fJs1XZK.js" as="script"><link rel="prefetch" href="/blog/assets/02_python_data_type.html-yqen_xfq.js" as="script"><link rel="prefetch" href="/blog/assets/03_python_operator.html-9_6xioiS.js" as="script"><link rel="prefetch" href="/blog/assets/04_python_method.html-IrOHK25K.js" as="script"><link rel="prefetch" href="/blog/assets/05_python_builtin_module.html-VwjNAomq.js" as="script"><link rel="prefetch" href="/blog/assets/06_python_popular_package.html-6--ZbeB9.js" as="script"><link rel="prefetch" href="/blog/assets/01_ai_concept.html-1dsmjxhQ.js" as="script"><link rel="prefetch" href="/blog/assets/02_neural_net_train.html-MX0ksQLN.js" as="script"><link rel="prefetch" href="/blog/assets/03_pytorch_operation.html-eCRdWA85.js" as="script"><link rel="prefetch" href="/blog/assets/05_linear_nn.html-m_m1sUSe.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-f_nlM_7J.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ZYhhb8JE.js" as="script"><link rel="prefetch" href="/blog/assets/langchain.html-SCmjtC1i.js" as="script"><link rel="prefetch" href="/blog/assets/langchain_source_code.html-z5i49H-V.js" as="script"><link rel="prefetch" href="/blog/assets/streamlit.html-iUfqazN1.js" as="script"><link rel="prefetch" href="/blog/assets/01_python_environment.html-6W1uTEtk.js" as="script"><link rel="prefetch" href="/blog/assets/02_python_data_type.html-leOQa_Y1.js" as="script"><link rel="prefetch" href="/blog/assets/03_python_operator.html-ZpTatogN.js" as="script"><link rel="prefetch" href="/blog/assets/04_python_method.html-RoP1I2kq.js" as="script"><link rel="prefetch" href="/blog/assets/05_python_builtin_module.html-Q8n1oyzt.js" as="script"><link rel="prefetch" href="/blog/assets/06_python_popular_package.html-D_hwoRQE.js" as="script"><link rel="prefetch" href="/blog/assets/01_ai_concept.html-sQ3f7eMA.js" as="script"><link rel="prefetch" href="/blog/assets/02_neural_net_train.html-ANQdT1B0.js" as="script"><link rel="prefetch" href="/blog/assets/03_pytorch_operation.html-YMujwhKY.js" as="script"><link rel="prefetch" href="/blog/assets/04_pytorch_practice_nn.html-QQ109Ack.js" as="script"><link rel="prefetch" href="/blog/assets/05_linear_nn.html-vHRH7ymp.js" as="script"><link rel="prefetch" href="/blog/assets/404.html-_gRo7Dcd.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-UxATL_0T.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Mv3ej2IF.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-hZU6eHY7.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-kJ320kxl.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-PCaJfeIo.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-EqHBUaBn.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-VOr9nBXB.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-lMZf9nw6.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-8E67PwBh.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-qostYW_M.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-T-uPJpYq.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-VpAiyB26.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-67j3W8G7.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-bys25b8k.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-NSZidhQD.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-sh1juioO.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ZDxccGry.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-m34kEvDY.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Kzol0OIK.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-m0dv9t6y.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-4rWeg-rw.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-dxLqYysi.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-SVlXYkho.js" as="script"><link rel="prefetch" href="/blog/assets/index.html--IEIJJE7.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-gikpHa9b.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-YVQ3Gxv8.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-yX1j37_q.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-qnPGVL8b.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-a9hcFS-z.js" as="script"><link rel="prefetch" href="/blog/assets/intro.html-K0o90Bjt.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-j6W8Seqh.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-zcudztNd.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-oLrabP9l.js" as="script"><link rel="prefetch" href="/blog/assets/intro.html-pIVVRu0G.js" as="script"><link rel="prefetch" href="/blog/assets/langchain.html-P5cfLis_.js" as="script"><link rel="prefetch" href="/blog/assets/langchain_source_code.html-VtN2LzYN.js" as="script"><link rel="prefetch" href="/blog/assets/streamlit.html-SaZtX5Xy.js" as="script"><link rel="prefetch" href="/blog/assets/01_python_environment.html-wXaTkSXW.js" as="script"><link rel="prefetch" href="/blog/assets/02_python_data_type.html-Oej936mM.js" as="script"><link rel="prefetch" href="/blog/assets/03_python_operator.html-16jjuJqH.js" as="script"><link rel="prefetch" href="/blog/assets/04_python_method.html-0l6oCkYw.js" as="script"><link rel="prefetch" href="/blog/assets/05_python_builtin_module.html-wK2OnZnN.js" as="script"><link rel="prefetch" href="/blog/assets/06_python_popular_package.html-EqsXzeOU.js" as="script"><link rel="prefetch" href="/blog/assets/01_ai_concept.html-lypThr2E.js" as="script"><link rel="prefetch" href="/blog/assets/02_neural_net_train.html-XBfEz9J_.js" as="script"><link rel="prefetch" href="/blog/assets/03_pytorch_operation.html-9pIpfOIF.js" as="script"><link rel="prefetch" href="/blog/assets/05_linear_nn.html-L7gTMWDd.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ByDiazy3.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-FA8XMDGi.js" as="script"><link rel="prefetch" href="/blog/assets/langchain.html-BEw_6x7q.js" as="script"><link rel="prefetch" href="/blog/assets/langchain_source_code.html-VeIwQhho.js" as="script"><link rel="prefetch" href="/blog/assets/streamlit.html-hIznomlM.js" as="script"><link rel="prefetch" href="/blog/assets/01_python_environment.html-mS86_Yn_.js" as="script"><link rel="prefetch" href="/blog/assets/02_python_data_type.html-EW-JhV2l.js" as="script"><link rel="prefetch" href="/blog/assets/03_python_operator.html-taALZURh.js" as="script"><link rel="prefetch" href="/blog/assets/04_python_method.html-ILMaSrgW.js" as="script"><link rel="prefetch" href="/blog/assets/05_python_builtin_module.html-gBSRBuGH.js" as="script"><link rel="prefetch" href="/blog/assets/06_python_popular_package.html-RGYgPgRh.js" as="script"><link rel="prefetch" href="/blog/assets/01_ai_concept.html-C9bLoEHB.js" as="script"><link rel="prefetch" href="/blog/assets/02_neural_net_train.html-6HfNkp5B.js" as="script"><link rel="prefetch" href="/blog/assets/03_pytorch_operation.html-wwW-eIki.js" as="script"><link rel="prefetch" href="/blog/assets/04_pytorch_practice_nn.html-qBttG4yb.js" as="script"><link rel="prefetch" href="/blog/assets/05_linear_nn.html--ZpMcsv_.js" as="script"><link rel="prefetch" href="/blog/assets/404.html-shSVykYl.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-gU25xLDT.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-bIaGApMR.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Kob2rJqA.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-IKHGtc2O.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-A_ZZySZ6.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-zoc7ZdNt.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-4TR_hXm2.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-7yHWdVK0.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-9Az8N6qW.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-JivdOh_T.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-iA7lmOnN.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-VUBIJ3Lx.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-kwRUnD-q.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-W62g8Bbd.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-FcXzt0K_.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-f88Ap3Tv.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-hl4Gm-vf.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-RZvnsHlN.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-iQ5pHCFu.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-2XytNdRr.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-O4KriSIe.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-vVtUNqn6.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-sM4kqI-n.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-7iCT1bG6.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ajTpwjpA.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-U_cqGklF.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-IgcLx_0q.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-9askE3Q5.js" as="script"><link rel="prefetch" href="/blog/assets/photoswipe.esm-08_zHRDQ.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">Skip to main content</a><!--]--><!--[--><div class="theme-container has-toc"><!--[--><header id="navbar" class="vp-navbar"><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!--[--><!----><!--]--><!--[--><a class="vp-link vp-brand vp-brand" href="/blog/"><img class="vp-nav-logo" src="/blog/blogger.png" alt><!----><span class="vp-site-name hide-in-pad">Liz</span></a><!--]--><!--[--><!----><!--]--></div><div class="vp-navbar-center"><!--[--><!----><!--]--><!--[--><nav class="vp-nav-links"><div class="nav-item hide-in-mobile"><a aria-label="Home" class="vp-link nav-link nav-link" href="/blog/"><span class="font-icon icon fa-fw fa-sm fas fa-home" style=""></span>Home<!----></a></div><div class="nav-item hide-in-mobile"><a aria-label="Blog" class="vp-link nav-link active nav-link active" href="/blog/posts/"><span class="font-icon icon fa-fw fa-sm fas fa-book" style=""></span>Blog<!----></a></div><div class="nav-item hide-in-mobile"><a aria-label="Project" class="vp-link nav-link nav-link" href="/blog/demo/"><span class="font-icon icon fa-fw fa-sm fas fa-star" style=""></span>Project<!----></a></div></nav><!--]--><!--[--><!----><!--]--></div><div class="vp-navbar-end"><!--[--><!----><!--]--><!--[--><div class="nav-item"><div class="dropdown-wrapper i18n-dropdown"><button type="button" class="dropdown-title" aria-label="Select language"><!--[--><svg xmlns="http://www.w3.org/2000/svg" class="icon i18n-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="i18n icon" style="width:1rem;height:1rem;vertical-align:middle;"><path d="M379.392 460.8 494.08 575.488l-42.496 102.4L307.2 532.48 138.24 701.44l-71.68-72.704L234.496 460.8l-45.056-45.056c-27.136-27.136-51.2-66.56-66.56-108.544h112.64c7.68 14.336 16.896 27.136 26.112 35.84l45.568 46.08 45.056-45.056C382.976 312.32 409.6 247.808 409.6 204.8H0V102.4h256V0h102.4v102.4h256v102.4H512c0 70.144-37.888 161.28-87.04 210.944L378.88 460.8zM576 870.4 512 1024H409.6l256-614.4H768l256 614.4H921.6l-64-153.6H576zM618.496 768h196.608L716.8 532.48 618.496 768z"></path></svg><!--]--><span class="arrow"></span><ul class="nav-dropdown"><li class="dropdown-item"><a aria-label="English" class="vp-link nav-link active nav-link active" href="/blog/posts/pytorch/04_pytorch_practice_nn.html"><!---->English<!----></a></li><li class="dropdown-item"><a aria-label="简体中文" class="vp-link nav-link nav-link" href="/blog/zh/posts/pytorch/04_pytorch_practice_nn.html"><!---->简体中文<!----></a></li></ul></button></div></div><div class="nav-item vp-repo"><a class="vp-repo-link" href="https://github.com/liz-starfield" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><div class="nav-item hide-in-mobile"><button type="button" id="appearance-switch"><svg xmlns="http://www.w3.org/2000/svg" class="icon auto-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="auto icon" style="display:block;"><path d="M512 992C246.92 992 32 777.08 32 512S246.92 32 512 32s480 214.92 480 480-214.92 480-480 480zm0-840c-198.78 0-360 161.22-360 360 0 198.84 161.22 360 360 360s360-161.16 360-360c0-198.78-161.22-360-360-360zm0 660V212c165.72 0 300 134.34 300 300 0 165.72-134.28 300-300 300z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon dark-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="dark icon" style="display:none;"><path d="M524.8 938.667h-4.267a439.893 439.893 0 0 1-313.173-134.4 446.293 446.293 0 0 1-11.093-597.334A432.213 432.213 0 0 1 366.933 90.027a42.667 42.667 0 0 1 45.227 9.386 42.667 42.667 0 0 1 10.24 42.667 358.4 358.4 0 0 0 82.773 375.893 361.387 361.387 0 0 0 376.747 82.774 42.667 42.667 0 0 1 54.187 55.04 433.493 433.493 0 0 1-99.84 154.88 438.613 438.613 0 0 1-311.467 128z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon light-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="light icon" style="display:none;"><path d="M952 552h-80a40 40 0 0 1 0-80h80a40 40 0 0 1 0 80zM801.88 280.08a41 41 0 0 1-57.96-57.96l57.96-58a41.04 41.04 0 0 1 58 58l-58 57.96zM512 752a240 240 0 1 1 0-480 240 240 0 0 1 0 480zm0-560a40 40 0 0 1-40-40V72a40 40 0 0 1 80 0v80a40 40 0 0 1-40 40zm-289.88 88.08-58-57.96a41.04 41.04 0 0 1 58-58l57.96 58a41 41 0 0 1-57.96 57.96zM192 512a40 40 0 0 1-40 40H72a40 40 0 0 1 0-80h80a40 40 0 0 1 40 40zm30.12 231.92a41 41 0 0 1 57.96 57.96l-57.96 58a41.04 41.04 0 0 1-58-58l58-57.96zM512 832a40 40 0 0 1 40 40v80a40 40 0 0 1-80 0v-80a40 40 0 0 1 40-40zm289.88-88.08 58 57.96a41.04 41.04 0 0 1-58 58l-57.96-58a41 41 0 0 1 57.96-57.96z"></path></svg></button></div><!----><!--]--><!--[--><!----><!--]--><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar"><!--[--><!----><!--]--><ul class="vp-sidebar-links"><li><!--[--><a aria-label="Home" class="vp-link nav-link vp-sidebar-link vp-sidebar-page nav-link vp-sidebar-link vp-sidebar-page" href="/blog/"><span class="font-icon icon fa-fw fa-sm fas fa-home" style=""></span>Home<!----></a><ul class="vp-sidebar-sub-headers"></ul><!--]--></li><li><!--[--><a aria-label="About Me" class="vp-link nav-link vp-sidebar-link vp-sidebar-page nav-link vp-sidebar-link vp-sidebar-page" href="/blog/intro.html"><span class="font-icon icon fa-fw fa-sm fas fa-user" style=""></span>About Me<!----></a><ul class="vp-sidebar-sub-headers"></ul><!--]--></li><li><section class="vp-sidebar-group"><p class="vp-sidebar-heading active"><span class="font-icon icon fa-fw fa-sm fas fa-book" style=""></span><span class="vp-sidebar-title">Blog</span><!----></p><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><button class="vp-sidebar-heading clickable" type="button"><!----><span class="vp-sidebar-title">L L M</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-heading clickable" type="button"><!----><span class="vp-sidebar-title">Python</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-heading clickable active" type="button"><!----><span class="vp-sidebar-title">Pytorch</span><span class="vp-arrow down"></span></button><ul class="vp-sidebar-links"><li><!--[--><a aria-label="Artificial Intelligence Concept Interpretation" class="vp-link nav-link vp-sidebar-link vp-sidebar-page nav-link vp-sidebar-link vp-sidebar-page" href="/blog/posts/pytorch/01_ai_concept.html"><span class="font-icon icon fa-fw fa-sm fas fa-lightbulb" style=""></span>Artificial Intelligence Concept Interpretation<!----></a><ul class="vp-sidebar-sub-headers"></ul><!--]--></li><li><!--[--><a aria-label="Neural Network Training Key Points Interpretation" class="vp-link nav-link vp-sidebar-link vp-sidebar-page nav-link vp-sidebar-link vp-sidebar-page" href="/blog/posts/pytorch/02_neural_net_train.html"><span class="font-icon icon fa-fw fa-sm fas fa-lightbulb" style=""></span>Neural Network Training Key Points Interpretation<!----></a><ul class="vp-sidebar-sub-headers"></ul><!--]--></li><li><!--[--><a aria-label="Tensor Operations" class="vp-link nav-link vp-sidebar-link vp-sidebar-page nav-link vp-sidebar-link vp-sidebar-page" href="/blog/posts/pytorch/03_pytorch_operation.html"><span class="font-icon icon fa-fw fa-sm fas fa-lightbulb" style=""></span>Tensor Operations<!----></a><ul class="vp-sidebar-sub-headers"></ul><!--]--></li><li><!--[--><a aria-label="Deep Learning Practice with PyTorch" class="vp-link nav-link active vp-sidebar-link vp-sidebar-page active nav-link active vp-sidebar-link vp-sidebar-page active" href="/blog/posts/pytorch/04_pytorch_practice_nn.html"><span class="font-icon icon fa-fw fa-sm fas fa-lightbulb" style=""></span>Deep Learning Practice with PyTorch<!----></a><ul class="vp-sidebar-sub-headers"><li class="vp-sidebar-sub-header"><a aria-label="0. PyTorch&#39;s APIs" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/blog/posts/pytorch/04_pytorch_practice_nn.html#_0-pytorch-s-apis"><!---->0. PyTorch&#39;s APIs<!----></a><ul class="vp-sidebar-sub-headers"></ul></li><li class="vp-sidebar-sub-header"><a aria-label="1. Data Loading and Preprocessing" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/blog/posts/pytorch/04_pytorch_practice_nn.html#_1-data-loading-and-preprocessing"><!---->1. Data Loading and Preprocessing<!----></a><ul class="vp-sidebar-sub-headers"><li class="vp-sidebar-sub-header"><a aria-label="1.1. DataLoarder" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/blog/posts/pytorch/04_pytorch_practice_nn.html#_1-1-dataloarder"><!---->1.1. DataLoarder<!----></a><ul class="vp-sidebar-sub-headers"></ul></li><li class="vp-sidebar-sub-header"><a aria-label="1.2. 自定义数据集" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/blog/posts/pytorch/04_pytorch_practice_nn.html#_1-2-自定义数据集"><!---->1.2. 自定义数据集<!----></a><ul class="vp-sidebar-sub-headers"></ul></li><li class="vp-sidebar-sub-header"><a aria-label="1.3. 使用pandas预处理原始数据" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/blog/posts/pytorch/04_pytorch_practice_nn.html#_1-3-使用pandas预处理原始数据"><!---->1.3. 使用pandas预处理原始数据<!----></a><ul class="vp-sidebar-sub-headers"></ul></li></ul></li><li class="vp-sidebar-sub-header"><a aria-label="2. Defining Network Models" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/blog/posts/pytorch/04_pytorch_practice_nn.html#_2-defining-network-models"><!---->2. Defining Network Models<!----></a><ul class="vp-sidebar-sub-headers"></ul></li><li class="vp-sidebar-sub-header"><a aria-label="3. Defining Loss Function and Optimizer" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/blog/posts/pytorch/04_pytorch_practice_nn.html#_3-defining-loss-function-and-optimizer"><!---->3. Defining Loss Function and Optimizer<!----></a><ul class="vp-sidebar-sub-headers"></ul></li><li class="vp-sidebar-sub-header"><a aria-label="4. Training the Network" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/blog/posts/pytorch/04_pytorch_practice_nn.html#_4-training-the-network"><!---->4. Training the Network<!----></a><ul class="vp-sidebar-sub-headers"></ul></li><li class="vp-sidebar-sub-header"><a aria-label="5. Testing the Network" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/blog/posts/pytorch/04_pytorch_practice_nn.html#_5-testing-the-network"><!---->5. Testing the Network<!----></a><ul class="vp-sidebar-sub-headers"></ul></li><li class="vp-sidebar-sub-header"><a aria-label="6. Saving and Loading Models" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/blog/posts/pytorch/04_pytorch_practice_nn.html#_6-saving-and-loading-models"><!---->6. Saving and Loading Models<!----></a><ul class="vp-sidebar-sub-headers"><li class="vp-sidebar-sub-header"><a aria-label="6.1. 保存和加载模型参数" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/blog/posts/pytorch/04_pytorch_practice_nn.html#_6-1-保存和加载模型参数"><!---->6.1. 保存和加载模型参数<!----></a><ul class="vp-sidebar-sub-headers"></ul></li><li class="vp-sidebar-sub-header"><a aria-label="6.2. 保存和加载整个模型" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/blog/posts/pytorch/04_pytorch_practice_nn.html#_6-2-保存和加载整个模型"><!---->6.2. 保存和加载整个模型<!----></a><ul class="vp-sidebar-sub-headers"></ul></li></ul></li><li class="vp-sidebar-sub-header"><a aria-label="7. GPU Acceleration" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/blog/posts/pytorch/04_pytorch_practice_nn.html#_7-gpu-acceleration"><!---->7. GPU Acceleration<!----></a><ul class="vp-sidebar-sub-headers"></ul></li><li class="vp-sidebar-sub-header"><a aria-label="8. Visualization with TensorBoard" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/blog/posts/pytorch/04_pytorch_practice_nn.html#_8-visualization-with-tensorboard"><!---->8. Visualization with TensorBoard<!----></a><ul class="vp-sidebar-sub-headers"><li class="vp-sidebar-sub-header"><a aria-label="8.1. 启动TensorBoard" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/blog/posts/pytorch/04_pytorch_practice_nn.html#_8-1-启动tensorboard"><!---->8.1. 启动TensorBoard<!----></a><ul class="vp-sidebar-sub-headers"></ul></li><li class="vp-sidebar-sub-header"><a aria-label="8.2. 记录数据" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/blog/posts/pytorch/04_pytorch_practice_nn.html#_8-2-记录数据"><!---->8.2. 记录数据<!----></a><ul class="vp-sidebar-sub-headers"></ul></li><li class="vp-sidebar-sub-header"><a aria-label="8.3. 可视化模型结构" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/blog/posts/pytorch/04_pytorch_practice_nn.html#_8-3-可视化模型结构"><!---->8.3. 可视化模型结构<!----></a><ul class="vp-sidebar-sub-headers"></ul></li><li class="vp-sidebar-sub-header"><a aria-label="8.4. 可视化高维数据" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/blog/posts/pytorch/04_pytorch_practice_nn.html#_8-4-可视化高维数据"><!---->8.4. 可视化高维数据<!----></a><ul class="vp-sidebar-sub-headers"></ul></li></ul></li></ul><!--]--></li><li><!--[--><a aria-label="PyTorch Practical for Linear Neural Network" class="vp-link nav-link vp-sidebar-link vp-sidebar-page nav-link vp-sidebar-link vp-sidebar-page" href="/blog/posts/pytorch/05_linear_nn.html"><span class="font-icon icon fa-fw fa-sm fas fa-lightbulb" style=""></span>PyTorch Practical for Linear Neural Network<!----></a><ul class="vp-sidebar-sub-headers"></ul><!--]--></li></ul></section></li></ul></section></li></ul><!--[--><!----><!--]--></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!--[--><!----><!--]--><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><span class="font-icon icon fa-fw fa-sm fas fa-lightbulb" style=""></span>Deep Learning Practice with PyTorch</h1><div class="page-info"><span class="page-author-info" aria-label="Author🖊" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><a class="page-author-item" href="https://github.com/liz-starfield" target="_blank" rel="noopener noreferrer">Liz</a></span><span property="author" content="Liz"></span></span><!----><span class="page-date-info" aria-label="Writing Date📅" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span><!----></span><meta property="datePublished" content="2022-07-23T00:00:00.000Z"></span><!----><span class="page-reading-time-info" aria-label="Reading Time⌛" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>About 9 min</span><meta property="timeRequired" content="PT9M"></span><span class="page-category-info" aria-label="Category🌈" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon category-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="category icon"><path d="M148.41 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H148.41c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.311-40.31zM147.556 553.478H429.73c22.263 0 40.311 18.048 40.311 40.31v282.176c0 22.263-18.048 40.312-40.31 40.312H147.555c-22.263 0-40.311-18.049-40.311-40.312V593.79c0-22.263 18.048-40.311 40.31-40.311zM593.927 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H593.927c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.31-40.31zM730.22 920.502H623.926c-40.925 0-74.22-33.388-74.22-74.425V623.992c0-41.038 33.387-74.424 74.425-74.424h222.085c41.038 0 74.424 33.226 74.424 74.067v114.233c0 10.244-8.304 18.548-18.547 18.548s-18.548-8.304-18.548-18.548V623.635c0-20.388-16.746-36.974-37.33-36.974H624.13c-20.585 0-37.331 16.747-37.331 37.33v222.086c0 20.585 16.654 37.331 37.126 37.331H730.22c10.243 0 18.547 8.304 18.547 18.547 0 10.244-8.304 18.547-18.547 18.547z"></path></svg><!--[--><span class="page-category-item category8 clickable" role="navigation">Pytorch</span><!--]--><meta property="articleSection" content="Pytorch"></span><span class="page-tag-info" aria-label="Tag🏷" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon tag-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="tag icon"><path d="M939.902 458.563L910.17 144.567c-1.507-16.272-14.465-29.13-30.737-30.737L565.438 84.098h-.402c-3.215 0-5.726 1.005-7.634 2.913l-470.39 470.39a10.004 10.004 0 000 14.164l365.423 365.424c1.909 1.908 4.42 2.913 7.132 2.913s5.223-1.005 7.132-2.913l470.39-470.39c2.01-2.11 3.014-5.023 2.813-8.036zm-240.067-72.121c-35.458 0-64.286-28.828-64.286-64.286s28.828-64.285 64.286-64.285 64.286 28.828 64.286 64.285-28.829 64.286-64.286 64.286z"></path></svg><!--[--><span class="page-tag-item tag8 clickable" role="navigation">Pytorch</span><!--]--><meta property="keywords" content="Pytorch"></span></div><hr></div><div class="toc-place-holder"><aside id="toc"><!--[--><!----><!--]--><div class="toc-header">On This Page<button type="button" class="print-button" title="Print"><svg xmlns="http://www.w3.org/2000/svg" class="icon print-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="print icon"><path d="M819.2 364.8h-44.8V128c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v236.8h-44.8C145.067 364.8 96 413.867 96 473.6v192c0 59.733 49.067 108.8 108.8 108.8h44.8V896c0 17.067 14.933 32 32 32h460.8c17.067 0 32-14.933 32-32V774.4h44.8c59.733 0 108.8-49.067 108.8-108.8v-192c0-59.733-49.067-108.8-108.8-108.8zM313.6 160h396.8v204.8H313.6V160zm396.8 704H313.6V620.8h396.8V864zM864 665.6c0 25.6-19.2 44.8-44.8 44.8h-44.8V588.8c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v121.6h-44.8c-25.6 0-44.8-19.2-44.8-44.8v-192c0-25.6 19.2-44.8 44.8-44.8h614.4c25.6 0 44.8 19.2 44.8 44.8v192z"></path></svg></button></div><div class="toc-wrapper"><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_0-pytorch-s-apis">0. PyTorch&#39;s APIs</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_1-data-loading-and-preprocessing">1. Data Loading and Preprocessing</a></li><li><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_1-1-dataloarder">1.1. DataLoarder</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_1-2-自定义数据集">1.2. 自定义数据集</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_1-3-使用pandas预处理原始数据">1.3. 使用pandas预处理原始数据</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_2-defining-network-models">2. Defining Network Models</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_3-defining-loss-function-and-optimizer">3. Defining Loss Function and Optimizer</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_4-training-the-network">4. Training the Network</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_5-testing-the-network">5. Testing the Network</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_6-saving-and-loading-models">6. Saving and Loading Models</a></li><li><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_6-1-保存和加载模型参数">6.1. 保存和加载模型参数</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_6-2-保存和加载整个模型">6.2. 保存和加载整个模型</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_7-gpu-acceleration">7. GPU Acceleration</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_8-visualization-with-tensorboard">8. Visualization with TensorBoard</a></li><li><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_8-1-启动tensorboard">8.1. 启动TensorBoard</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_8-2-记录数据">8.2. 记录数据</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_8-3-可视化模型结构">8.3. 可视化模型结构</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_8-4-可视化高维数据">8.4. 可视化高维数据</a></li><!----><!--]--></ul></li><!--]--></ul><div class="toc-marker" style="top:-1.7rem;"></div></div><!--[--><!----><!--]--></aside></div><!--[--><!----><!--]--><div class="theme-hope-content"><h1 id="deep-learning-practice-with-pytorch" tabindex="-1"><a class="header-anchor" href="#deep-learning-practice-with-pytorch" aria-hidden="true">#</a> Deep Learning Practice with PyTorch</h1><ul><li><ol start="0"><li>PyTorch&#39;s APIs</li></ol></li><li><ol><li>Data Loading and Preprocessing</li></ol></li><li><ol start="2"><li>Defining Network Models</li></ol></li><li><ol start="3"><li>Defining Loss Function and Optimizer</li></ol></li><li><ol start="4"><li>Training the Network</li></ol></li><li><ol start="5"><li>Testing the Network</li></ol></li><li><ol start="6"><li>Saving and Loading Models</li></ol></li><li><ol start="7"><li>GPU Acceleration</li></ol></li><li><ol start="8"><li>Visualization with TensorBoard</li></ol></li></ul><!-- more --><h2 id="_0-pytorch-s-apis" tabindex="-1"><a class="header-anchor" href="#_0-pytorch-s-apis" aria-hidden="true">#</a> 0. PyTorch&#39;s APIs</h2><ul><li>data模块：提供了数据处理工具</li><li>nn模型：定义了大量的神经网络层和常见损失函数</li></ul><h2 id="_1-data-loading-and-preprocessing" tabindex="-1"><a class="header-anchor" href="#_1-data-loading-and-preprocessing" aria-hidden="true">#</a> 1. Data Loading and Preprocessing</h2><p>PyTorch提供了torch.utils.data.DataLoader类，可以帮助我们方便地进行数据的加载和处理。</p><h3 id="_1-1-dataloarder" tabindex="-1"><a class="header-anchor" href="#_1-1-dataloarder" aria-hidden="true">#</a> 1.1. DataLoarder</h3><p>DataLoader类提供了对数据集的并行加载，可以有效地加载大量数据，并提供了多种数据采样方式。</p><p>常用的参数有：</p><ul><li>dataset：加载的数据集（Dataset对象）</li><li>batch_size：batch大小</li><li>shuffle：是否每个epoch时都打乱数据</li><li>num_workers：使用多进程加载的进程数，0表示不使用多进程</li></ul><h3 id="_1-2-自定义数据集" tabindex="-1"><a class="header-anchor" href="#_1-2-自定义数据集" aria-hidden="true">#</a> 1.2. 自定义数据集</h3><p>自定义数据集需要继承Dataset类，并实现__len__和__getitem__两个方法。</p><p>以下是一个自定义数据集的简单示例：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> Dataset<span class="token punctuation">,</span> DataLoader

<span class="token comment"># 定义MyDataset类，继承父类Dataset</span>
<span class="token keyword">class</span> <span class="token class-name">MyDataset</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x_tensor<span class="token punctuation">,</span> y_tensor<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>x <span class="token operator">=</span> x_tensor
        self<span class="token punctuation">.</span>y <span class="token operator">=</span> y_tensor

    <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> index<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>x<span class="token punctuation">[</span>index<span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>y<span class="token punctuation">[</span>index<span class="token punctuation">]</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>x<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>我们创建了一个简单的数据集，包含10个数据。然后我们使用DataLoader加载数据，并设置了batch大小和shuffle参数。</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>x <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span>
y <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span>

my_dataset <span class="token operator">=</span> MyDataset<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span>

loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>my_dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> num_workers<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> x<span class="token punctuation">,</span> y <span class="token keyword">in</span> loader<span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;x:&quot;</span><span class="token punctuation">,</span> x<span class="token punctuation">,</span> <span class="token string">&quot;y:&quot;</span><span class="token punctuation">,</span> y<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><figure><img src="/blog/assets/data_loader-Y0qQv4_6.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h3 id="_1-3-使用pandas预处理原始数据" tabindex="-1"><a class="header-anchor" href="#_1-3-使用pandas预处理原始数据" aria-hidden="true">#</a> 1.3. 使用pandas预处理原始数据</h3><p><strong>目标：使用pandas预处理原始数据，并将原始数据转换为张量格式</strong></p><ul><li>pandas软件包是Python中常用的数据分析工具，pandas可以与张量兼容。</li><li>用pandas处理缺失的数据时，我们可根据情况选择用插值法和删除法。</li></ul><h4 id="_1-3-1-读取数据集" tabindex="-1"><a class="header-anchor" href="#_1-3-1-读取数据集" aria-hidden="true">#</a> 1.3.1. 读取数据集</h4><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> os

os<span class="token punctuation">.</span>makedirs<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token string">&#39;..&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;data&#39;</span><span class="token punctuation">)</span><span class="token punctuation">,</span> exist_ok<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span> <span class="token comment"># os.path.join会用对应操作系统的分隔符如/去拼接路径</span>
data_file <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token string">&#39;..&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;data&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;house_tiny.csv&#39;</span><span class="token punctuation">)</span>
<span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>data_file<span class="token punctuation">,</span> <span class="token string">&#39;w&#39;</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
    f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">&#39;NumRooms,Alley,Price\n&#39;</span><span class="token punctuation">)</span>  <span class="token comment"># 列名</span>
    f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">&#39;NA,Pave,127500\n&#39;</span><span class="token punctuation">)</span>  <span class="token comment"># 每行表示一个数据样本</span>
    f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">&#39;2,NA,106000\n&#39;</span><span class="token punctuation">)</span>
    f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">&#39;4,NA,178100\n&#39;</span><span class="token punctuation">)</span>
    f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">&#39;NA,NA,140000\n&#39;</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># 如果没有安装pandas，只需取消对以下行的注释来安装pandas</span>
<span class="token comment"># !pip install pandas</span>
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd

data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span>data_file<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>输出如下：</p><figure><img src="/blog/assets/output_1-X7VIO0As.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h4 id="_1-3-2-处理缺失值-连续值和离散值" tabindex="-1"><a class="header-anchor" href="#_1-3-2-处理缺失值-连续值和离散值" aria-hidden="true">#</a> 1.3.2. 处理缺失值(连续值和离散值)</h4><p>注意，“NaN”项代表缺失值。</p><p>为了处理缺失的数据，典型的方法包括<em>插值法</em>和<em>删除法</em>， 其中插值法用一个替代值弥补缺失值，而删除法则直接忽略缺失值。</p><p>在这里，我们将考虑插值法。</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># iloc, 全称为index location，即对数据进行位置索引，从而在数据表中提取出相应的数据。</span>
<span class="token comment"># 将data分成inputs和outputs</span>
inputs<span class="token punctuation">,</span> outputs <span class="token operator">=</span> data<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> data<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span>
<span class="token comment"># 对于inputs中缺少的数值，我们用同一列的均值替换“NaN”项。</span>
inputs <span class="token operator">=</span> inputs<span class="token punctuation">.</span>fillna<span class="token punctuation">(</span>inputs<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>输出如下：</p><figure><img src="/blog/assets/nan_process_1-MiNS-RBA.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># inputs中的类别值或离散值的缺失值处理</span>
inputs <span class="token operator">=</span> pd<span class="token punctuation">.</span>get_dummies<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> dummy_na<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><figure><img src="/blog/assets/nan_process_2-2Bj3yJ1w.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h4 id="_1-3-3-转换为张量格式" tabindex="-1"><a class="header-anchor" href="#_1-3-3-转换为张量格式" aria-hidden="true">#</a> 1.3.3. 转换为张量格式</h4><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> torch

x<span class="token punctuation">,</span> y <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>inputs<span class="token punctuation">.</span>values<span class="token punctuation">)</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>outputs<span class="token punctuation">.</span>values<span class="token punctuation">)</span>
x<span class="token punctuation">,</span> y
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>输出如下：</p><figure><img src="/blog/assets/process_to_tensor-ppYV54dt.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h2 id="_2-defining-network-models" tabindex="-1"><a class="header-anchor" href="#_2-defining-network-models" aria-hidden="true">#</a> 2. Defining Network Models</h2><p>PyTorch提供了<code>torch.nn</code>库，它是用于构建神经网络的工具库。 <code>nn.Module</code>包含了神经网络的层以及返回输出的<code>forward(input)</code>方法。</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F

<span class="token comment"># 定义一个Net类，继承父类nn.Module</span>
<span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    
    <span class="token comment"># 在`__init__`方法中定义网络的结构(网络的层)</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token comment"># 输入图像channel：1，输出channel：6，5x5卷积核</span>
        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>

        <span class="token comment"># 全连接层</span>
        self<span class="token punctuation">.</span>fc1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">16</span> <span class="token operator">*</span> <span class="token number">5</span> <span class="token operator">*</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">120</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fc2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">120</span><span class="token punctuation">,</span> <span class="token number">84</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fc3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">84</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>

    <span class="token comment"># 在`forward`方法中定义数据的流向(网络的前向传播过程)</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 使用2x2窗口进行最大池化</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>max_pool2d<span class="token punctuation">(</span>F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token comment"># 如果窗口是方的，只需要指定一个维度</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>max_pool2d<span class="token punctuation">(</span>F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>

        x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_flat_features<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>

        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc3<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

        <span class="token keyword">return</span> x

    <span class="token keyword">def</span> <span class="token function">num_flat_features</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        size <span class="token operator">=</span> x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span>  <span class="token comment"># 获取除了batch维度之外的其他维度</span>
        num_features <span class="token operator">=</span> <span class="token number">1</span>
        <span class="token keyword">for</span> s <span class="token keyword">in</span> size<span class="token punctuation">:</span>
            num_features <span class="token operator">*=</span> s
        <span class="token keyword">return</span> num_features

net <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span>

输出结果为：
Net<span class="token punctuation">(</span>
  <span class="token punctuation">(</span>conv1<span class="token punctuation">)</span><span class="token punctuation">:</span> Conv2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
  <span class="token punctuation">(</span>conv2<span class="token punctuation">)</span><span class="token punctuation">:</span> Conv2d<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
  <span class="token punctuation">(</span>fc1<span class="token punctuation">)</span><span class="token punctuation">:</span> Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">400</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">120</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
  <span class="token punctuation">(</span>fc2<span class="token punctuation">)</span><span class="token punctuation">:</span> Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">120</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">84</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
  <span class="token punctuation">(</span>fc3<span class="token punctuation">)</span><span class="token punctuation">:</span> Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">84</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>这里需要注意：</p><ul><li>backward函数（用于计算梯度）会被autograd自动创建和实现。你只需要在nn.Module的子类中定义forward函数。</li><li>在创建好神经网络后，我们可以使用net.parameters()方法来返回网络的可学习参数。</li></ul><h2 id="_3-defining-loss-function-and-optimizer" tabindex="-1"><a class="header-anchor" href="#_3-defining-loss-function-and-optimizer" aria-hidden="true">#</a> 3. Defining Loss Function and Optimizer</h2><p>损失函数用于衡量模型的预测与真实标签的差距。我们一般使用交叉熵损失函数（Cross Entropy Loss）</p><p>优化器用于优化模型的参数以减少损失，我们一般使用随机梯度下降优化器（Stochastic Gradient Descent，SGD）</p><p>更新网络的梯度，一个简单的更新规则是 weight = weight - learning_rate * gradient</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optim

<span class="token comment"># 定义损失函数</span>
criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># 定义优化器</span>
<span class="token comment"># 我们需要将网络的参数传递给优化器，然后设置学习率和动量</span>
optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="_4-training-the-network" tabindex="-1"><a class="header-anchor" href="#_4-training-the-network" aria-hidden="true">#</a> 4. Training the Network</h2><p>在训练过程中，我们首先通过网络进行前向传播得到输出，然后计算输出与真实标签的损失，接着通过后向传播计算梯度，最后使用优化器更新模型参数</p><p>在训练集上训练epochs轮次</p><p>每一轮，对于一batchs批次</p><ul><li>获取输入数据：inputs, labels = data</li><li>梯度清零：optimizer.zero_grad()</li><li>前向传播：outputs = net(inputs)</li><li>计算损失：loss = criterion(outputs, labels)</li><li>反向传播：loss.backward()</li><li>更新参数：optimizer.step()</li></ul><h2 id="_5-testing-the-network" tabindex="-1"><a class="header-anchor" href="#_5-testing-the-network" aria-hidden="true">#</a> 5. Testing the Network</h2><p>训练完成后，在测试集上测试网络的性能，评估其泛化能力</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment"># 是指无需计算梯度，减少内存消耗</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><h2 id="_6-saving-and-loading-models" tabindex="-1"><a class="header-anchor" href="#_6-saving-and-loading-models" aria-hidden="true">#</a> 6. Saving and Loading Models</h2><p>在深度学习模型的训练过程中，我们经常需要保存模型的参数以便于将来重新加载。这对于中断的训练过程的恢复，或者用于模型的分享和部署都是非常有用的。</p><p>PyTorch提供了简单的API来保存和加载模型。最常见的方法是使用torch.save来保存模型的参数，然后通过torch.load来加载模型的参数。</p><h3 id="_6-1-保存和加载模型参数" tabindex="-1"><a class="header-anchor" href="#_6-1-保存和加载模型参数" aria-hidden="true">#</a> 6.1. 保存和加载模型参数</h3><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># 保存</span>
torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> PATH<span class="token punctuation">)</span>

<span class="token comment"># 加载</span>
model <span class="token operator">=</span> TheModelClass<span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span> <span class="token comment"># 创建新的模型实例</span>
model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>PATH<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># 加载模型参数</span>
model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>在保存模型参数时，我们通常使用.state_dict()方法来获取模型的参数。.state_dict()是一个从参数名字映射到参数值的字典对象。</p><p>在加载模型参数时，我们首先需要实例化一个和原模型结构相同的模型，然后使用.load_state_dict()方法加载参数。</p><p>请注意，load_state_dict()函数接受一个字典对象，而不是保存对象的路径。这意味着在你传入load_state_dict()函数之前，你必须反序列化你的保存的state_dict。</p><p>在加载模型后，我们通常调用.eval()方法将dropout和batch normalization层设置为评估模式。否则，它们会在评估模式下保持训练模式。</p><h3 id="_6-2-保存和加载整个模型" tabindex="-1"><a class="header-anchor" href="#_6-2-保存和加载整个模型" aria-hidden="true">#</a> 6.2. 保存和加载整个模型</h3><p>除了保存模型的参数，我们也可以保存整个模型。</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># 保存</span>
torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">,</span> PATH<span class="token punctuation">)</span>

<span class="token comment"># 加载</span>
model <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>PATH<span class="token punctuation">)</span>
model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>保存整个模型会将模型的结构和参数一起保存。这意味着在加载模型时，我们不再需要手动创建模型实例。但是，这种方式需要更多的磁盘空间，并且可能在某些情况下导致代码的混乱，所以并不总是推荐的。</p><h2 id="_7-gpu-acceleration" tabindex="-1"><a class="header-anchor" href="#_7-gpu-acceleration" aria-hidden="true">#</a> 7. GPU Acceleration</h2><p>在深度学习训练中，GPU加速是非常重要的一部分。GPU的并行计算能力使得其比CPU在大规模矩阵运算上更具优势。PyTorch提供了简单易用的API，让我们可以很容易地在CPU和GPU之间切换计算。但需要注意的是，数据在CPU和GPU之间的传输会消耗一定的时间，因此我们应该尽量减少数据的传输次数。</p><p>PyTorch支持使用GPU进行计算，这可以大大提高训练和推理的速度。使用GPU进行计算的核心就是将Tensor和模型转移到GPU上。</p><p>检查系统中是否存在可用的GPU:</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> torch

<span class="token comment"># 检查是否有可用的GPU</span>
<span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;There is a GPU available.&quot;</span><span class="token punctuation">)</span>
<span class="token keyword">else</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;There is no GPU available.&quot;</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>使用<code>.to(device)</code>方法将tensor移动到GPU上：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># 判断是否支持CUDA</span>
device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">&quot;cuda&quot;</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">&quot;cpu&quot;</span><span class="token punctuation">)</span>

<span class="token comment"># 创建一个tensor</span>
x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">,</span> <span class="token number">2.0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># 移动tensor到GPU上</span>
<span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    x <span class="token operator">=</span> x<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>创建tensor时指定设备：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># 直接在GPU上创建tensor</span>
<span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">,</span> <span class="token number">2.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> device<span class="token operator">=</span><span class="token string">&#39;cuda&#39;</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>模型训练时，将模型和数据移动到GPU上:</p><p>当模型在GPU上时，我们需要确保输入的Tensor也在GPU上，否则会报错。</p><p>注意，将模型转移到GPU上后，模型的所有参数和缓冲区都会转移到GPU上。</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># 判断是否支持CUDA</span>
device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">&quot;cuda&quot;</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">&quot;cpu&quot;</span><span class="token punctuation">)</span>

<span class="token comment"># 创建一个简单的模型</span>
model <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>

<span class="token comment"># 创建一些数据</span>
data <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>

<span class="token comment"># 移动模型和数据到GPU</span>
<span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    model <span class="token operator">=</span> model<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
    data <span class="token operator">=</span> data<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="_8-visualization-with-tensorboard" tabindex="-1"><a class="header-anchor" href="#_8-visualization-with-tensorboard" aria-hidden="true">#</a> 8. Visualization with TensorBoard</h2><p>TensorBoard 是一个可视化工具，它可以帮助我们更好地理解，优化，和调试深度学习模型。PyTorch 提供了对 TensorBoard 的支持，我们可以非常方便地使用 TensorBoard 来监控模型的训练过程，比较不同模型的性能，可视化模型结构，等等。</p><p>通过使用 TensorBoard，我们可以更好地理解和优化我们的模型。</p><h3 id="_8-1-启动tensorboard" tabindex="-1"><a class="header-anchor" href="#_8-1-启动tensorboard" aria-hidden="true">#</a> 8.1. 启动TensorBoard</h3><p>要启动 TensorBoard，我们需要在命令行中运行 tensorboard --logdir=runs 命令，其中 runs 是保存 TensorBoard 数据的目录。</p><h3 id="_8-2-记录数据" tabindex="-1"><a class="header-anchor" href="#_8-2-记录数据" aria-hidden="true">#</a> 8.2. 记录数据</h3><p>我们可以使用 torch.utils.tensorboard 模块来记录数据。首先，我们需要创建一个 SummaryWriter 对象，然后通过这个对象的方法来记录数据。</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>tensorboard <span class="token keyword">import</span> SummaryWriter

<span class="token comment"># 创建一个 SummaryWriter 对象</span>
writer <span class="token operator">=</span> SummaryWriter<span class="token punctuation">(</span><span class="token string">&#39;runs/experiment1&#39;</span><span class="token punctuation">)</span>

<span class="token comment"># 使用 writer 来记录数据</span>
<span class="token keyword">for</span> n_iter <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    writer<span class="token punctuation">.</span>add_scalar<span class="token punctuation">(</span><span class="token string">&#39;Loss/train&#39;</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>random<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> n_iter<span class="token punctuation">)</span>
    writer<span class="token punctuation">.</span>add_scalar<span class="token punctuation">(</span><span class="token string">&#39;Loss/test&#39;</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>random<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> n_iter<span class="token punctuation">)</span>
    writer<span class="token punctuation">.</span>add_scalar<span class="token punctuation">(</span><span class="token string">&#39;Accuracy/train&#39;</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>random<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> n_iter<span class="token punctuation">)</span>
    writer<span class="token punctuation">.</span>add_scalar<span class="token punctuation">(</span><span class="token string">&#39;Accuracy/test&#39;</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>random<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> n_iter<span class="token punctuation">)</span>

<span class="token comment"># 关闭 writer</span>
writer<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_8-3-可视化模型结构" tabindex="-1"><a class="header-anchor" href="#_8-3-可视化模型结构" aria-hidden="true">#</a> 8.3. 可视化模型结构</h3><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># 添加模型</span>
writer<span class="token punctuation">.</span>add_graph<span class="token punctuation">(</span>model<span class="token punctuation">,</span> images<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_8-4-可视化高维数据" tabindex="-1"><a class="header-anchor" href="#_8-4-可视化高维数据" aria-hidden="true">#</a> 8.4. 可视化高维数据</h3><p>我们还可以使用 TensorBoard 的嵌入功能来可视化高维数据，如图像特征、词嵌入等。</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># 添加嵌入</span>
writer<span class="token punctuation">.</span>add_embedding<span class="token punctuation">(</span>features<span class="token punctuation">,</span> metadata<span class="token operator">=</span>class_labels<span class="token punctuation">,</span> label_img<span class="token operator">=</span>images<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div></div><!--[--><!----><!--]--><footer class="page-meta"><!----><div class="meta-item git-info"><!----><!----></div></footer><nav class="vp-page-nav"><a aria-label="Tensor Operations" class="vp-link nav-link prev nav-link prev" href="/blog/posts/pytorch/03_pytorch_operation.html"><div class="hint"><span class="arrow start"></span>Prev</div><div class="link"><span class="font-icon icon fa-fw fa-sm fas fa-lightbulb" style=""></span>Tensor Operations</div></a><a aria-label="PyTorch Practical for Linear Neural Network" class="vp-link nav-link next nav-link next" href="/blog/posts/pytorch/05_linear_nn.html"><div class="hint">Next<span class="arrow end"></span></div><div class="link">PyTorch Practical for Linear Neural Network<span class="font-icon icon fa-fw fa-sm fas fa-lightbulb" style=""></span></div></a></nav><!----><!--[--><!----><!--]--><!--]--></main><!--]--><!----></div><!--]--><!--]--><!----><!--]--></div>
    <script type="module" src="/blog/assets/app-KJHtdF_7.js" defer></script>
  </body>
</html>
