<!doctype html>
<html lang="en-US" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.0" />
    <meta name="theme" content="VuePress Theme Hope 2.0.0-rc.13" />
    <style>
      html {
        background: var(--bg-color, #fff);
      }

      html[data-theme="dark"] {
        background: var(--bg-color, #1d1e1f);
      }

      body {
        background: var(--bg-color);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <link rel="alternate" hreflang="zh-cn" href="https://liz-in-tech.github.io/blog/zh/posts/llm/029_unsloth_grpo.html"><meta property="og:url" content="https://liz-in-tech.github.io/blog/posts/llm/029_unsloth_grpo.html"><meta property="og:site_name" content="Liz"><meta property="og:title" content="GRPO + Unsloth + vLLM"><meta property="og:description" content="GRPO + Unsloth + vLLM"><meta property="og:type" content="article"><meta property="og:locale" content="en-US"><meta property="og:locale:alternate" content="zh-CN"><meta property="og:updated_time" content="2025-03-10T14:44:44.000Z"><meta property="article:author" content="Liz"><meta property="article:tag" content="GRPO"><meta property="article:tag" content="RL"><meta property="article:tag" content="Unsloth"><meta property="article:tag" content="vLLM"><meta property="article:published_time" content="2025-03-08T00:00:00.000Z"><meta property="article:modified_time" content="2025-03-10T14:44:44.000Z"><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"GRPO + Unsloth + vLLM","image":[""],"datePublished":"2025-03-08T00:00:00.000Z","dateModified":"2025-03-10T14:44:44.000Z","author":[{"@type":"Person","name":"Liz","url":"https://github.com/liz-in-tech"}]}</script><link rel="icon" herf="/blogger.png"><link rel="icon" href="/blog/blogger.png"><title>GRPO + Unsloth + vLLM | Liz</title><meta name="description" content="GRPO + Unsloth + vLLM">
    <link rel="preload" href="/blog/assets/style-m_obra2h.css" as="style"><link rel="stylesheet" href="/blog/assets/style-m_obra2h.css">
    <link rel="modulepreload" href="/blog/assets/app-nSXwnGLr.js"><link rel="modulepreload" href="/blog/assets/029_unsloth_grpo.html-T25XLAW-.js"><link rel="modulepreload" href="/blog/assets/029_unsloth_grpo.html-EzVpjqeG.js"><link rel="modulepreload" href="/blog/assets/029_training-YPL3rOVm.js"><link rel="modulepreload" href="/blog/assets/plugin-vue_export-helper-x3n3nnut.js">
    <link rel="prefetch" href="/blog/assets/index.html-YbPtte5_.js" as="script"><link rel="prefetch" href="/blog/assets/intro.html-CGfhr1vY.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-FUMOuem4.js" as="script"><link rel="prefetch" href="/blog/assets/index.html--TTjrkIy.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-g4Nfr7z1.js" as="script"><link rel="prefetch" href="/blog/assets/intro.html-bitGHKd2.js" as="script"><link rel="prefetch" href="/blog/assets/001_langchain.html-nrisQopy.js" as="script"><link rel="prefetch" href="/blog/assets/002_langchain_sourcecode.html-9XtwFAwc.js" as="script"><link rel="prefetch" href="/blog/assets/003_streamlit.html-oji9upQP.js" as="script"><link rel="prefetch" href="/blog/assets/004_transformer.html-xrin91s2.js" as="script"><link rel="prefetch" href="/blog/assets/005_llama.html-zssRppb4.js" as="script"><link rel="prefetch" href="/blog/assets/006_llm_leaderboard.html-c628DmZb.js" as="script"><link rel="prefetch" href="/blog/assets/007_computer_use.html-4RcS3hxb.js" as="script"><link rel="prefetch" href="/blog/assets/008_rag_challenge.html-_8stdYVV.js" as="script"><link rel="prefetch" href="/blog/assets/009_llm_challenge.html-eluz3bTT.js" as="script"><link rel="prefetch" href="/blog/assets/010_rag_workflow.html-Ft0RQWf3.js" as="script"><link rel="prefetch" href="/blog/assets/011_vector_database.html-htZNHy9b.js" as="script"><link rel="prefetch" href="/blog/assets/012_prompt_engineering.html-Q27DlfZz.js" as="script"><link rel="prefetch" href="/blog/assets/013_optimizing_llm.html-6CxOIR84.js" as="script"><link rel="prefetch" href="/blog/assets/014_rag_evaluation.html-l_kCYUI1.js" as="script"><link rel="prefetch" href="/blog/assets/015_fine_tune.html-48naV3Ea.js" as="script"><link rel="prefetch" href="/blog/assets/016_multimodal.html-XtD4OMNh.js" as="script"><link rel="prefetch" href="/blog/assets/017_agent_and_multiagent.html-dm178NRn.js" as="script"><link rel="prefetch" href="/blog/assets/018_huggingface.html-WI0c55vB.js" as="script"><link rel="prefetch" href="/blog/assets/019_ollama.html-kLkdC4dl.js" as="script"><link rel="prefetch" href="/blog/assets/020_neo4j.html-P-Llr3CJ.js" as="script"><link rel="prefetch" href="/blog/assets/021_microsoft_graphrag.html-0d0frUhq.js" as="script"><link rel="prefetch" href="/blog/assets/022_llamaindex_graphrag.html-RhkTd_Zr.js" as="script"><link rel="prefetch" href="/blog/assets/023_agent_framework.html-5MCDM_Sd.js" as="script"><link rel="prefetch" href="/blog/assets/024_distribution_and_parallelism.html-uCefT9T7.js" as="script"><link rel="prefetch" href="/blog/assets/025_distribution_and_parallelism_1.html-32IzAErP.js" as="script"><link rel="prefetch" href="/blog/assets/026_distribution_and_parallelism_2.html-MEZ1JY2b.js" as="script"><link rel="prefetch" href="/blog/assets/027_distribution_and_parallelism_3.html-IYByZhbZ.js" as="script"><link rel="prefetch" href="/blog/assets/028_distribution_and_parallelism_4.html-Kub1JEXd.js" as="script"><link rel="prefetch" href="/blog/assets/030_wandb.html-61V6KLeo.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ZDCSnlc1.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ZYw6WxxA.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-OavE9BET.js" as="script"><link rel="prefetch" href="/blog/assets/001_langchain.html-hE_T0u_5.js" as="script"><link rel="prefetch" href="/blog/assets/002_langchain_sourcecode.html-iH0mq6XB.js" as="script"><link rel="prefetch" href="/blog/assets/003_streamlit.html-WyFhRqF6.js" as="script"><link rel="prefetch" href="/blog/assets/004_transformer.html-wy9Toayl.js" as="script"><link rel="prefetch" href="/blog/assets/005_llama.html-6PFDsh_d.js" as="script"><link rel="prefetch" href="/blog/assets/006_llm_leaderboard.html-WHPR-17-.js" as="script"><link rel="prefetch" href="/blog/assets/007_computer_use.html-hz6Q-DAA.js" as="script"><link rel="prefetch" href="/blog/assets/008_rag_challenge.html-3KMCwhrh.js" as="script"><link rel="prefetch" href="/blog/assets/009_llm_challenge.html-7gxKMp_3.js" as="script"><link rel="prefetch" href="/blog/assets/010_rag_workflow.html-KndRvZAj.js" as="script"><link rel="prefetch" href="/blog/assets/011_vector_database.html-DtFi92ig.js" as="script"><link rel="prefetch" href="/blog/assets/012_prompt_engineering.html-ZdCqy2Fu.js" as="script"><link rel="prefetch" href="/blog/assets/013_optimizing_llm.html-W-CdR_ck.js" as="script"><link rel="prefetch" href="/blog/assets/014_rag_evaluation.html-aq7YkQ-T.js" as="script"><link rel="prefetch" href="/blog/assets/015_fine_tune.html-egR6ajJ8.js" as="script"><link rel="prefetch" href="/blog/assets/016_multimodal.html-DCPUUxWe.js" as="script"><link rel="prefetch" href="/blog/assets/017_agent_and_multiagent.html-bS1SRdf4.js" as="script"><link rel="prefetch" href="/blog/assets/018_huggingface.html-Si3T7PB7.js" as="script"><link rel="prefetch" href="/blog/assets/019_ollama.html-V5tcXCC4.js" as="script"><link rel="prefetch" href="/blog/assets/020_neo4j.html-ytaIU5xV.js" as="script"><link rel="prefetch" href="/blog/assets/021_microsoft_graphrag.html-kvlLpO3f.js" as="script"><link rel="prefetch" href="/blog/assets/022_llamaindex_graphrag.html-nS8_ZZy5.js" as="script"><link rel="prefetch" href="/blog/assets/023_agent_framework.html-VZsN2kO8.js" as="script"><link rel="prefetch" href="/blog/assets/024_distribution_and_parallelism.html-MO4kg9bC.js" as="script"><link rel="prefetch" href="/blog/assets/025_distribution_and_parallelism_1.html-ZR9kuXUl.js" as="script"><link rel="prefetch" href="/blog/assets/026_distribution_and_parallelism_2.html-GkjDPoeT.js" as="script"><link rel="prefetch" href="/blog/assets/027_distribution_and_parallelism_3.html-5kFJGreK.js" as="script"><link rel="prefetch" href="/blog/assets/028_distribution_and_parallelism_4.html-38Gbieji.js" as="script"><link rel="prefetch" href="/blog/assets/029_unsloth_grpo.html-sutxVW-j.js" as="script"><link rel="prefetch" href="/blog/assets/030_wandb.html-VCoqJJSk.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-wh_dBtOR.js" as="script"><link rel="prefetch" href="/blog/assets/404.html-cxLWDy2T.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-kf4JCRaf.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-RkA-insV.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-4kI_oqSd.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-WhuidxNt.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-OqGkeUA_.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-5GeN-sdD.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-c4Rf4yh1.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-2r0jUs7o.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-BSKRXRQc.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-KjTsJ0Hg.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-TteIwMx3.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-g00XXzrL.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-YxbJgo4L.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-3T79Cy0i.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-A5tlQHan.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-04ff5e0O.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-vgZ6rfFh.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-OmipPplE.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-E1KrJL6a.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-oPH9QkTj.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-cHRqZSs8.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-74SU9ZTn.js" as="script"><link rel="prefetch" href="/blog/assets/index.html--iJiA8oX.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-oZPWb_Fc.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-FUIWSLsp.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-5ERWyusD.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Zjn0JNqd.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-jcvPTrgB.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-9t2TsyuQ.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-CcLVFNIv.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-DVoYOOaL.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-V52ipvRm.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-9If_KW0o.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-df9Mrf2R.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-f9bWoKcO.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-GYH0QUoo.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-JVTfeijx.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-_C1QVNqX.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-L_IXFmna.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-nZWHmXY7.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-x4gPgqE4.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-bWnVyuyA.js" as="script"><link rel="prefetch" href="/blog/assets/index.html--yTU23ka.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-tRnpyzfw.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-7aypos-L.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-1BXcbV1R.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-pu478WKz.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-LHukpLS7.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-howjHe2f.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-DeN_iOWx.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-cnlzR0a7.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-0P_c_pcU.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-dy_CcFmq.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-FzFytZ_p.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-2KSwV7xp.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-F1coElwg.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ffflqCb9.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-F8ZuLYgH.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-HeYWaFeL.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-xKYeJEc5.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-xB-iS7Ql.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-OEUPqfTV.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-EE4iQI9m.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-g1PUF_BG.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-nUBcs85a.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-9Y3la5Sf.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-wufIFDPM.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-bXZQIxRE.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-wd6ZkEHi.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Xlk0AXmC.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Uv7c7pYa.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-FfZqC9tZ.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-mSPhZxqB.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-51HoKD5A.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Q5_K6Vux.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-jkWPo860.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-kTEqch5G.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-y4iBqBqc.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ibHhI9SI.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-3hk_s27_.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-QJ9j3Zl2.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-QvWFHL99.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Pefl6i_g.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-OYT9Cnbu.js" as="script"><link rel="prefetch" href="/blog/assets/intro.html-jA3YYHtT.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-C-ni94Fk.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-78DLFUPD.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ejUtAtf9.js" as="script"><link rel="prefetch" href="/blog/assets/intro.html-sb0pph-w.js" as="script"><link rel="prefetch" href="/blog/assets/001_langchain.html-zU6p2z7r.js" as="script"><link rel="prefetch" href="/blog/assets/002_langchain_sourcecode.html-vsxilBcr.js" as="script"><link rel="prefetch" href="/blog/assets/003_streamlit.html-Q52mdydL.js" as="script"><link rel="prefetch" href="/blog/assets/004_transformer.html-bqLQzmSl.js" as="script"><link rel="prefetch" href="/blog/assets/005_llama.html-YBGwLDeJ.js" as="script"><link rel="prefetch" href="/blog/assets/006_llm_leaderboard.html-JQ9W-PkJ.js" as="script"><link rel="prefetch" href="/blog/assets/007_computer_use.html-r-og2oac.js" as="script"><link rel="prefetch" href="/blog/assets/008_rag_challenge.html-KGJ0GjhB.js" as="script"><link rel="prefetch" href="/blog/assets/009_llm_challenge.html-YFPEbTyR.js" as="script"><link rel="prefetch" href="/blog/assets/010_rag_workflow.html-F79n8rL8.js" as="script"><link rel="prefetch" href="/blog/assets/011_vector_database.html-NkD2ZCYw.js" as="script"><link rel="prefetch" href="/blog/assets/012_prompt_engineering.html-f4swVPMN.js" as="script"><link rel="prefetch" href="/blog/assets/013_optimizing_llm.html-kvEOtqsY.js" as="script"><link rel="prefetch" href="/blog/assets/014_rag_evaluation.html-7rtbm_km.js" as="script"><link rel="prefetch" href="/blog/assets/015_fine_tune.html-ovVaCwRK.js" as="script"><link rel="prefetch" href="/blog/assets/016_multimodal.html-amF7EkKC.js" as="script"><link rel="prefetch" href="/blog/assets/017_agent_and_multiagent.html-Tg6CSKhx.js" as="script"><link rel="prefetch" href="/blog/assets/018_huggingface.html-_FPJ0V83.js" as="script"><link rel="prefetch" href="/blog/assets/019_ollama.html-1utoVcuX.js" as="script"><link rel="prefetch" href="/blog/assets/020_neo4j.html-96p4te7X.js" as="script"><link rel="prefetch" href="/blog/assets/021_microsoft_graphrag.html-tSvHmdh_.js" as="script"><link rel="prefetch" href="/blog/assets/022_llamaindex_graphrag.html-ZNSmZ1eW.js" as="script"><link rel="prefetch" href="/blog/assets/023_agent_framework.html-MVnBUcj-.js" as="script"><link rel="prefetch" href="/blog/assets/024_distribution_and_parallelism.html-yYlq00eN.js" as="script"><link rel="prefetch" href="/blog/assets/025_distribution_and_parallelism_1.html-xyHvuySO.js" as="script"><link rel="prefetch" href="/blog/assets/026_distribution_and_parallelism_2.html-OH2HJ7xc.js" as="script"><link rel="prefetch" href="/blog/assets/027_distribution_and_parallelism_3.html-7WU74Fl_.js" as="script"><link rel="prefetch" href="/blog/assets/028_distribution_and_parallelism_4.html-vybKOYMh.js" as="script"><link rel="prefetch" href="/blog/assets/030_wandb.html-Q6WnGftQ.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-3VpyOHva.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-7SlZqp6l.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-0hMhEjR6.js" as="script"><link rel="prefetch" href="/blog/assets/001_langchain.html-WBkx0nZY.js" as="script"><link rel="prefetch" href="/blog/assets/002_langchain_sourcecode.html-r8CAo3a-.js" as="script"><link rel="prefetch" href="/blog/assets/003_streamlit.html-9iFMqJ97.js" as="script"><link rel="prefetch" href="/blog/assets/004_transformer.html-CXC8CtMG.js" as="script"><link rel="prefetch" href="/blog/assets/005_llama.html-qJmyt2RU.js" as="script"><link rel="prefetch" href="/blog/assets/006_llm_leaderboard.html-3LNNY4wc.js" as="script"><link rel="prefetch" href="/blog/assets/007_computer_use.html-LE5UGr5U.js" as="script"><link rel="prefetch" href="/blog/assets/008_rag_challenge.html-4FfpU1Ak.js" as="script"><link rel="prefetch" href="/blog/assets/009_llm_challenge.html-A2uyVDu1.js" as="script"><link rel="prefetch" href="/blog/assets/010_rag_workflow.html-iBYWnYul.js" as="script"><link rel="prefetch" href="/blog/assets/011_vector_database.html-DGMArgRj.js" as="script"><link rel="prefetch" href="/blog/assets/012_prompt_engineering.html-NAyPUQko.js" as="script"><link rel="prefetch" href="/blog/assets/013_optimizing_llm.html--ho9KWRE.js" as="script"><link rel="prefetch" href="/blog/assets/014_rag_evaluation.html-0ErZ3QLK.js" as="script"><link rel="prefetch" href="/blog/assets/015_fine_tune.html-VoWFuc51.js" as="script"><link rel="prefetch" href="/blog/assets/016_multimodal.html-n5QCzM2z.js" as="script"><link rel="prefetch" href="/blog/assets/017_agent_and_multiagent.html-Ns1Si_7v.js" as="script"><link rel="prefetch" href="/blog/assets/018_huggingface.html-MSleXtOZ.js" as="script"><link rel="prefetch" href="/blog/assets/019_ollama.html-Il1wDXj2.js" as="script"><link rel="prefetch" href="/blog/assets/020_neo4j.html-zlL21HmT.js" as="script"><link rel="prefetch" href="/blog/assets/021_microsoft_graphrag.html-kLExa2kF.js" as="script"><link rel="prefetch" href="/blog/assets/022_llamaindex_graphrag.html-gPhzeJCy.js" as="script"><link rel="prefetch" href="/blog/assets/023_agent_framework.html-raJW7Ac-.js" as="script"><link rel="prefetch" href="/blog/assets/024_distribution_and_parallelism.html-t3KynS2n.js" as="script"><link rel="prefetch" href="/blog/assets/025_distribution_and_parallelism_1.html-phz7lCxn.js" as="script"><link rel="prefetch" href="/blog/assets/026_distribution_and_parallelism_2.html-HlrVZU0m.js" as="script"><link rel="prefetch" href="/blog/assets/027_distribution_and_parallelism_3.html-KIxdO5y4.js" as="script"><link rel="prefetch" href="/blog/assets/028_distribution_and_parallelism_4.html-rohB09rA.js" as="script"><link rel="prefetch" href="/blog/assets/029_unsloth_grpo.html-pnMevtmN.js" as="script"><link rel="prefetch" href="/blog/assets/030_wandb.html-zy1ozukQ.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-KiM80mJ1.js" as="script"><link rel="prefetch" href="/blog/assets/404.html-NMKNbTZZ.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-uuLs4Z6T.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-uSbZshJ7.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Pjjw5hBr.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Nxz0rJgl.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-avNwbgT0.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-cFEQSQb_.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-4FdO6iLl.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-s4qPvThw.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-SCKeaVz_.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-2mKvY1J7.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-TE60ZeTW.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-iQQeZ-Qn.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-re9WgKEF.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-v31mdPp8.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-wdOUrqFy.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-lcNqrqK0.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-juJEPrQi.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-oda_9UAG.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-5rycXluJ.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-MhCutf3A.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-a1TfCsZE.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-VNp41I_t.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-clVt1M4B.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-8ZN2skYB.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-wNoTchuG.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-em1VeGA2.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-DlfMgDES.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-sF5uEuxu.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ZxIk5SO3.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ZTIv45jP.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-dxktCSmc.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-cqTcjC3T.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ia8pAM6l.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-gPkfiI8J.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-CT4Zfip2.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-t6Ogar8X.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-kmLnoh8w.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-OKwqbula.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-UmHwNsjM.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-cA_tSQhe.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-aUuInsxF.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-WAGHZNJp.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-JhFrMp_O.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Gez6p6Wp.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-wuVlLLHf.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-xXXzqjQ4.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-o5xi6WsO.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-RLZ-NUsj.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-DTjL0MvC.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-9ocihkiO.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ulKbpJpF.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-h8wz2RIU.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-P9UcmUsl.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Vwr4GyWV.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-zzCZoAez.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-2OUkQvnt.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-5iSZ802H.js" as="script"><link rel="prefetch" href="/blog/assets/index.html--umbkG-f.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-T-vcpvgB.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-BUozHpgo.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-3V7lx-Tm.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-aTFV0IwY.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-44NuA0qZ.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-bndBTKLa.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ICDAifEc.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-9nh8zOWp.js" as="script"><link rel="prefetch" href="/blog/assets/index.html--y9b_seJ.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-pUW-WDvr.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-v4CW4uPg.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-eiHhCvRd.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-JvwwPVL9.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-NmmZefCF.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-j4z0QamO.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-pbksNDDb.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-DaEMivwb.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-SQ2q_phL.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-7WaGqIhR.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-d37KOrcK.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-EwXZftCs.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-bjakj1z-.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Mz7msLP8.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-O3L58gdm.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-DBRLv6Q6.js" as="script"><link rel="prefetch" href="/blog/assets/photoswipe.esm-08_zHRDQ.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">Skip to main content</a><!--]--><!--[--><div class="theme-container no-sidebar has-toc"><!--[--><header id="navbar" class="vp-navbar"><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!--[--><!----><!--]--><!--[--><a class="vp-link vp-brand vp-brand" href="/blog/"><img class="vp-nav-logo" src="/blog/blogger.png" alt><!----><span class="vp-site-name hide-in-pad">Liz</span></a><!--]--><!--[--><!----><!--]--></div><div class="vp-navbar-center"><!--[--><!----><!--]--><!--[--><nav class="vp-nav-links"><div class="nav-item hide-in-mobile"><a aria-label="Home" class="vp-link nav-link nav-link" href="/blog/"><span class="font-icon icon fa-fw fa-sm fas fa-home" style=""></span>Home<!----></a></div><div class="nav-item hide-in-mobile"><a aria-label="Project" class="vp-link nav-link nav-link" href="/blog/demo/"><span class="font-icon icon fa-fw fa-sm fas fa-star" style=""></span>Project<!----></a></div></nav><!--]--><!--[--><!----><!--]--></div><div class="vp-navbar-end"><!--[--><!----><!--]--><!--[--><div class="nav-item"><div class="dropdown-wrapper i18n-dropdown"><button type="button" class="dropdown-title" aria-label="Select language"><!--[--><svg xmlns="http://www.w3.org/2000/svg" class="icon i18n-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="i18n icon" style="width:1rem;height:1rem;vertical-align:middle;"><path d="M379.392 460.8 494.08 575.488l-42.496 102.4L307.2 532.48 138.24 701.44l-71.68-72.704L234.496 460.8l-45.056-45.056c-27.136-27.136-51.2-66.56-66.56-108.544h112.64c7.68 14.336 16.896 27.136 26.112 35.84l45.568 46.08 45.056-45.056C382.976 312.32 409.6 247.808 409.6 204.8H0V102.4h256V0h102.4v102.4h256v102.4H512c0 70.144-37.888 161.28-87.04 210.944L378.88 460.8zM576 870.4 512 1024H409.6l256-614.4H768l256 614.4H921.6l-64-153.6H576zM618.496 768h196.608L716.8 532.48 618.496 768z"></path></svg><!--]--><span class="arrow"></span><ul class="nav-dropdown"><li class="dropdown-item"><a aria-label="English" class="vp-link nav-link active nav-link active" href="/blog/posts/llm/029_unsloth_grpo.html"><!---->English<!----></a></li><li class="dropdown-item"><a aria-label="简体中文" class="vp-link nav-link nav-link" href="/blog/zh/posts/llm/029_unsloth_grpo.html"><!---->简体中文<!----></a></li></ul></button></div></div><div class="nav-item vp-repo"><a class="vp-repo-link" href="https://github.com/liz-in-tech" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><div class="nav-item hide-in-mobile"><button type="button" id="appearance-switch"><svg xmlns="http://www.w3.org/2000/svg" class="icon auto-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="auto icon" style="display:block;"><path d="M512 992C246.92 992 32 777.08 32 512S246.92 32 512 32s480 214.92 480 480-214.92 480-480 480zm0-840c-198.78 0-360 161.22-360 360 0 198.84 161.22 360 360 360s360-161.16 360-360c0-198.78-161.22-360-360-360zm0 660V212c165.72 0 300 134.34 300 300 0 165.72-134.28 300-300 300z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon dark-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="dark icon" style="display:none;"><path d="M524.8 938.667h-4.267a439.893 439.893 0 0 1-313.173-134.4 446.293 446.293 0 0 1-11.093-597.334A432.213 432.213 0 0 1 366.933 90.027a42.667 42.667 0 0 1 45.227 9.386 42.667 42.667 0 0 1 10.24 42.667 358.4 358.4 0 0 0 82.773 375.893 361.387 361.387 0 0 0 376.747 82.774 42.667 42.667 0 0 1 54.187 55.04 433.493 433.493 0 0 1-99.84 154.88 438.613 438.613 0 0 1-311.467 128z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon light-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="light icon" style="display:none;"><path d="M952 552h-80a40 40 0 0 1 0-80h80a40 40 0 0 1 0 80zM801.88 280.08a41 41 0 0 1-57.96-57.96l57.96-58a41.04 41.04 0 0 1 58 58l-58 57.96zM512 752a240 240 0 1 1 0-480 240 240 0 0 1 0 480zm0-560a40 40 0 0 1-40-40V72a40 40 0 0 1 80 0v80a40 40 0 0 1-40 40zm-289.88 88.08-58-57.96a41.04 41.04 0 0 1 58-58l57.96 58a41 41 0 0 1-57.96 57.96zM192 512a40 40 0 0 1-40 40H72a40 40 0 0 1 0-80h80a40 40 0 0 1 40 40zm30.12 231.92a41 41 0 0 1 57.96 57.96l-57.96 58a41.04 41.04 0 0 1-58-58l58-57.96zM512 832a40 40 0 0 1 40 40v80a40 40 0 0 1-80 0v-80a40 40 0 0 1 40-40zm289.88-88.08 58 57.96a41.04 41.04 0 0 1-58 58l-57.96-58a41 41 0 0 1 57.96-57.96z"></path></svg></button></div><form class="search-box" role="search"><input type="search" autocomplete="off" spellcheck="false" value><!----></form><!--]--><!--[--><!----><!--]--><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar"><!--[--><!----><!--]--><ul class="vp-sidebar-links"></ul><!--[--><!----><!--]--></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!--[--><!----><!--]--><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><span class="font-icon icon fa-fw fa-sm fas fa-lightbulb" style=""></span>GRPO + Unsloth + vLLM</h1><div class="page-info"><span class="page-author-info" aria-label="Author🖊" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><a class="page-author-item" href="https://github.com/liz-in-tech" target="_blank" rel="noopener noreferrer">Liz</a></span><span property="author" content="Liz"></span></span><!----><span class="page-date-info" aria-label="Writing Date📅" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span><!----></span><meta property="datePublished" content="2025-03-08T00:00:00.000Z"></span><!----><span class="page-reading-time-info" aria-label="Reading Time⌛" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>About 10 min</span><meta property="timeRequired" content="PT10M"></span><span class="page-category-info" aria-label="Category🌈" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon category-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="category icon"><path d="M148.41 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H148.41c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.311-40.31zM147.556 553.478H429.73c22.263 0 40.311 18.048 40.311 40.31v282.176c0 22.263-18.048 40.312-40.31 40.312H147.555c-22.263 0-40.311-18.049-40.311-40.312V593.79c0-22.263 18.048-40.311 40.31-40.311zM593.927 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H593.927c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.31-40.31zM730.22 920.502H623.926c-40.925 0-74.22-33.388-74.22-74.425V623.992c0-41.038 33.387-74.424 74.425-74.424h222.085c41.038 0 74.424 33.226 74.424 74.067v114.233c0 10.244-8.304 18.548-18.547 18.548s-18.548-8.304-18.548-18.548V623.635c0-20.388-16.746-36.974-37.33-36.974H624.13c-20.585 0-37.331 16.747-37.331 37.33v222.086c0 20.585 16.654 37.331 37.126 37.331H730.22c10.243 0 18.547 8.304 18.547 18.547 0 10.244-8.304 18.547-18.547 18.547z"></path></svg><!--[--><span class="page-category-item category6 clickable" role="navigation">LLM</span><!--]--><meta property="articleSection" content="LLM"></span><span class="page-tag-info" aria-label="Tag🏷" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon tag-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="tag icon"><path d="M939.902 458.563L910.17 144.567c-1.507-16.272-14.465-29.13-30.737-30.737L565.438 84.098h-.402c-3.215 0-5.726 1.005-7.634 2.913l-470.39 470.39a10.004 10.004 0 000 14.164l365.423 365.424c1.909 1.908 4.42 2.913 7.132 2.913s5.223-1.005 7.132-2.913l470.39-470.39c2.01-2.11 3.014-5.023 2.813-8.036zm-240.067-72.121c-35.458 0-64.286-28.828-64.286-64.286s28.828-64.285 64.286-64.285 64.286 28.828 64.286 64.285-28.829 64.286-64.286 64.286z"></path></svg><!--[--><span class="page-tag-item tag4 clickable" role="navigation">GRPO</span><span class="page-tag-item tag6 clickable" role="navigation">RL</span><span class="page-tag-item tag4 clickable" role="navigation">Unsloth</span><span class="page-tag-item tag7 clickable" role="navigation">vLLM</span><!--]--><meta property="keywords" content="GRPO,RL,Unsloth,vLLM"></span></div><hr></div><div class="toc-place-holder"><aside id="toc"><!--[--><!----><!--]--><div class="toc-header">On This Page<button type="button" class="print-button" title="Print"><svg xmlns="http://www.w3.org/2000/svg" class="icon print-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="print icon"><path d="M819.2 364.8h-44.8V128c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v236.8h-44.8C145.067 364.8 96 413.867 96 473.6v192c0 59.733 49.067 108.8 108.8 108.8h44.8V896c0 17.067 14.933 32 32 32h460.8c17.067 0 32-14.933 32-32V774.4h44.8c59.733 0 108.8-49.067 108.8-108.8v-192c0-59.733-49.067-108.8-108.8-108.8zM313.6 160h396.8v204.8H313.6V160zm396.8 704H313.6V620.8h396.8V864zM864 665.6c0 25.6-19.2 44.8-44.8 44.8h-44.8V588.8c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v121.6h-44.8c-25.6 0-44.8-19.2-44.8-44.8v-192c0-25.6 19.2-44.8 44.8-44.8h614.4c25.6 0 44.8 19.2 44.8 44.8v192z"></path></svg></button></div><div class="toc-wrapper"><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_1-grpo">1. GRPO</a></li><li><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_1-1-what-grpo-can-do">1.1. What GRPO Can Do</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_1-2-how-grpo-works">1.2. How GRPO Works</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_1-3-grpo-vs-ppo">1.3. GRPO vs PPO</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_1-4-three-revolutionary-designs-of-grpo">1.4. Three Revolutionary Designs of GRPO</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_1-5-comparison-of-different-llm-training-methods">1.5. Comparison of Different LLM Training Methods</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_2-efficient-grpo-training-with-unsloth">2. Efficient GRPO Training with Unsloth</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_3-grpo-training-tips">3. GRPO Training Tips</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_4-code-implementation">4. Code Implementation</a></li><li><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_4-1-install-required-libraries">4.1. Install Required Libraries</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_4-2-load-llama-3-1-8b-instruct-model">4.2. Load Llama-3.1-8B-Instruct Model</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_4-3-inference-before-grpo-training">4.3. Inference Before GRPO Training</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_4-4-load-and-prepare-dataset">4.4. Load and Prepare Dataset</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_4-5-set-lora-fine-tuning-configuration">4.5. Set LoRA Fine-tuning Configuration</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_4-6-define-reward-functions">4.6. Define Reward Functions</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_4-7-configure-grpo-parameters">4.7. Configure GRPO Parameters</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_4-8-define-grpotrainer">4.8. Define GRPOTrainer</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_4-9-start-grpo-training">4.9. Start GRPO Training</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_4-10-save-lora-weights">4.10. Save LoRA Weights</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_4-11-inference-after-grpo-training">4.11. Inference After GRPO Training</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_5-references">5. References</a></li><!----><!--]--></ul><div class="toc-marker" style="top:-1.7rem;"></div></div><!--[--><!----><!--]--></aside></div><!--[--><!----><!--]--><div class="theme-hope-content"><h1 id="grpo-unsloth-vllm" tabindex="-1"><a class="header-anchor" href="#grpo-unsloth-vllm" aria-hidden="true">#</a> GRPO + Unsloth + vLLM</h1><!-- more --><ul><li>GRPO (Group Relative Policy Optimization): A reinforcement learning method focused on optimizing model performance based on a specific reward function.</li><li>Unsloth: A framework for efficiently fine-tuning large language models.</li><li>vllm: An inference framework optimized for large language models.</li></ul><h2 id="_1-grpo" tabindex="-1"><a class="header-anchor" href="#_1-grpo" aria-hidden="true">#</a> 1. GRPO</h2><p>GRPO (Group Relative Policy Optimization)</p><p>GRPO was first introduced in <a href="https://arxiv.org/pdf/2402.03300" target="_blank" rel="noopener noreferrer">DeepSeek&#39;s Math paper<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a> from February to April 2024, and later utilized by DeepSeek in creating <a href="https://arxiv.org/pdf/2501.12948" target="_blank" rel="noopener noreferrer">DeepSeek R1<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a> as described in their paper.</p><h3 id="_1-1-what-grpo-can-do" tabindex="-1"><a class="header-anchor" href="#_1-1-what-grpo-can-do" aria-hidden="true">#</a> 1.1. What GRPO Can Do</h3><p>GRPO can transform standard models into fully functional inference models.</p><p>The main goal of GRPO is to maximize rewards and learn how answers are derived, rather than simply memorizing and reproducing answers from training data.</p><p>Conventional fine-tuning (without GRPO) only maximizes the prediction probability of the next word, without optimizing for rewards. GRPO optimizes the reward function, not just the next word prediction.</p><p>Initially, a large amount of data was needed to fill in the reasoning process or chain of thought. But GRPO or other reinforcement learning algorithms can guide the model to automatically exhibit reasoning abilities and generate reasoning trajectories, relying on GRPO or other reinforcement learning algorithms to create good reward functions or validators.</p><p>The application scenarios of GRPO are not limited to code or mathematics. Its reasoning process can also enhance tasks such as email automation, database retrieval, legal, and medical tasks, greatly improving accuracy based on the datasets and reward functions used in training!</p><h3 id="_1-2-how-grpo-works" tabindex="-1"><a class="header-anchor" href="#_1-2-how-grpo-works" aria-hidden="true">#</a> 1.2. How GRPO Works</h3><ol><li>For each question-answer pair, the model generates multiple responses as a group (e.g., 8 different responses).</li><li>Each response is scored based on the reward function.</li><li>The average score of the group of responses is calculated as a baseline.</li><li>Each response&#39;s score is compared to the average score, and each response&#39;s advantage value is determined by the difference between its score and the baseline.</li><li>The model is enhanced to favor higher-scoring responses.</li></ol><h3 id="_1-3-grpo-vs-ppo" tabindex="-1"><a class="header-anchor" href="#_1-3-grpo-vs-ppo" aria-hidden="true">#</a> 1.3. GRPO vs PPO</h3><h4 id="_1-3-1-the-double-teacher-dilemma-of-ppo" tabindex="-1"><a class="header-anchor" href="#_1-3-1-the-double-teacher-dilemma-of-ppo" aria-hidden="true">#</a> 1.3.1. The &quot;Double Teacher Dilemma&quot; of PPO</h4><p>In traditional reinforcement learning methods, PPO (Proximal Policy Optimization) is widely used, where the training system requires two &quot;teachers&quot; to work together: the policy model (student) is responsible for generating answers, and the value model (scoring teacher) is responsible for evaluating quality. This architecture has three fundamental flaws:</p><ul><li>Resource consumption black hole: The parameter size of the value model is often comparable to the policy model, requiring additional storage of gradient parameters during training, doubling memory usage.</li><li>Evaluation standard drift: Asynchronous updates of the two models can easily lead to inconsistent &quot;teaching standards.&quot;</li><li>Absolute scoring trap: The absolute score of a single output is difficult to reflect the relative merits of answers. These problems are particularly prominent in complex reasoning tasks. When dealing with multi-step mathematical proofs, traditional methods are like using the same ruler to measure answers of different dimensions, easily causing evaluation bias.</li></ul><h4 id="_1-3-2-grpo-s-improvements-over-ppo" tabindex="-1"><a class="header-anchor" href="#_1-3-2-grpo-s-improvements-over-ppo" aria-hidden="true">#</a> 1.3.2. GRPO&#39;s Improvements Over PPO</h4><p>Imagine you are teaching a student to solve math problems. Traditional methods may require another teacher (value function model) to evaluate the student&#39;s performance. GRPO adopts a smarter approach: letting the student generate multiple answers and then guiding learning by comparing the merits of these answers. This method is not only more intuitive but also greatly improves learning efficiency. It is closer to the human cognitive way of &quot;comparative learning,&quot; where the merits of answers are no longer determined by absolute scores but are generated through group comparison.</p><p>GRPO is a reinforcement learning method developed on the popular PPO (Proximal Policy Optimization). Its biggest innovation is the introduction of the &quot;intra-group relative evaluation&quot; mechanism, while removing the need for a value function model in traditional methods, making the entire training process more efficient and stable.</p><figure><img src="/blog/assets/029_grpo_vs_ppo-BtZ68f6c.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h3 id="_1-4-three-revolutionary-designs-of-grpo" tabindex="-1"><a class="header-anchor" href="#_1-4-three-revolutionary-designs-of-grpo" aria-hidden="true">#</a> 1.4. Three Revolutionary Designs of GRPO</h3><h4 id="_1-4-1-from-decisive-evaluation-mechanism-to-relative-evaluation-mechanism" tabindex="-1"><a class="header-anchor" href="#_1-4-1-from-decisive-evaluation-mechanism-to-relative-evaluation-mechanism" aria-hidden="true">#</a> 1.4.1. From Decisive Evaluation Mechanism to Relative Evaluation Mechanism</h4><p>This relative evaluation mechanism brings three major advantages:</p><ul><li>Evaluation dimension normalization: Automatically eliminates the impact of differences in question difficulty.</li><li>Error compensation effect: Random fluctuations are naturally smoothed in group comparisons.</li><li>Implicit knowledge mining: The model learns implicit rules beyond the scoring standard through comparison.</li></ul><h4 id="_1-4-2-removal-of-the-value-function-model" tabindex="-1"><a class="header-anchor" href="#_1-4-2-removal-of-the-value-function-model" aria-hidden="true">#</a> 1.4.2. Removal of the Value Function Model</h4><ul><li>GRPO&#39;s success validates the &quot;less is more&quot; technical philosophy.</li><li>GRPO, a reinforcement learning technology, efficiently optimizes responses without the need for a value function model, reducing memory and computational costs compared to PPO.</li><li>By replacing complex model inference with simple matrix operations, training speed is increased by 40%, and memory usage is reduced by 55%. This design is especially suitable for training today&#39;s large models with billions of parameters.</li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># Traditional PPO advantage calculation</span>
advantage <span class="token operator">=</span> reward <span class="token operator">-</span> value_model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>state<span class="token punctuation">)</span>

<span class="token comment"># GRPO advantage calculation</span>
group_rewards <span class="token operator">=</span> <span class="token punctuation">[</span>r1<span class="token punctuation">,</span> r2<span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> rn<span class="token punctuation">]</span>
baseline <span class="token operator">=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>group_rewards<span class="token punctuation">)</span>
advantages <span class="token operator">=</span> <span class="token punctuation">[</span>r <span class="token operator">-</span> baseline <span class="token keyword">for</span> r <span class="token keyword">in</span> group_rewards<span class="token punctuation">]</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>In the GSM8K math benchmark test, models empowered by GRPO showed amazing breakthroughs:</p><figure><img src="/blog/assets/029_performance_comparation-RbnGa91p.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h4 id="_1-4-3-kl-intelligent-constraint" tabindex="-1"><a class="header-anchor" href="#_1-4-3-kl-intelligent-constraint" aria-hidden="true">#</a> 1.4.3. KL Intelligent Constraint</h4><p>GRPO directly integrates the KL divergence constraint into the loss function, creatively solving the &quot;catastrophic forgetting&quot; problem in reinforcement learning.</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>Loss = -E[log(π(a|s)) * A] + β*KL(π||π_ref)
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>Where the β parameter is dynamically adjusted through an adaptive algorithm, achieving a subtle balance between exploration and convergence. Experiments show that this design improves the training stability of mathematical reasoning tasks by 70%.</p><h3 id="_1-5-comparison-of-different-llm-training-methods" tabindex="-1"><a class="header-anchor" href="#_1-5-comparison-of-different-llm-training-methods" aria-hidden="true">#</a> 1.5. Comparison of Different LLM Training Methods</h3><ul><li>SFT <ul><li>Standardizes model output format (with reasoning and answer tags).</li><li>Difficult to learn the mathematical rules and meta-thinking behind the data, still only learns the generation probability of the next token.</li><li>Poor generalization ability, somewhat rote memorization.</li></ul></li><li>Traditional RL <ul><li>A large amount of high-quality data containing problem-solving steps and precise reward functions, then training with brute force.</li><li>Has long-cot, belongs to the type with standard answers, so the model completely fits and approaches the long-cot, essentially learning according to the standard answers and problem-solving process of the training data.</li><li>No mutual comparison between multiple answers (no distinction between the merits of answers), somewhat like cramming education.</li></ul></li><li>GRPO <ul><li>Encourages the model to learn the rules behind reasoning in the process of maximizing rewards through trial and error.</li><li>GRPO only looks at the result, the process is explored and attempted by the model itself. There is no standard cot answer (only the final answer), requiring the model to do a lot of exploration to find the optimal cot, so the model has an aha moment, with better generalization.</li><li>Flexible rewards, generating multiple responses for each question, finding the optimal ones, guiding the model towards the optimal direction.</li><li>Doing so results in a very chaotic reasoning format in the first 100+ steps, so R1 first uses long-cot for SFT on the basis of R1-zero, allowing the model&#39;s response to output according to a predetermined template, appropriately reducing some exploration steps, and improving training efficiency.</li><li>Higher upper bound on generalization and reasoning performance.</li></ul></li></ul><h2 id="_2-efficient-grpo-training-with-unsloth" tabindex="-1"><a class="header-anchor" href="#_2-efficient-grpo-training-with-unsloth" aria-hidden="true">#</a> 2. Efficient GRPO Training with Unsloth</h2><ul><li>With the help of 15GB of VRAM, Unsloth can transform any model with up to 17B parameters, such as Llama 3.1 (8B), Phi-4 (14B), Mistral (7B), or Qwen2.5 (7B), into an inference model.</li><li>In extreme cases, only 5G of VRAM is needed to train your own inference model locally, reaching the &quot;aha&quot; moment (suitable for any model with 1.5B parameters or less).</li><li>Previously, GRPO only supported full fine-tuning, Unsloth AI enables compatibility with QLoRA and LoRA.</li><li>Unsloth x vLLM: vLLM achieves fast inference, can increase throughput (up to 20 times), allows fine-tuning and inference to occur simultaneously, and magically eliminates the double memory consumption when loading vLLM and Unsloth simultaneously.</li><li>Unsloth cleverly reduces VRAM usage by over 90% compared to standard implementations (HuggingFace TRL + Flash Attention 2), significantly optimizing. For example, with a 20K context length, generating 8 times per prompt, Unsloth uses only 54.3GB of VRAM for Llama 3.1 8B, while the standard implementation requires 510.8GB (Unsloth saves 90% of VRAM). <ul><li>Unsloth&#39;s new memory-efficient linear kernel for GRPO reduces memory usage by 8 times or more. This cuts 68.5GB of memory while achieving num_generations = 8 and 20K context length with torch.compile, actually faster.</li><li>Unsloth uses the <a href="https://unsloth.ai/blog/long-context" target="_blank" rel="noopener noreferrer">smart Unsloth gradient checkpoint algorithm<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a>, intelligently offloading intermediate activations to system memory asynchronously, slowing down by only 1%. Since we need num_generations = 8, up to 372GB of VRAM can be saved. We can further reduce this memory usage through intermediate gradient accumulation.</li><li>Unsloth also uses the same GPU/CUDA memory space as the underlying inference engine (vLLM), unlike implementations from other packages, cutting 16GB of VRAM.</li></ul></li></ul><figure><img src="/blog/assets/029_unsloth_vs_standard-uc2MV5ug.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h2 id="_3-grpo-training-tips" tabindex="-1"><a class="header-anchor" href="#_3-grpo-training-tips" aria-hidden="true">#</a> 3. GRPO Training Tips</h2><ul><li>Wait at least 300 steps to see substantial reward growth.</li><li>Train the model with at least 500 rows of data.</li><li>A standard model with at least 1.5B parameters is required to generate a chain of thought with GRPO; too small a model may not generate a chain of thought.</li><li>For GRPO&#39;s GPU VRAM requirements in QLoRA 4-bit mode, the general rule is that the model parameter size equals the required VRAM size.</li><li>The longer the context length set, the more VRAM is required. LoRA 16-bit will use at least 4 times more VRAM.</li><li>One major advantage of GRPO is that you don&#39;t even need a lot of data. You only need a good reward function/validator, and the longer the training time, the better the model becomes. The reward value increases with the number of training steps.</li><li>Reward functions and validators: <ul><li>Reward function: scoring <ul><li>Correctness verification is not necessary.</li><li>Reward functions can use validators.</li></ul></li><li>Validator: correctness verification <ul><li>Does not score.</li><li>Validators can also execute code to verify logic or syntax and other correctness.</li></ul></li></ul></li><li>There is no single correct way to design reward functions or validators—the possibilities are endless. However, they must be well-designed and meaningful, as poorly designed rewards may inadvertently degrade model performance.</li></ul><h2 id="_4-code-implementation" tabindex="-1"><a class="header-anchor" href="#_4-code-implementation" aria-hidden="true">#</a> 4. Code Implementation</h2><h3 id="_4-1-install-required-libraries" tabindex="-1"><a class="header-anchor" href="#_4-1-install-required-libraries" aria-hidden="true">#</a> 4.1. Install Required Libraries</h3><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token operator">%</span><span class="token operator">%</span>capture <span class="token comment"># Jupyter magic command to capture cell output to avoid displaying lengthy installation processes</span>
<span class="token keyword">import</span> sys<span class="token punctuation">;</span> modules <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>sys<span class="token punctuation">.</span>modules<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># Get the names of all currently loaded modules</span>
<span class="token keyword">for</span> x <span class="token keyword">in</span> modules<span class="token punctuation">:</span> sys<span class="token punctuation">.</span>modules<span class="token punctuation">.</span>pop<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token keyword">if</span> <span class="token string">&quot;PIL&quot;</span> <span class="token keyword">in</span> x <span class="token keyword">or</span> <span class="token string">&quot;google&quot;</span> <span class="token keyword">in</span> x <span class="token keyword">else</span> <span class="token boolean">None</span> <span class="token comment"># Remove cached modules related to PIL (Pillow) and google</span>

!pip install unsloth vllm <span class="token comment"># Install unsloth and vllm</span>
!pip install <span class="token operator">-</span><span class="token operator">-</span>upgrade pillow <span class="token comment"># Upgrade pillow</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_4-2-load-llama-3-1-8b-instruct-model" tabindex="-1"><a class="header-anchor" href="#_4-2-load-llama-3-1-8b-instruct-model" aria-hidden="true">#</a> 4.2. Load Llama-3.1-8B-Instruct Model</h3><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># Import core libraries</span>
<span class="token keyword">from</span> unsloth <span class="token keyword">import</span> FastLanguageModel <span class="token comment"># Library for efficiently loading models</span>
<span class="token keyword">import</span> torch <span class="token comment"># PyTorch deep learning framework</span>

<span class="token comment"># Model configuration parameters</span>
max_seq_length <span class="token operator">=</span> <span class="token number">1024</span> <span class="token comment"># Maximum input sequence length (affects VRAM usage)</span>
lora_rank <span class="token operator">=</span> <span class="token number">32</span> <span class="token comment"># LoRA rank, the larger the value, the stronger the model capability, but also slower</span>

<span class="token comment"># Load the base model</span>
model<span class="token punctuation">,</span> tokenizer <span class="token operator">=</span> FastLanguageModel<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>
    model_name <span class="token operator">=</span> <span class="token string">&quot;meta-llama/meta-Llama-3.1-8B-Instruct&quot;</span><span class="token punctuation">,</span> <span class="token comment"># Base model is the 8B parameter Llama3 instruction fine-tuned version</span>
    max_seq_length <span class="token operator">=</span> max_seq_length<span class="token punctuation">,</span>
    load_in_4bit <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">,</span> <span class="token comment"># True for 4bit quantization (VRAM optimization), False for 16bit</span>
    fast_inference <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">,</span> <span class="token comment"># Enable vLLM accelerated inference</span>
    max_lora_rank <span class="token operator">=</span> lora_rank<span class="token punctuation">,</span> <span class="token comment"># Maximum LoRA rank limit</span>
    gpu_memory_utilization <span class="token operator">=</span> <span class="token number">0.6</span><span class="token punctuation">,</span> <span class="token comment"># GPU VRAM utilization (can be adjusted lower if OOM)</span>
<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_4-3-inference-before-grpo-training" tabindex="-1"><a class="header-anchor" href="#_4-3-inference-before-grpo-training" aria-hidden="true">#</a> 4.3. Inference Before GRPO Training</h3><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># Create chat template</span>
text <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>apply_chat_template<span class="token punctuation">(</span><span class="token punctuation">[</span> 
    <span class="token punctuation">{</span><span class="token string">&quot;role&quot;</span> <span class="token punctuation">:</span> <span class="token string">&quot;user&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;content&quot;</span> <span class="token punctuation">:</span> <span class="token string">&quot;Calculate pi.&quot;</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
<span class="token punctuation">]</span><span class="token punctuation">,</span> 
tokenize <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token comment"># Indicates not to tokenize the input</span>
add_generation_prompt <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token comment"># Set sampling parameters</span>
<span class="token keyword">from</span> vllm <span class="token keyword">import</span> SamplingParams
sampling_params <span class="token operator">=</span> SamplingParams<span class="token punctuation">(</span> 
    temperature <span class="token operator">=</span> <span class="token number">0.8</span><span class="token punctuation">,</span>
    top_p <span class="token operator">=</span> <span class="token number">0.95</span><span class="token punctuation">,</span>
    max_tokens <span class="token operator">=</span> <span class="token number">1024</span><span class="token punctuation">,</span> <span class="token comment"># Maximum length of generated text</span>
<span class="token punctuation">)</span>

<span class="token comment"># Generate text</span>
output <span class="token operator">=</span> model<span class="token punctuation">.</span>fast_generate<span class="token punctuation">(</span> 
    <span class="token punctuation">[</span>text<span class="token punctuation">]</span><span class="token punctuation">,</span>
    sampling_params <span class="token operator">=</span> sampling_params<span class="token punctuation">,</span>
    lora_request <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token comment"># Indicates not to use LoRA (low-rank adaptation) request</span>
<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>outputs<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>text

output
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_4-4-load-and-prepare-dataset" tabindex="-1"><a class="header-anchor" href="#_4-4-load-and-prepare-dataset" aria-hidden="true">#</a> 4.4. Load and Prepare Dataset</h3><p>OpenAI&#39;s GSM8K dataset</p><figure><img src="/blog/assets/029_dataset-WkWkZBzS.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> re <span class="token comment"># Regular expressions</span>
<span class="token keyword">from</span> datasets <span class="token keyword">import</span> load_dataset<span class="token punctuation">,</span> Dataset

SYSTEM_PROMPT <span class="token operator">=</span> <span class="token triple-quoted-string string">&quot;&quot;&quot;
Respond in the following format:
&lt;reasoning&gt;
...
&lt;/reasoning&gt;
&lt;answer&gt;
...
&lt;/answer&gt;
&quot;&quot;&quot;</span>

<span class="token keyword">def</span> <span class="token function">extract_hash_answer</span><span class="token punctuation">(</span>text<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">str</span> <span class="token operator">|</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> <span class="token string">&quot;####&quot;</span> <span class="token keyword">not</span> <span class="token keyword">in</span> text<span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token boolean">None</span>
    <span class="token keyword">return</span> text<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot;####&quot;</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># uncomment middle messages for 1-shot prompting</span>
<span class="token keyword">def</span> <span class="token function">get_gsm8k_questions</span><span class="token punctuation">(</span>split <span class="token operator">=</span> <span class="token string">&quot;train&quot;</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> Dataset<span class="token punctuation">:</span>
    data <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">&#39;openai/gsm8k&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;main&#39;</span><span class="token punctuation">)</span><span class="token punctuation">[</span>split<span class="token punctuation">]</span> <span class="token comment"># Load dataset</span>
    data <span class="token operator">=</span> data<span class="token punctuation">.</span><span class="token builtin">map</span><span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> <span class="token punctuation">{</span> <span class="token comment"># Construct as dict format</span>
        <span class="token string">&#39;prompt&#39;</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>
            <span class="token punctuation">{</span><span class="token string">&#39;role&#39;</span><span class="token punctuation">:</span> <span class="token string">&#39;system&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;content&#39;</span><span class="token punctuation">:</span> SYSTEM_PROMPT<span class="token punctuation">}</span><span class="token punctuation">,</span>
            <span class="token punctuation">{</span><span class="token string">&#39;role&#39;</span><span class="token punctuation">:</span> <span class="token string">&#39;user&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;content&#39;</span><span class="token punctuation">:</span> x<span class="token punctuation">[</span><span class="token string">&#39;question&#39;</span><span class="token punctuation">]</span><span class="token punctuation">}</span>
        <span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token string">&#39;answer&#39;</span><span class="token punctuation">:</span> extract_hash_answer<span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token string">&#39;answer&#39;</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token punctuation">}</span><span class="token punctuation">)</span> <span class="token comment"># type: ignore</span>
    <span class="token keyword">return</span> data <span class="token comment"># type: ignore</span>

dataset <span class="token operator">=</span> get_gsm8k_questions<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_4-5-set-lora-fine-tuning-configuration" tabindex="-1"><a class="header-anchor" href="#_4-5-set-lora-fine-tuning-configuration" aria-hidden="true">#</a> 4.5. Set LoRA Fine-tuning Configuration</h3><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>model <span class="token operator">=</span> FastLanguageModel<span class="token punctuation">.</span>get_peft_model<span class="token punctuation">(</span>
    model<span class="token punctuation">,</span>
    r <span class="token operator">=</span> lora_rank<span class="token punctuation">,</span> 
    target_modules <span class="token operator">=</span> <span class="token punctuation">[</span> <span class="token comment"># Modules to apply LoRA (can remove QKVO if OOM)</span>
        <span class="token string">&quot;q_proj&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;k_proj&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;v_proj&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;o_proj&quot;</span><span class="token punctuation">,</span>
        <span class="token string">&quot;gate_proj&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;up_proj&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;down_proj&quot;</span><span class="token punctuation">,</span>
    <span class="token punctuation">]</span><span class="token punctuation">,</span> 
    lora_alpha <span class="token operator">=</span> lora_rank<span class="token punctuation">,</span> <span class="token comment"># LoRA scaling factor, usually the same as rank, used to adjust the impact of LoRA</span>
    use_gradient_checkpointing <span class="token operator">=</span> <span class="token string">&quot;unsloth&quot;</span><span class="token punctuation">,</span> <span class="token comment"># Apply activation recomputation/gradient checkpointing for long text fine-tuning, set to &quot;unsloth&quot;, possibly referring to a library-specific gradient checkpointing implementation (VRAM optimization technique)</span>
    random_state <span class="token operator">=</span> <span class="token number">3407</span><span class="token punctuation">,</span> <span class="token comment"># Random seed (ensures experiment reproducibility)</span>
<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_4-6-define-reward-functions" tabindex="-1"><a class="header-anchor" href="#_4-6-define-reward-functions" aria-hidden="true">#</a> 4.6. Define Reward Functions</h3><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># Reward if LLM-generated answer matches the standard answer</span>
<span class="token keyword">def</span> <span class="token function">correctness_reward_func</span><span class="token punctuation">(</span>prompts<span class="token punctuation">,</span> completions<span class="token punctuation">,</span> answer<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">list</span><span class="token punctuation">[</span><span class="token builtin">float</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
    responses <span class="token operator">=</span> <span class="token punctuation">[</span>completion<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">&#39;content&#39;</span><span class="token punctuation">]</span> <span class="token keyword">for</span> completion <span class="token keyword">in</span> completions<span class="token punctuation">]</span> <span class="token comment"># List of LLM-generated results</span>
    q <span class="token operator">=</span> prompts<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">&#39;content&#39;</span><span class="token punctuation">]</span> <span class="token comment"># Question</span>
    extracted_responses <span class="token operator">=</span> <span class="token punctuation">[</span>extract_xml_answer<span class="token punctuation">(</span>r<span class="token punctuation">)</span> <span class="token keyword">for</span> r <span class="token keyword">in</span> responses<span class="token punctuation">]</span> <span class="token comment"># List of LLM-generated answers</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&#39;-&#39;</span><span class="token operator">*</span><span class="token number">20</span><span class="token punctuation">,</span> <span class="token string-interpolation"><span class="token string">f&quot;Question:\n</span><span class="token interpolation"><span class="token punctuation">{</span>q<span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">,</span> <span class="token string-interpolation"><span class="token string">f&quot;\nAnswer:\n</span><span class="token interpolation"><span class="token punctuation">{</span>answer<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">,</span> <span class="token string-interpolation"><span class="token string">f&quot;\nResponse:\n</span><span class="token interpolation"><span class="token punctuation">{</span>responses<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">,</span> <span class="token string-interpolation"><span class="token string">f&quot;\nExtracted:\n</span><span class="token interpolation"><span class="token punctuation">{</span>extracted_responses<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> <span class="token punctuation">[</span><span class="token number">2.0</span> <span class="token keyword">if</span> r <span class="token operator">==</span> a <span class="token keyword">else</span> <span class="token number">0.0</span> <span class="token keyword">for</span> r<span class="token punctuation">,</span> a <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>extracted_responses<span class="token punctuation">,</span> answer<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token comment"># Compare each LLM-generated answer with the standard answer</span>

<span class="token comment"># Reward if LLM-generated answer is a number</span>
<span class="token keyword">def</span> <span class="token function">int_reward_func</span><span class="token punctuation">(</span>completions<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">list</span><span class="token punctuation">[</span><span class="token builtin">float</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
    responses <span class="token operator">=</span> <span class="token punctuation">[</span>completion<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">&#39;content&#39;</span><span class="token punctuation">]</span> <span class="token keyword">for</span> completion <span class="token keyword">in</span> completions<span class="token punctuation">]</span>
    extracted_responses <span class="token operator">=</span> <span class="token punctuation">[</span>extract_xml_answer<span class="token punctuation">(</span>r<span class="token punctuation">)</span> <span class="token keyword">for</span> r <span class="token keyword">in</span> responses<span class="token punctuation">]</span>
    <span class="token keyword">return</span> <span class="token punctuation">[</span><span class="token number">0.5</span> <span class="token keyword">if</span> r<span class="token punctuation">.</span>isdigit<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token number">0.0</span> <span class="token keyword">for</span> r <span class="token keyword">in</span> extracted_responses<span class="token punctuation">]</span>

<span class="token comment"># Reward if LLM-generated result meets the format requirements of the system prompt (strict version)</span>
<span class="token keyword">def</span> <span class="token function">strict_format_reward_func</span><span class="token punctuation">(</span>completions<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">list</span><span class="token punctuation">[</span><span class="token builtin">float</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">&quot;&quot;&quot;Reward function that checks if the completion has a specific format.&quot;&quot;&quot;</span>
    pattern <span class="token operator">=</span> <span class="token string">r&quot;^&lt;reasoning&gt;\n.*?\n&lt;/reasoning&gt;\n&lt;answer&gt;\n.*?\n&lt;/answer&gt;\n$&quot;</span>
    responses <span class="token operator">=</span> <span class="token punctuation">[</span>completion<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">&quot;content&quot;</span><span class="token punctuation">]</span> <span class="token keyword">for</span> completion <span class="token keyword">in</span> completions<span class="token punctuation">]</span>
    matches <span class="token operator">=</span> <span class="token punctuation">[</span>re<span class="token punctuation">.</span><span class="token keyword">match</span><span class="token punctuation">(</span>pattern<span class="token punctuation">,</span> r<span class="token punctuation">)</span> <span class="token keyword">for</span> r <span class="token keyword">in</span> responses<span class="token punctuation">]</span>
    <span class="token keyword">return</span> <span class="token punctuation">[</span><span class="token number">0.5</span> <span class="token keyword">if</span> <span class="token keyword">match</span> <span class="token keyword">else</span> <span class="token number">0.0</span> <span class="token keyword">for</span> <span class="token keyword">match</span> <span class="token keyword">in</span> matches<span class="token punctuation">]</span>

<span class="token comment"># Reward if LLM-generated result meets the format requirements of the system prompt (lenient version)</span>
<span class="token keyword">def</span> <span class="token function">soft_format_reward_func</span><span class="token punctuation">(</span>completions<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">list</span><span class="token punctuation">[</span><span class="token builtin">float</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">&quot;&quot;&quot;Reward function that checks if the completion has a specific format.&quot;&quot;&quot;</span>
    pattern <span class="token operator">=</span> <span class="token string">r&quot;&lt;reasoning&gt;.*?&lt;/reasoning&gt;\s*&lt;answer&gt;.*?&lt;/answer&gt;&quot;</span>
    responses <span class="token operator">=</span> <span class="token punctuation">[</span>completion<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">&quot;content&quot;</span><span class="token punctuation">]</span> <span class="token keyword">for</span> completion <span class="token keyword">in</span> completions<span class="token punctuation">]</span>
    matches <span class="token operator">=</span> <span class="token punctuation">[</span>re<span class="token punctuation">.</span><span class="token keyword">match</span><span class="token punctuation">(</span>pattern<span class="token punctuation">,</span> r<span class="token punctuation">)</span> <span class="token keyword">for</span> r <span class="token keyword">in</span> responses<span class="token punctuation">]</span>
    <span class="token keyword">return</span> <span class="token punctuation">[</span><span class="token number">0.5</span> <span class="token keyword">if</span> <span class="token keyword">match</span> <span class="token keyword">else</span> <span class="token number">0.0</span> <span class="token keyword">for</span> <span class="token keyword">match</span> <span class="token keyword">in</span> matches<span class="token punctuation">]</span>

<span class="token comment"># Reward if LLM-generated result meets the format requirements of the system prompt (reward by point), and the shorter the content between &lt;answer&gt; and &lt;/answer&gt; tags, the higher the reward</span>
<span class="token keyword">def</span> <span class="token function">xmlcount_reward_func</span><span class="token punctuation">(</span>completions<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">list</span><span class="token punctuation">[</span><span class="token builtin">float</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
    contents <span class="token operator">=</span> <span class="token punctuation">[</span>completion<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">&quot;content&quot;</span><span class="token punctuation">]</span> <span class="token keyword">for</span> completion <span class="token keyword">in</span> completions<span class="token punctuation">]</span>
    <span class="token keyword">return</span> <span class="token punctuation">[</span>count_xml<span class="token punctuation">(</span>c<span class="token punctuation">)</span> <span class="token keyword">for</span> c <span class="token keyword">in</span> contents<span class="token punctuation">]</span>

<span class="token keyword">def</span> <span class="token function">count_xml</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">float</span><span class="token punctuation">:</span>
    count <span class="token operator">=</span> <span class="token number">0.0</span>
    <span class="token keyword">if</span> text<span class="token punctuation">.</span>count<span class="token punctuation">(</span><span class="token string">&quot;&lt;reasoning&gt;\n&quot;</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span>
        count <span class="token operator">+=</span> <span class="token number">0.125</span>
    <span class="token keyword">if</span> text<span class="token punctuation">.</span>count<span class="token punctuation">(</span><span class="token string">&quot;\n&lt;/reasoning&gt;\n&quot;</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span>
        count <span class="token operator">+=</span> <span class="token number">0.125</span>
    <span class="token keyword">if</span> text<span class="token punctuation">.</span>count<span class="token punctuation">(</span><span class="token string">&quot;\n&lt;answer&gt;\n&quot;</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span>
        count <span class="token operator">+=</span> <span class="token number">0.125</span>
        count <span class="token operator">-=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>text<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot;\n&lt;/answer&gt;\n&quot;</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">*</span><span class="token number">0.001</span>
    <span class="token keyword">if</span> text<span class="token punctuation">.</span>count<span class="token punctuation">(</span><span class="token string">&quot;\n&lt;/answer&gt;&quot;</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span>
        count <span class="token operator">+=</span> <span class="token number">0.125</span>
        count <span class="token operator">-=</span> <span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>text<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot;\n&lt;/answer&gt;&quot;</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">*</span><span class="token number">0.001</span>
    <span class="token keyword">return</span> count

<span class="token keyword">def</span> <span class="token function">extract_xml_answer</span><span class="token punctuation">(</span>text<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">str</span><span class="token punctuation">:</span>
    answer <span class="token operator">=</span> text<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot;&lt;answer&gt;&quot;</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>
    answer <span class="token operator">=</span> answer<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot;&lt;/answer&gt;&quot;</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    <span class="token keyword">return</span> answer<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_4-7-configure-grpo-parameters" tabindex="-1"><a class="header-anchor" href="#_4-7-configure-grpo-parameters" aria-hidden="true">#</a> 4.7. Configure GRPO Parameters</h3><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>max_prompt_length <span class="token operator">=</span> <span class="token number">256</span> <span class="token comment"># Maximum prompt length for model input</span>

<span class="token keyword">from</span> trl <span class="token keyword">import</span> GRPOConfig<span class="token punctuation">,</span> GRPOTrainer

training_args <span class="token operator">=</span> GRPOConfig<span class="token punctuation">(</span>
    learning_rate <span class="token operator">=</span> <span class="token number">5e-6</span><span class="token punctuation">,</span> <span class="token comment"># Learning rate, the step size for optimizer to adjust model parameters at each update</span>
    adam_beta1 <span class="token operator">=</span> <span class="token number">0.9</span><span class="token punctuation">,</span> <span class="token comment"># Beta parameter for Adam optimizer, used to control momentum calculation</span>
    adam_beta2 <span class="token operator">=</span> <span class="token number">0.99</span><span class="token punctuation">,</span> <span class="token comment"># Beta parameter for Adam optimizer, used to control momentum calculation</span>
    weight_decay <span class="token operator">=</span> <span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token comment"># Weight decay, used to prevent overfitting by reducing the size of weights at each update</span>
    warmup_ratio <span class="token operator">=</span> <span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token comment"># Learning rate warm-up ratio, indicating that the learning rate will gradually increase to the set learning rate at the beginning of training</span>
    lr_scheduler_type <span class="token operator">=</span> <span class="token string">&quot;cosine&quot;</span><span class="token punctuation">,</span> <span class="token comment"># Learning rate scheduler type, set to &quot;cosine,&quot; indicating that the learning rate will gradually decrease according to a cosine function</span>
    optim <span class="token operator">=</span> <span class="token string">&quot;paged_adamw_8bit&quot;</span><span class="token punctuation">,</span> <span class="token comment"># Optimizer, &quot;paged_adamw_8bit&quot; is a variant of the optimizer, possibly used to reduce memory usage</span>
    logging_steps <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token comment"># Set logging steps to 1, indicating that logs are recorded at every step</span>
    per_device_train_batch_size <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token comment"># Set the training batch size per device to 1</span>
    gradient_accumulation_steps <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token comment"># Gradient accumulation steps, can be increased to 4 for smoother training</span>
    num_generations <span class="token operator">=</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token comment"># Number of generations (can be reduced if OOM)</span>
    max_prompt_length <span class="token operator">=</span> max_prompt_length<span class="token punctuation">,</span>
    max_completion_length <span class="token operator">=</span> max_seq_length <span class="token operator">-</span> max_prompt_length<span class="token punctuation">,</span> <span class="token comment"># Maximum completion length, ensuring that the generated text does not exceed the model&#39;s maximum sequence length</span>
    <span class="token comment"># num_train_epochs = 1, # Set to 1 for a full training run</span>
    max_steps <span class="token operator">=</span> <span class="token number">250</span><span class="token punctuation">,</span> <span class="token comment"># Maximum training steps</span>
    save_steps <span class="token operator">=</span> <span class="token number">250</span><span class="token punctuation">,</span> <span class="token comment"># Steps to save the model, indicating that the model is saved every 250 steps</span>
    max_grad_norm <span class="token operator">=</span> <span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token comment"># Maximum gradient norm, used for gradient clipping to prevent gradient explosion</span>
    report_to <span class="token operator">=</span> <span class="token string">&quot;none&quot;</span><span class="token punctuation">,</span> <span class="token comment"># Can use Weights &amp; Biases</span>
    output_dir <span class="token operator">=</span> <span class="token string">&quot;outputs&quot;</span><span class="token punctuation">,</span> <span class="token comment"># Output directory for storing training results and model checkpoints</span>
<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_4-8-define-grpotrainer" tabindex="-1"><a class="header-anchor" href="#_4-8-define-grpotrainer" aria-hidden="true">#</a> 4.8. Define GRPOTrainer</h3><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>trainer <span class="token operator">=</span> GRPOTrainer<span class="token punctuation">(</span>
    model <span class="token operator">=</span> model<span class="token punctuation">,</span> <span class="token comment"># Base model</span>
    processing_class <span class="token operator">=</span> tokenizer<span class="token punctuation">,</span> <span class="token comment"># Embedding model</span>
    reward_funcs <span class="token operator">=</span> <span class="token punctuation">[</span> <span class="token comment"># Reward functions</span>
        xmlcount_reward_func<span class="token punctuation">,</span>
        soft_format_reward_func<span class="token punctuation">,</span>
        strict_format_reward_func<span class="token punctuation">,</span>
        int_reward_func<span class="token punctuation">,</span>
        correctness_reward_func<span class="token punctuation">,</span>
    <span class="token punctuation">]</span><span class="token punctuation">,</span>
    args <span class="token operator">=</span> training_args<span class="token punctuation">,</span> <span class="token comment"># Training parameters</span>
    train_dataset <span class="token operator">=</span> dataset<span class="token punctuation">,</span> <span class="token comment"># Dataset</span>
<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_4-9-start-grpo-training" tabindex="-1"><a class="header-anchor" href="#_4-9-start-grpo-training" aria-hidden="true">#</a> 4.9. Start GRPO Training</h3><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>trainer<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><figure><img src="/blog/assets/029_training-b8MDjICk.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h3 id="_4-10-save-lora-weights" tabindex="-1"><a class="header-anchor" href="#_4-10-save-lora-weights" aria-hidden="true">#</a> 4.10. Save LoRA Weights</h3><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>model<span class="token punctuation">.</span>save_lora<span class="token punctuation">(</span><span class="token string">&quot;grpo_saved_lora&quot;</span><span class="token punctuation">)</span> <span class="token comment"># Save LoRA weights to grpo_saved_lora file</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><h3 id="_4-11-inference-after-grpo-training" tabindex="-1"><a class="header-anchor" href="#_4-11-inference-after-grpo-training" aria-hidden="true">#</a> 4.11. Inference After GRPO Training</h3><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>text <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>apply_chat_template<span class="token punctuation">(</span><span class="token punctuation">[</span>
    <span class="token punctuation">{</span><span class="token string">&quot;role&quot;</span> <span class="token punctuation">:</span> <span class="token string">&quot;system&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;content&quot;</span> <span class="token punctuation">:</span> SYSTEM_PROMPT<span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token comment"># Difference from pre-training inference 1: Added system prompt</span>
    <span class="token punctuation">{</span><span class="token string">&quot;role&quot;</span> <span class="token punctuation">:</span> <span class="token string">&quot;user&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;content&quot;</span> <span class="token punctuation">:</span> <span class="token string">&quot;Calculate pi.&quot;</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
<span class="token punctuation">]</span><span class="token punctuation">,</span> tokenize <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">,</span> add_generation_prompt <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token keyword">from</span> vllm <span class="token keyword">import</span> SamplingParams
sampling_params <span class="token operator">=</span> SamplingParams<span class="token punctuation">(</span>
    temperature <span class="token operator">=</span> <span class="token number">0.8</span><span class="token punctuation">,</span>
    top_p <span class="token operator">=</span> <span class="token number">0.95</span><span class="token punctuation">,</span>
    max_tokens <span class="token operator">=</span> <span class="token number">1024</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>
output <span class="token operator">=</span> model<span class="token punctuation">.</span>fast_generate<span class="token punctuation">(</span>
    text<span class="token punctuation">,</span>
    sampling_params <span class="token operator">=</span> sampling_params<span class="token punctuation">,</span>
    lora_request <span class="token operator">=</span> model<span class="token punctuation">.</span>load_lora<span class="token punctuation">(</span><span class="token string">&quot;grpo_saved_lora&quot;</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token comment"># Difference from pre-training inference 2: Load LoRA weights</span>
<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>outputs<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>text

output
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="_5-references" tabindex="-1"><a class="header-anchor" href="#_5-references" aria-hidden="true">#</a> 5. References</h2><p>https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.1_(8B)-GRPO.ipynb</p><p>https://www.kaggle.com/code/kingabzpro/fine-tuning-deepseek-r1-reasoning-model</p><p>https://colab.research.google.com/github/wandb/examples/blob/master/colabs/intro/Intro_to_Weights_%26_Biases.ipynb</p><p>https://www.51cto.com/aigc/4216.html</p><p>https://unsloth.ai/blog/grpo</p><p><a href="https://blog.csdn.net/simoncool23/article/details/145400144" target="_blank" rel="noopener noreferrer">What is the GRPO technology behind the popular Deepseek<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><p><a href="https://www.cnblogs.com/theseventhson/p/18696408" target="_blank" rel="noopener noreferrer">LLM Large Model: Shallow Analysis of Deepseek (Part 2): The Principle of R1&#39;s GRPO<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p></div><!--[--><!----><!--]--><footer class="page-meta"><!----><div class="meta-item git-info"><!----><!----></div></footer><nav class="vp-page-nav"><a aria-label="Lightweight Visualization Tool for Deep Learning: wandb" class="vp-link nav-link prev nav-link prev" href="/blog/posts/llm/030_wandb.html"><div class="hint"><span class="arrow start"></span>Prev</div><div class="link"><span class="font-icon icon fa-fw fa-sm fas fa-lightbulb" style=""></span>Lightweight Visualization Tool for Deep Learning: wandb</div></a><a aria-label="Distributed Training Part 5: Introduction to GPU" class="vp-link nav-link next nav-link next" href="/blog/posts/llm/028_distribution_and_parallelism_4.html"><div class="hint">Next<span class="arrow end"></span></div><div class="link">Distributed Training Part 5: Introduction to GPU<span class="font-icon icon fa-fw fa-sm fas fa-lightbulb" style=""></span></div></a></nav><!----><!--[--><!----><!--]--><!--]--></main><!--]--><!----></div><!--]--><!--]--><!----><!--]--></div>
    <script type="module" src="/blog/assets/app-nSXwnGLr.js" defer></script>
  </body>
</html>
