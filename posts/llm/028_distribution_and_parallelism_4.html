<!doctype html>
<html lang="en-US" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.0" />
    <meta name="theme" content="VuePress Theme Hope 2.0.0-rc.13" />
    <style>
      html {
        background: var(--bg-color, #fff);
      }

      html[data-theme="dark"] {
        background: var(--bg-color, #1d1e1f);
      }

      body {
        background: var(--bg-color);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <link rel="alternate" hreflang="zh-cn" href="https://liz-in-tech.github.io/blog/zh/posts/llm/028_distribution_and_parallelism_4.html"><meta property="og:url" content="https://liz-in-tech.github.io/blog/posts/llm/028_distribution_and_parallelism_4.html"><meta property="og:site_name" content="Liz"><meta property="og:title" content="Distributed Training Part 5: Introduction to GPU"><meta property="og:description" content="Distributed Training Part 5: Introduction to GPU"><meta property="og:type" content="article"><meta property="og:locale" content="en-US"><meta property="og:locale:alternate" content="zh-CN"><meta property="og:updated_time" content="2025-03-08T14:32:06.000Z"><meta property="article:author" content="Liz"><meta property="article:tag" content="Distributed"><meta property="article:tag" content="Parallelism"><meta property="article:published_time" content="2025-03-06T00:00:00.000Z"><meta property="article:modified_time" content="2025-03-08T14:32:06.000Z"><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"Distributed Training Part 5: Introduction to GPU","image":[""],"datePublished":"2025-03-06T00:00:00.000Z","dateModified":"2025-03-08T14:32:06.000Z","author":[{"@type":"Person","name":"Liz","url":"https://github.com/liz-in-tech"}]}</script><link rel="icon" herf="/blogger.png"><link rel="icon" href="/blog/blogger.png"><title>Distributed Training Part 5: Introduction to GPU | Liz</title><meta name="description" content="Distributed Training Part 5: Introduction to GPU">
    <link rel="preload" href="/blog/assets/style-m_obra2h.css" as="style"><link rel="stylesheet" href="/blog/assets/style-m_obra2h.css">
    <link rel="modulepreload" href="/blog/assets/app-jv-bB2tz.js"><link rel="modulepreload" href="/blog/assets/028_distribution_and_parallelism_4.html-4GIWJVgM.js"><link rel="modulepreload" href="/blog/assets/028_after_flash_attention-tADJ-9m9.js"><link rel="modulepreload" href="/blog/assets/plugin-vue_export-helper-x3n3nnut.js"><link rel="modulepreload" href="/blog/assets/028_distribution_and_parallelism_4.html-Kub1JEXd.js">
    <link rel="prefetch" href="/blog/assets/index.html-YbPtte5_.js" as="script"><link rel="prefetch" href="/blog/assets/intro.html-CGfhr1vY.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-FUMOuem4.js" as="script"><link rel="prefetch" href="/blog/assets/index.html--TTjrkIy.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-g4Nfr7z1.js" as="script"><link rel="prefetch" href="/blog/assets/intro.html-bitGHKd2.js" as="script"><link rel="prefetch" href="/blog/assets/001_langchain.html-nrisQopy.js" as="script"><link rel="prefetch" href="/blog/assets/002_langchain_sourcecode.html-9XtwFAwc.js" as="script"><link rel="prefetch" href="/blog/assets/003_streamlit.html-oji9upQP.js" as="script"><link rel="prefetch" href="/blog/assets/004_transformer.html-xrin91s2.js" as="script"><link rel="prefetch" href="/blog/assets/005_llama.html-RcwJewgQ.js" as="script"><link rel="prefetch" href="/blog/assets/006_llm_leaderboard.html-c628DmZb.js" as="script"><link rel="prefetch" href="/blog/assets/007_computer_use.html-4RcS3hxb.js" as="script"><link rel="prefetch" href="/blog/assets/008_rag_challenge.html-_8stdYVV.js" as="script"><link rel="prefetch" href="/blog/assets/009_llm_challenge.html-eluz3bTT.js" as="script"><link rel="prefetch" href="/blog/assets/010_rag_workflow.html-Ft0RQWf3.js" as="script"><link rel="prefetch" href="/blog/assets/011_vector_database.html-htZNHy9b.js" as="script"><link rel="prefetch" href="/blog/assets/012_prompt_engineering.html-Q27DlfZz.js" as="script"><link rel="prefetch" href="/blog/assets/013_optimizing_llm.html-6CxOIR84.js" as="script"><link rel="prefetch" href="/blog/assets/014_rag_evaluation.html-GIu-oGwK.js" as="script"><link rel="prefetch" href="/blog/assets/015_fine_tune.html-Gj-zyjT6.js" as="script"><link rel="prefetch" href="/blog/assets/016_multimodal.html-xa8M4Wu4.js" as="script"><link rel="prefetch" href="/blog/assets/017_agent_and_multiagent.html-dm178NRn.js" as="script"><link rel="prefetch" href="/blog/assets/018_huggingface.html-WI0c55vB.js" as="script"><link rel="prefetch" href="/blog/assets/019_ollama.html-kLkdC4dl.js" as="script"><link rel="prefetch" href="/blog/assets/020_neo4j.html-P-Llr3CJ.js" as="script"><link rel="prefetch" href="/blog/assets/021_microsoft_graphrag.html-0d0frUhq.js" as="script"><link rel="prefetch" href="/blog/assets/022_llamaindex_graphrag.html-RhkTd_Zr.js" as="script"><link rel="prefetch" href="/blog/assets/023_agent_framework.html-5MCDM_Sd.js" as="script"><link rel="prefetch" href="/blog/assets/024_distribution_and_parallelism.html-01hi9eD-.js" as="script"><link rel="prefetch" href="/blog/assets/025_distribution_and_parallelism_1.html-32IzAErP.js" as="script"><link rel="prefetch" href="/blog/assets/026_distribution_and_parallelism_2.html-rsWgIQO4.js" as="script"><link rel="prefetch" href="/blog/assets/027_distribution_and_parallelism_3.html-aP_ykF_V.js" as="script"><link rel="prefetch" href="/blog/assets/029_unsloth_grpo.html-zgQtWVj-.js" as="script"><link rel="prefetch" href="/blog/assets/030_wandb.html-61V6KLeo.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ZDCSnlc1.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ZYw6WxxA.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-OavE9BET.js" as="script"><link rel="prefetch" href="/blog/assets/001_langchain.html-hE_T0u_5.js" as="script"><link rel="prefetch" href="/blog/assets/002_langchain_sourcecode.html-iH0mq6XB.js" as="script"><link rel="prefetch" href="/blog/assets/003_streamlit.html-WyFhRqF6.js" as="script"><link rel="prefetch" href="/blog/assets/004_transformer.html-wy9Toayl.js" as="script"><link rel="prefetch" href="/blog/assets/005_llama.html-Igb8VTzY.js" as="script"><link rel="prefetch" href="/blog/assets/006_llm_leaderboard.html-WHPR-17-.js" as="script"><link rel="prefetch" href="/blog/assets/007_computer_use.html-hz6Q-DAA.js" as="script"><link rel="prefetch" href="/blog/assets/008_rag_challenge.html-3KMCwhrh.js" as="script"><link rel="prefetch" href="/blog/assets/009_llm_challenge.html-7gxKMp_3.js" as="script"><link rel="prefetch" href="/blog/assets/010_rag_workflow.html-KndRvZAj.js" as="script"><link rel="prefetch" href="/blog/assets/011_vector_database.html-DtFi92ig.js" as="script"><link rel="prefetch" href="/blog/assets/012_prompt_engineering.html-ZdCqy2Fu.js" as="script"><link rel="prefetch" href="/blog/assets/013_optimizing_llm.html-W-CdR_ck.js" as="script"><link rel="prefetch" href="/blog/assets/014_rag_evaluation.html-mimwqA-t.js" as="script"><link rel="prefetch" href="/blog/assets/015_fine_tune.html--JjBpVvQ.js" as="script"><link rel="prefetch" href="/blog/assets/016_multimodal.html-hiqs-a6X.js" as="script"><link rel="prefetch" href="/blog/assets/017_agent_and_multiagent.html-bS1SRdf4.js" as="script"><link rel="prefetch" href="/blog/assets/018_huggingface.html-Si3T7PB7.js" as="script"><link rel="prefetch" href="/blog/assets/019_ollama.html-V5tcXCC4.js" as="script"><link rel="prefetch" href="/blog/assets/020_neo4j.html-ytaIU5xV.js" as="script"><link rel="prefetch" href="/blog/assets/021_microsoft_graphrag.html-kvlLpO3f.js" as="script"><link rel="prefetch" href="/blog/assets/022_llamaindex_graphrag.html-nS8_ZZy5.js" as="script"><link rel="prefetch" href="/blog/assets/023_agent_framework.html-VZsN2kO8.js" as="script"><link rel="prefetch" href="/blog/assets/024_distribution_and_parallelism.html-oCd9cE9Q.js" as="script"><link rel="prefetch" href="/blog/assets/025_distribution_and_parallelism_1.html-ZR9kuXUl.js" as="script"><link rel="prefetch" href="/blog/assets/026_distribution_and_parallelism_2.html-lTYQr6p_.js" as="script"><link rel="prefetch" href="/blog/assets/027_distribution_and_parallelism_3.html-j2B_wJ9U.js" as="script"><link rel="prefetch" href="/blog/assets/028_distribution_and_parallelism_4.html-38Gbieji.js" as="script"><link rel="prefetch" href="/blog/assets/029_unsloth_grpo.html-MLBLxBKQ.js" as="script"><link rel="prefetch" href="/blog/assets/030_wandb.html-VCoqJJSk.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-wh_dBtOR.js" as="script"><link rel="prefetch" href="/blog/assets/404.html-cxLWDy2T.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-kf4JCRaf.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-RkA-insV.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-4kI_oqSd.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-WhuidxNt.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-OqGkeUA_.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-5GeN-sdD.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-c4Rf4yh1.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-2r0jUs7o.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-BSKRXRQc.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-KjTsJ0Hg.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-TteIwMx3.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-g00XXzrL.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-YxbJgo4L.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-3T79Cy0i.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-A5tlQHan.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-04ff5e0O.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-vgZ6rfFh.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-OmipPplE.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-E1KrJL6a.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-oPH9QkTj.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-cHRqZSs8.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-74SU9ZTn.js" as="script"><link rel="prefetch" href="/blog/assets/index.html--iJiA8oX.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-oZPWb_Fc.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-FUIWSLsp.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-5ERWyusD.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Zjn0JNqd.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-jcvPTrgB.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-9t2TsyuQ.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-CcLVFNIv.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-DVoYOOaL.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-V52ipvRm.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-9If_KW0o.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-df9Mrf2R.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-f9bWoKcO.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-GYH0QUoo.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-JVTfeijx.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-_C1QVNqX.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-L_IXFmna.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-nZWHmXY7.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-x4gPgqE4.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-bWnVyuyA.js" as="script"><link rel="prefetch" href="/blog/assets/index.html--yTU23ka.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-tRnpyzfw.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-7aypos-L.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-1BXcbV1R.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-pu478WKz.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-LHukpLS7.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-howjHe2f.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-DeN_iOWx.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-cnlzR0a7.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-0P_c_pcU.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-dy_CcFmq.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-FzFytZ_p.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-2KSwV7xp.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-F1coElwg.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ffflqCb9.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-F8ZuLYgH.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-HeYWaFeL.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-xKYeJEc5.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-xB-iS7Ql.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-OEUPqfTV.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-EE4iQI9m.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-g1PUF_BG.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-nUBcs85a.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-9Y3la5Sf.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-wufIFDPM.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-bXZQIxRE.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-wd6ZkEHi.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Xlk0AXmC.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Uv7c7pYa.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-FfZqC9tZ.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-mSPhZxqB.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-51HoKD5A.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Q5_K6Vux.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-jkWPo860.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-kTEqch5G.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-y4iBqBqc.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ibHhI9SI.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-3hk_s27_.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-QJ9j3Zl2.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-QvWFHL99.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Pefl6i_g.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-B-z9qR27.js" as="script"><link rel="prefetch" href="/blog/assets/intro.html-o0JAcO4i.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-xyy_bEHA.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Le2uxnM3.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-wWqHzeJg.js" as="script"><link rel="prefetch" href="/blog/assets/intro.html-7cKwIc7T.js" as="script"><link rel="prefetch" href="/blog/assets/001_langchain.html-jfiuwOB1.js" as="script"><link rel="prefetch" href="/blog/assets/002_langchain_sourcecode.html-V9fspq1B.js" as="script"><link rel="prefetch" href="/blog/assets/003_streamlit.html-MA7SOktw.js" as="script"><link rel="prefetch" href="/blog/assets/004_transformer.html-XUcLATjE.js" as="script"><link rel="prefetch" href="/blog/assets/005_llama.html-QdZkGO4w.js" as="script"><link rel="prefetch" href="/blog/assets/006_llm_leaderboard.html-ULK7grvc.js" as="script"><link rel="prefetch" href="/blog/assets/007_computer_use.html-WZl8c0rE.js" as="script"><link rel="prefetch" href="/blog/assets/008_rag_challenge.html-D4hfurz0.js" as="script"><link rel="prefetch" href="/blog/assets/009_llm_challenge.html-dlDjD43g.js" as="script"><link rel="prefetch" href="/blog/assets/010_rag_workflow.html-qQibcSJ2.js" as="script"><link rel="prefetch" href="/blog/assets/011_vector_database.html-xkPuFru-.js" as="script"><link rel="prefetch" href="/blog/assets/012_prompt_engineering.html-0nDAxXB_.js" as="script"><link rel="prefetch" href="/blog/assets/013_optimizing_llm.html-VyepyXDg.js" as="script"><link rel="prefetch" href="/blog/assets/014_rag_evaluation.html-0r5rynof.js" as="script"><link rel="prefetch" href="/blog/assets/015_fine_tune.html-p3mqYAcL.js" as="script"><link rel="prefetch" href="/blog/assets/016_multimodal.html-jUfmdRi8.js" as="script"><link rel="prefetch" href="/blog/assets/017_agent_and_multiagent.html-YCit9PHd.js" as="script"><link rel="prefetch" href="/blog/assets/018_huggingface.html-NWjIVJnv.js" as="script"><link rel="prefetch" href="/blog/assets/019_ollama.html-Am0nvh0y.js" as="script"><link rel="prefetch" href="/blog/assets/020_neo4j.html-mXI94B5p.js" as="script"><link rel="prefetch" href="/blog/assets/021_microsoft_graphrag.html-0Eg0Yq4X.js" as="script"><link rel="prefetch" href="/blog/assets/022_llamaindex_graphrag.html-S0hoggQA.js" as="script"><link rel="prefetch" href="/blog/assets/023_agent_framework.html-PFHi6wUl.js" as="script"><link rel="prefetch" href="/blog/assets/024_distribution_and_parallelism.html-p_Y8ABRT.js" as="script"><link rel="prefetch" href="/blog/assets/025_distribution_and_parallelism_1.html-sV3Wj9Fh.js" as="script"><link rel="prefetch" href="/blog/assets/026_distribution_and_parallelism_2.html-Lqo1Nq6W.js" as="script"><link rel="prefetch" href="/blog/assets/027_distribution_and_parallelism_3.html-2g1792kQ.js" as="script"><link rel="prefetch" href="/blog/assets/029_unsloth_grpo.html-azotUUKO.js" as="script"><link rel="prefetch" href="/blog/assets/030_wandb.html-MVtaF7tV.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-8cEM1J38.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-uXaaeKBn.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-XDUlMB34.js" as="script"><link rel="prefetch" href="/blog/assets/001_langchain.html-j9JxR3Oy.js" as="script"><link rel="prefetch" href="/blog/assets/002_langchain_sourcecode.html-AxbTMP6k.js" as="script"><link rel="prefetch" href="/blog/assets/003_streamlit.html-czonciLU.js" as="script"><link rel="prefetch" href="/blog/assets/004_transformer.html-E72R3X2K.js" as="script"><link rel="prefetch" href="/blog/assets/005_llama.html-8BEWStH9.js" as="script"><link rel="prefetch" href="/blog/assets/006_llm_leaderboard.html-hVTMrUoS.js" as="script"><link rel="prefetch" href="/blog/assets/007_computer_use.html-vdVpmjIq.js" as="script"><link rel="prefetch" href="/blog/assets/008_rag_challenge.html-o-9JeXdO.js" as="script"><link rel="prefetch" href="/blog/assets/009_llm_challenge.html-YFOTD98T.js" as="script"><link rel="prefetch" href="/blog/assets/010_rag_workflow.html-GnYssTGf.js" as="script"><link rel="prefetch" href="/blog/assets/011_vector_database.html-kbiWLdfK.js" as="script"><link rel="prefetch" href="/blog/assets/012_prompt_engineering.html-Of4gb3SE.js" as="script"><link rel="prefetch" href="/blog/assets/013_optimizing_llm.html-jawa_ZaB.js" as="script"><link rel="prefetch" href="/blog/assets/014_rag_evaluation.html-rYvHdqJD.js" as="script"><link rel="prefetch" href="/blog/assets/015_fine_tune.html-4yz8JP8t.js" as="script"><link rel="prefetch" href="/blog/assets/016_multimodal.html-gFYKnJky.js" as="script"><link rel="prefetch" href="/blog/assets/017_agent_and_multiagent.html-ZaTlUYBL.js" as="script"><link rel="prefetch" href="/blog/assets/018_huggingface.html-DJVxSz-z.js" as="script"><link rel="prefetch" href="/blog/assets/019_ollama.html-7k6VZ-zx.js" as="script"><link rel="prefetch" href="/blog/assets/020_neo4j.html-ww_8v2Es.js" as="script"><link rel="prefetch" href="/blog/assets/021_microsoft_graphrag.html-zLtGOKKT.js" as="script"><link rel="prefetch" href="/blog/assets/022_llamaindex_graphrag.html-mPOy83tx.js" as="script"><link rel="prefetch" href="/blog/assets/023_agent_framework.html-HSebBxRT.js" as="script"><link rel="prefetch" href="/blog/assets/024_distribution_and_parallelism.html-W9pn3qPl.js" as="script"><link rel="prefetch" href="/blog/assets/025_distribution_and_parallelism_1.html-d_fxH1Jt.js" as="script"><link rel="prefetch" href="/blog/assets/026_distribution_and_parallelism_2.html-CI5ZCYyS.js" as="script"><link rel="prefetch" href="/blog/assets/027_distribution_and_parallelism_3.html-Fqrpy2FW.js" as="script"><link rel="prefetch" href="/blog/assets/028_distribution_and_parallelism_4.html-8APAil6S.js" as="script"><link rel="prefetch" href="/blog/assets/029_unsloth_grpo.html-CgOHas1M.js" as="script"><link rel="prefetch" href="/blog/assets/030_wandb.html-oomJYhEE.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-DlzVjJGD.js" as="script"><link rel="prefetch" href="/blog/assets/404.html-NOfzvidA.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-0ME1fFlo.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-H1wzXPfj.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-jDzlk0I4.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-RoRn8O4Q.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-4uIsd6xo.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-pt6g35c_.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-OFPBGLLG.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-DGUih0Xl.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-FkSB7y5C.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-exU2lLA1.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-vPNxik-b.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-JwKNwsKk.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-c6rhkU2H.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-lCyTfGd1.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ho22RS3R.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-7_OA9dB0.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-5eoR_AZS.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-cf0HF2DD.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-9axtHcYM.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-eH7y9GLA.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-UqAyd13L.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-GoB9tBYH.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-s7hVzQ9C.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-39M-xrXe.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-3x0398M8.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-to7GvZop.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-8cCJqyJ0.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-7oUd6rJL.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-yKlfYe9C.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ymJyrb2j.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-p3-XmYOf.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-BknHMbWy.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-TLcIRZqu.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-uiYP-VW2.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-TAoyM3ij.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-_LteAkkC.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-CYo3gfe4.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-DUnIGgOA.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Oxeyg2o7.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-wHFe4o6n.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-eYHOxLO-.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-38r1WHMP.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-9F8YDmux.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-CxEciGbg.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-g0zuAeZ_.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-xwZYouaJ.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-vTsgxL-5.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-oi8Kzm0y.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-aKAy8fSS.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Wiv2YoGk.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-VJ0HWpj9.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-dGTLCPHH.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-mk09a0Ye.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-XPMcvNDq.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-9LnXixFF.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-nfAZ38bU.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-mPUqixjW.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-yBEDtJzg.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-6gvUhmpY.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-f6C6Q8gh.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-xJ5CjIKf.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-1iuPFAOo.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-CSN1EBg6.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-9Ko4qVdT.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-oGNxIRtr.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-zLU1XkxV.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-qgefNsXL.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-9d1lmiQH.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-4_9SZBZK.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-mcLoIlBk.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-brdikAT4.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ixse3aqJ.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Nhkz8p3D.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-L-4ffam5.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-TXmROFM7.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-U61OjI9L.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-YYLIrTFe.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-FjbkEJA6.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-jr78Xcfs.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-oGYSa8G4.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-dbJ0Irmo.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-S45zWgfc.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-HV2FGU_v.js" as="script"><link rel="prefetch" href="/blog/assets/photoswipe.esm-08_zHRDQ.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">Skip to main content</a><!--]--><!--[--><div class="theme-container no-sidebar has-toc"><!--[--><header id="navbar" class="vp-navbar"><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!--[--><!----><!--]--><!--[--><a class="vp-link vp-brand vp-brand" href="/blog/"><img class="vp-nav-logo" src="/blog/blogger.png" alt><!----><span class="vp-site-name hide-in-pad">Liz</span></a><!--]--><!--[--><!----><!--]--></div><div class="vp-navbar-center"><!--[--><!----><!--]--><!--[--><nav class="vp-nav-links"><div class="nav-item hide-in-mobile"><a aria-label="Home" class="vp-link nav-link nav-link" href="/blog/"><span class="font-icon icon fa-fw fa-sm fas fa-home" style=""></span>Home<!----></a></div><div class="nav-item hide-in-mobile"><a aria-label="Project" class="vp-link nav-link nav-link" href="/blog/demo/"><span class="font-icon icon fa-fw fa-sm fas fa-star" style=""></span>Project<!----></a></div></nav><!--]--><!--[--><!----><!--]--></div><div class="vp-navbar-end"><!--[--><!----><!--]--><!--[--><div class="nav-item"><div class="dropdown-wrapper i18n-dropdown"><button type="button" class="dropdown-title" aria-label="Select language"><!--[--><svg xmlns="http://www.w3.org/2000/svg" class="icon i18n-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="i18n icon" style="width:1rem;height:1rem;vertical-align:middle;"><path d="M379.392 460.8 494.08 575.488l-42.496 102.4L307.2 532.48 138.24 701.44l-71.68-72.704L234.496 460.8l-45.056-45.056c-27.136-27.136-51.2-66.56-66.56-108.544h112.64c7.68 14.336 16.896 27.136 26.112 35.84l45.568 46.08 45.056-45.056C382.976 312.32 409.6 247.808 409.6 204.8H0V102.4h256V0h102.4v102.4h256v102.4H512c0 70.144-37.888 161.28-87.04 210.944L378.88 460.8zM576 870.4 512 1024H409.6l256-614.4H768l256 614.4H921.6l-64-153.6H576zM618.496 768h196.608L716.8 532.48 618.496 768z"></path></svg><!--]--><span class="arrow"></span><ul class="nav-dropdown"><li class="dropdown-item"><a aria-label="English" class="vp-link nav-link active nav-link active" href="/blog/posts/llm/028_distribution_and_parallelism_4.html"><!---->English<!----></a></li><li class="dropdown-item"><a aria-label="简体中文" class="vp-link nav-link nav-link" href="/blog/zh/posts/llm/028_distribution_and_parallelism_4.html"><!---->简体中文<!----></a></li></ul></button></div></div><div class="nav-item vp-repo"><a class="vp-repo-link" href="https://github.com/liz-in-tech" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><div class="nav-item hide-in-mobile"><button type="button" id="appearance-switch"><svg xmlns="http://www.w3.org/2000/svg" class="icon auto-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="auto icon" style="display:block;"><path d="M512 992C246.92 992 32 777.08 32 512S246.92 32 512 32s480 214.92 480 480-214.92 480-480 480zm0-840c-198.78 0-360 161.22-360 360 0 198.84 161.22 360 360 360s360-161.16 360-360c0-198.78-161.22-360-360-360zm0 660V212c165.72 0 300 134.34 300 300 0 165.72-134.28 300-300 300z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon dark-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="dark icon" style="display:none;"><path d="M524.8 938.667h-4.267a439.893 439.893 0 0 1-313.173-134.4 446.293 446.293 0 0 1-11.093-597.334A432.213 432.213 0 0 1 366.933 90.027a42.667 42.667 0 0 1 45.227 9.386 42.667 42.667 0 0 1 10.24 42.667 358.4 358.4 0 0 0 82.773 375.893 361.387 361.387 0 0 0 376.747 82.774 42.667 42.667 0 0 1 54.187 55.04 433.493 433.493 0 0 1-99.84 154.88 438.613 438.613 0 0 1-311.467 128z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon light-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="light icon" style="display:none;"><path d="M952 552h-80a40 40 0 0 1 0-80h80a40 40 0 0 1 0 80zM801.88 280.08a41 41 0 0 1-57.96-57.96l57.96-58a41.04 41.04 0 0 1 58 58l-58 57.96zM512 752a240 240 0 1 1 0-480 240 240 0 0 1 0 480zm0-560a40 40 0 0 1-40-40V72a40 40 0 0 1 80 0v80a40 40 0 0 1-40 40zm-289.88 88.08-58-57.96a41.04 41.04 0 0 1 58-58l57.96 58a41 41 0 0 1-57.96 57.96zM192 512a40 40 0 0 1-40 40H72a40 40 0 0 1 0-80h80a40 40 0 0 1 40 40zm30.12 231.92a41 41 0 0 1 57.96 57.96l-57.96 58a41.04 41.04 0 0 1-58-58l58-57.96zM512 832a40 40 0 0 1 40 40v80a40 40 0 0 1-80 0v-80a40 40 0 0 1 40-40zm289.88-88.08 58 57.96a41.04 41.04 0 0 1-58 58l-57.96-58a41 41 0 0 1 57.96-57.96z"></path></svg></button></div><form class="search-box" role="search"><input type="search" autocomplete="off" spellcheck="false" value><!----></form><!--]--><!--[--><!----><!--]--><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar"><!--[--><!----><!--]--><ul class="vp-sidebar-links"></ul><!--[--><!----><!--]--></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!--[--><!----><!--]--><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><span class="font-icon icon fa-fw fa-sm fas fa-lightbulb" style=""></span>Distributed Training Part 5: Introduction to GPU</h1><div class="page-info"><span class="page-author-info" aria-label="Author🖊" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><a class="page-author-item" href="https://github.com/liz-in-tech" target="_blank" rel="noopener noreferrer">Liz</a></span><span property="author" content="Liz"></span></span><!----><span class="page-date-info" aria-label="Writing Date📅" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span><!----></span><meta property="datePublished" content="2025-03-06T00:00:00.000Z"></span><!----><span class="page-reading-time-info" aria-label="Reading Time⌛" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>About 6 min</span><meta property="timeRequired" content="PT6M"></span><span class="page-category-info" aria-label="Category🌈" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon category-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="category icon"><path d="M148.41 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H148.41c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.311-40.31zM147.556 553.478H429.73c22.263 0 40.311 18.048 40.311 40.31v282.176c0 22.263-18.048 40.312-40.31 40.312H147.555c-22.263 0-40.311-18.049-40.311-40.312V593.79c0-22.263 18.048-40.311 40.31-40.311zM593.927 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H593.927c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.31-40.31zM730.22 920.502H623.926c-40.925 0-74.22-33.388-74.22-74.425V623.992c0-41.038 33.387-74.424 74.425-74.424h222.085c41.038 0 74.424 33.226 74.424 74.067v114.233c0 10.244-8.304 18.548-18.547 18.548s-18.548-8.304-18.548-18.548V623.635c0-20.388-16.746-36.974-37.33-36.974H624.13c-20.585 0-37.331 16.747-37.331 37.33v222.086c0 20.585 16.654 37.331 37.126 37.331H730.22c10.243 0 18.547 8.304 18.547 18.547 0 10.244-8.304 18.547-18.547 18.547z"></path></svg><!--[--><span class="page-category-item category6 clickable" role="navigation">LLM</span><!--]--><meta property="articleSection" content="LLM"></span><span class="page-tag-info" aria-label="Tag🏷" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon tag-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="tag icon"><path d="M939.902 458.563L910.17 144.567c-1.507-16.272-14.465-29.13-30.737-30.737L565.438 84.098h-.402c-3.215 0-5.726 1.005-7.634 2.913l-470.39 470.39a10.004 10.004 0 000 14.164l365.423 365.424c1.909 1.908 4.42 2.913 7.132 2.913s5.223-1.005 7.132-2.913l470.39-470.39c2.01-2.11 3.014-5.023 2.813-8.036zm-240.067-72.121c-35.458 0-64.286-28.828-64.286-64.286s28.828-64.285 64.286-64.285 64.286 28.828 64.286 64.285-28.829 64.286-64.286 64.286z"></path></svg><!--[--><span class="page-tag-item tag3 clickable" role="navigation">Distributed</span><span class="page-tag-item tag0 clickable" role="navigation">Parallelism</span><!--]--><meta property="keywords" content="Distributed,Parallelism"></span></div><hr></div><div class="toc-place-holder"><aside id="toc"><!--[--><!----><!--]--><div class="toc-header">On This Page<button type="button" class="print-button" title="Print"><svg xmlns="http://www.w3.org/2000/svg" class="icon print-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="print icon"><path d="M819.2 364.8h-44.8V128c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v236.8h-44.8C145.067 364.8 96 413.867 96 473.6v192c0 59.733 49.067 108.8 108.8 108.8h44.8V896c0 17.067 14.933 32 32 32h460.8c17.067 0 32-14.933 32-32V774.4h44.8c59.733 0 108.8-49.067 108.8-108.8v-192c0-59.733-49.067-108.8-108.8-108.8zM313.6 160h396.8v204.8H313.6V160zm396.8 704H313.6V620.8h396.8V864zM864 665.6c0 25.6-19.2 44.8-44.8 44.8h-44.8V588.8c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v121.6h-44.8c-25.6 0-44.8-19.2-44.8-44.8v-192c0-25.6 19.2-44.8 44.8-44.8h614.4c25.6 0 44.8 19.2 44.8 44.8v192z"></path></svg></button></div><div class="toc-wrapper"><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_1-gpu-architecture">1. GPU Architecture</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_2-how-to-improve-performance-with-kernels">2. How to Improve Performance with Kernels</a></li><li><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_2-1-tools-for-writing-kernel-code">2.1. Tools for Writing Kernel Code</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_2-2-torch-compile-decorator">2.2. torch.compile Decorator</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_2-3-implementing-triton-kernels">2.3. Implementing Triton Kernels</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_2-4-implementing-cuda-kernels">2.4. Implementing CUDA Kernels</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_3-fused-kernels">3. Fused Kernels</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_4-flash-attention">4. Flash Attention</a></li><li><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_4-1-before-optimization">4.1. Before Optimization</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_4-2-flash-attention-optimization">4.2. Flash Attention Optimization</a></li><!----><!--]--></ul></li><!--]--></ul><div class="toc-marker" style="top:-1.7rem;"></div></div><!--[--><!----><!--]--></aside></div><!--[--><!----><!--]--><div class="theme-hope-content"><h1 id="distributed-training-part-5-introduction-to-gpu" tabindex="-1"><a class="header-anchor" href="#distributed-training-part-5-introduction-to-gpu" aria-hidden="true">#</a> Distributed Training Part 5: Introduction to GPU</h1><!-- more --><h2 id="_1-gpu-architecture" tabindex="-1"><a class="header-anchor" href="#_1-gpu-architecture" aria-hidden="true">#</a> 1. GPU Architecture</h2><p>In terms of computation, it has a highly hierarchical structure</p><ul><li>A GPU consists of a set of computational units called Streaming Multiprocessors (SMs).</li><li>Each SM contains and controls a set of streaming processors, also known as cores. For example, the Nvidia H100 GPU has 132 SMs, each with 128 cores, totaling 16,896 cores.</li><li>Each core can handle multiple threads simultaneously.</li></ul><figure><img src="/blog/assets/028_gpu_architecture-Z2tU00bx.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>In terms of memory, it also has a highly hierarchical structure, including multiple layers of cache and memory</p><ul><li>Registers are the smallest units, private to threads during execution</li><li>Shared Memory and L1 cache are shared by threads running on a single SM</li><li>A higher level is the L2 cache shared by all SMs</li><li>Finally, there is global memory, which is the largest memory on the GPU (e.g., the H100 boasts 80 GB), but it is also the slowest to access and query</li></ul><figure><img src="/blog/assets/028_gpu_memory_and_cache-NiNT2E4Z.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>The goal of a GPU is to leverage this hierarchical organization of computation/memory to run as many workloads as possible in parallel on the GPU cores.</p><p>A piece of code running on GPU cores is called a kernel. It can be written in high-level languages in CUDA or Triton and then compiled into PTX (Parallel Thread Execution), the low-level assembly language used by NVIDIA GPUs.</p><p>To run a kernel, a specific piece of code called host code is also needed, which executes on the CPU/host and is responsible for preparing data allocation and loading data and code.</p><p>The scheduling of a kernel typically follows:</p><ul><li>Threads are grouped into warps of size 32. All threads in a warp execute instructions synchronously but process different parts of the data.</li><li>Warps are grouped into larger and more flexible blocks (e.g., size 256), each block still assigned to a single SM. An SM can run multiple blocks in parallel, but depending on resource availability, not all blocks can be assigned for execution immediately, and some blocks may be queued, waiting for resources.</li></ul><h2 id="_2-how-to-improve-performance-with-kernels" tabindex="-1"><a class="header-anchor" href="#_2-how-to-improve-performance-with-kernels" aria-hidden="true">#</a> 2. How to Improve Performance with Kernels</h2><h3 id="_2-1-tools-for-writing-kernel-code" tabindex="-1"><a class="header-anchor" href="#_2-1-tools-for-writing-kernel-code" aria-hidden="true">#</a> 2.1. Tools for Writing Kernel Code</h3><ul><li>Pytorch: easy but slow</li><li>torch.compile: easy, fast, but not flexible</li><li>triton: harder, faster, and more flexible</li><li>CUDA: hardest, fastest, and most flexible (if you get it right)</li></ul><h3 id="_2-2-torch-compile-decorator" tabindex="-1"><a class="header-anchor" href="#_2-2-torch-compile-decorator" aria-hidden="true">#</a> 2.2. torch.compile Decorator</h3><p>If you want to add a new operation lacking in a kernel or speed up an existing PyTorch function, writing a kernel from scratch might seem the most straightforward approach. However, creating high-performance CUDA Kernels from scratch requires extensive experience and a steep learning curve. A better starting point is often to use torch.compile, which captures your operations and generates low-level, high-performance Kernels in Triton, dynamically optimizing PyTorch code.</p><p>Suppose you want to write a Kernel for the activation function of the Exponential Linear Unit:</p><figure><img src="/blog/assets/028_elu-W6YBeiqT.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>After writing a PyTorch implementation, you only need to decorate it with @torch.compile</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token decorator annotation punctuation">@torch<span class="token punctuation">.</span>compile</span>
<span class="token keyword">def</span> <span class="token function">elu</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> torch<span class="token punctuation">.</span>where<span class="token punctuation">(</span>x <span class="token operator">&lt;</span> <span class="token number">0</span><span class="token punctuation">,</span> alpha <span class="token operator">*</span> <span class="token punctuation">(</span>torch<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> x<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>The performance improvement is significant</p><figure><img src="/blog/assets/028_torch_compile_performance-WzBn3UVG.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>Once you run a Python script with the @torch.compile decorator, the corresponding Triton Kernel is generated.</p><p>To view the Triton Kernel generated by @torch.compile, simply set the environment variable TORCH_LOGS to &quot;output_code&quot;</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token builtin class-name">export</span> <span class="token assign-left variable">TORCH_LOGS</span><span class="token operator">=</span><span class="token string">&quot;output_code&quot;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>The corresponding Triton Kernel (variables renamed and comments added for readability):</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token decorator annotation punctuation">@triton<span class="token punctuation">.</span>jit</span>
<span class="token keyword">def</span> <span class="token function">elu_kernel</span><span class="token punctuation">(</span>input_ptr<span class="token punctuation">,</span> output_ptr<span class="token punctuation">,</span> num_elements<span class="token punctuation">,</span> BLOCK_SIZE<span class="token punctuation">:</span> tl<span class="token punctuation">.</span>constexpr<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># Calculate the starting index for this block</span>
    block_start <span class="token operator">=</span> tl<span class="token punctuation">.</span>program_id<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">*</span> BLOCK_SIZE
    <span class="token comment"># Create an array of indices for this block</span>
    block_indices <span class="token operator">=</span> block_start <span class="token operator">+</span> tl<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> BLOCK_SIZE<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">]</span>
    <span class="token comment"># Create a mask to ensure only valid indices are processed</span>
    valid_mask <span class="token operator">=</span> block_indices <span class="token operator">&lt;</span> num_elements
    <span class="token comment"># Load input values from the input pointer based on valid indices</span>
    input_values <span class="token operator">=</span> tl<span class="token punctuation">.</span>load<span class="token punctuation">(</span>input_ptr <span class="token operator">+</span> block_indices<span class="token punctuation">,</span> valid_mask<span class="token punctuation">)</span>
    <span class="token comment"># Define the ELU parameters</span>
    zero_value <span class="token operator">=</span> <span class="token number">0.0</span>  <span class="token comment"># Threshold for ELU activation</span>
    negative_mask <span class="token operator">=</span> input_values <span class="token operator">&lt;</span> zero_value
    exp_values <span class="token operator">=</span> tl<span class="token punctuation">.</span>math<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>input_values<span class="token punctuation">)</span>
    <span class="token comment"># Define the ELU output shift</span>
    one_value <span class="token operator">=</span> <span class="token number">1.0</span>
    shifted_exp_values <span class="token operator">=</span> exp_values <span class="token operator">-</span> one_value

    output_values <span class="token operator">=</span> tl<span class="token punctuation">.</span>where<span class="token punctuation">(</span>negative_mask<span class="token punctuation">,</span> shifted_exp_values<span class="token punctuation">,</span> input_values<span class="token punctuation">)</span>

    <span class="token comment"># Store the computed output values back to the output pointer</span>
    tl<span class="token punctuation">.</span>store<span class="token punctuation">(</span>output_ptr <span class="token operator">+</span> block_indices<span class="token punctuation">,</span> output_values<span class="token punctuation">,</span> valid_mask<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>Here, tl.program_id(0) provides a unique block ID, which we use to determine the segment of data the block will process. Using this block ID, block_start calculates the starting index for each block segment, while block_indices specify the range of indices within the segment. valid_mask ensures that only indices within num_elements are processed, safely loading data with tl.load. The ELU function is then applied, modifying values based on whether they are negative, and finally, the results are written back to memory with tl.store.</p><h3 id="_2-3-implementing-triton-kernels" tabindex="-1"><a class="header-anchor" href="#_2-3-implementing-triton-kernels" aria-hidden="true">#</a> 2.3. Implementing Triton Kernels</h3><p>If this performance improvement is not enough, consider implementing Triton Kernels</p><figure><img src="/blog/assets/028_triton_performance-kI6Pgd4I.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>Even in Triton, sometimes due to the language&#39;s limitations in handling low-level details (such as shared memory and scheduling within SMs), we cannot fully achieve the device&#39;s optimal performance. Triton&#39;s functionality is limited to blocks and their scheduling across SMs. For deeper control, you need to implement kernels directly in CUDA, where you can access all the underlying low-level details.</p><h3 id="_2-4-implementing-cuda-kernels" tabindex="-1"><a class="header-anchor" href="#_2-4-implementing-cuda-kernels" aria-hidden="true">#</a> 2.4. Implementing CUDA Kernels</h3><p>Techniques to improve kernel efficiency:</p><ul><li>Optimize memory access patterns to reduce latency</li><li>Use shared memory to store frequently accessed data</li><li>Manage thread workloads to minimize idle time</li></ul><h4 id="_2-4-1-optimizing-memory-access-memory-coalescing" tabindex="-1"><a class="header-anchor" href="#_2-4-1-optimizing-memory-access-memory-coalescing" aria-hidden="true">#</a> 2.4.1. Optimizing Memory Access / Memory Coalescing</h4><p>Compared to cache, Global Memory has longer latency and lower bandwidth, which is often the bottleneck for most applications.</p><p>In CUDA devices, global memory is implemented using DRAM</p><p>Memory coalescing takes advantage of DRAM&#39;s burst data transfer mode, where accessing one memory address simultaneously transfers a series of contiguous memory locations.</p><p>Maximize memory access efficiency by ensuring that 32 threads in a warp access adjacent memory (For instance, if thread 0 accesses location M, thread 1 accesses M + 1, thread 2 accesses M + 2, and so forth)</p><figure><img src="/blog/assets/028_memory_coalescing-0qW7xgJF.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><figure><img src="/blog/assets/028_memory_workload_analysis-4PTWYHy3.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>Problem</p><ul><li>Low throughput</li><li>Warning of uncoalesced memory access</li></ul><p>Reason Matrix elements are stored in row-major order, as shown below:</p><figure><img src="/blog/assets/028_row_first-HJych-Bb.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>But threads load data in column-major order, preventing memory access coalescing</p><p>Solution: Let threads load data in row-major order to coalesce memory access</p><figure><img src="/blog/assets/028_memory_workload_analysis1-SFZ_aFCV.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>Throughput increased tenfold</p><h4 id="_2-4-2-using-shared-memory-tiling" tabindex="-1"><a class="header-anchor" href="#_2-4-2-using-shared-memory-tiling" aria-hidden="true">#</a> 2.4.2. Using Shared Memory / Tiling</h4><p>Shared memory is a small, fast-access memory space shared by all threads in a block, reducing the need to repeatedly load data from slow global memory</p><p>Use tiling to load data into shared memory at once, allowing all threads in a block to reuse the same shared data, enabling quick access to all necessary data for matrix multiplication</p><figure><img src="/blog/assets/028_tiling-R0FSMmOy.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>Throughput increased to 410 GB/s, kernel execution time reduced by about 43%, achieving approximately 6.6 TFLOPs of performance</p><h4 id="_2-4-3-thread-coarsening" tabindex="-1"><a class="header-anchor" href="#_2-4-3-thread-coarsening" aria-hidden="true">#</a> 2.4.3. Thread Coarsening</h4><p>Thread coarsening combines several threads into a single coarse thread, significantly reducing shared memory access as each coarse thread can handle multiple output elements</p><h4 id="_2-4-4-minimizing-control-divergence" tabindex="-1"><a class="header-anchor" href="#_2-4-4-minimizing-control-divergence" aria-hidden="true">#</a> 2.4.4. Minimizing Control Divergence</h4><p>SIMD: single instruction, multiple data</p><p>An SM (Streaming Multiprocessor) executes all threads in a warp using the SIMD model</p><p>The advantage of SIMD is efficiency: control hardware responsible for instruction fetching and scheduling is shared by multiple execution units, minimizing hardware overhead related to control functions, allowing more hardware to focus on improving arithmetic throughput</p><h2 id="_3-fused-kernels" tabindex="-1"><a class="header-anchor" href="#_3-fused-kernels" aria-hidden="true">#</a> 3. Fused Kernels</h2><p>GPU and CPU operations can be asynchronous. Specifically, host code on the CPU can schedule workloads on the GPU in a non-blocking manner.</p><p>Avoid switching back and forth between host and GPU Kernel commands</p><p>A series of kernels that need to switch back and forth between global memory and compute units:</p><figure><img src="/blog/assets/028_before_fused_kernels-lxzOoLJ3.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>Complete all operations at once:</p><figure><img src="/blog/assets/028_after_fused_kernels-YBpfrS_n.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>How to avoid this back-and-forth switching? The best way is to make our GPU as autonomous as possible. This can be achieved by packaging as many consecutive computational operations as possible into a single kernel for the GPU to run, known as a &quot;Fused Kernel.&quot;</p><p>Fused Kernels are particularly efficient and easy to write for consecutive point-like operations, which are executed independently on each input token. In this case, it makes no sense to first put the computed values back into global memory and then move them to SM memory to start a new kernel. A more efficient approach is to keep all values locally until a series of computations are completed.</p><p>In Transformer models, there are many places where this &quot;fusing&quot; method can be applied: every time we encounter a series of point-like operations, such as in the computations involved in layer normalization.</p><h2 id="_4-flash-attention" tabindex="-1"><a class="header-anchor" href="#_4-flash-attention" aria-hidden="true">#</a> 4. Flash Attention</h2><p>Flash Attention, proposed by Tri Dao, aims to optimize attention computation by writing custom CUDA kernels, making it faster and more memory-efficient. The core idea of Flash Attention is to efficiently utilize various GPU memories, avoiding excessive reliance on the slowest memory: the GPU&#39;s global memory.</p><h3 id="_4-1-before-optimization" tabindex="-1"><a class="header-anchor" href="#_4-1-before-optimization" aria-hidden="true">#</a> 4.1. Before Optimization</h3><figure><img src="/blog/assets/028_before_flash_attention-9DD7B5U0.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>HBM: High Bandwidth Memory (represents global memory, not efficient at all)</p><p>The basic implementation of the attention mechanism involves a lot of transfers between memory and work units. It requires instantiating S and P matrices in HBM, meaning results need to be sent to HBM first and then returned to SRAM for subsequent computations.</p><p>Because HBM&#39;s bandwidth is quite low, it is the bottleneck for attention computation</p><h3 id="_4-2-flash-attention-optimization" tabindex="-1"><a class="header-anchor" href="#_4-2-flash-attention-optimization" aria-hidden="true">#</a> 4.2. Flash Attention Optimization</h3><p>The key is to compute the S matrix in small chunks so that it can fit into the smaller shared memory of the SM. But we can do better by completely avoiding the instantiation of the large S matrix and instead only keeping the necessary statistics needed to compute the softmax normalization factor. This way, we can compute O directly in SRAM at once, rather than moving intermediate results back and forth. In this case, we not only utilize shared memory but also alleviate the memory bottleneck caused by instantiating the attention matrix (the bulk of activations).</p><figure><img src="/blog/assets/028_after_flash_attention-pQVj0P43.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>The concept of Flash Attention addresses many bottlenecks in model training, quickly becoming the default way to perform attention in all Transformer models.</p><p>After Flash-Attention 1, the same lab released two improved versions: Flash-Attention 2 and Flash-Attention 3. Compared to Flash-Attention 1, the improvements in Flash-Attention 2 and 3 focus more on low-level implementation optimizations for GPUs rather than the general attention mechanism. Specifically, these optimizations include: (1) minimizing the number of non-matmul operations as much as possible; (2) for Flash-Attention 2, carefully distributing workloads to warps and thread blocks; for Flash-Attention 3, optimizing support for FP8 and Tensor Core for the latest Hopper (H100) architecture.</p></div><!--[--><!----><!--]--><footer class="page-meta"><!----><div class="meta-item git-info"><!----><!----></div></footer><nav class="vp-page-nav"><!----><a aria-label="Distributed Training Part 4: Parallel Strategies" class="vp-link nav-link next nav-link next" href="/blog/posts/llm/027_distribution_and_parallelism_3.html"><div class="hint">Next<span class="arrow end"></span></div><div class="link">Distributed Training Part 4: Parallel Strategies<span class="font-icon icon fa-fw fa-sm fas fa-lightbulb" style=""></span></div></a></nav><!----><!--[--><!----><!--]--><!--]--></main><!--]--><!----></div><!--]--><!--]--><!----><!--]--></div>
    <script type="module" src="/blog/assets/app-jv-bB2tz.js" defer></script>
  </body>
</html>
