<!doctype html>
<html lang="en-US" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.0" />
    <meta name="theme" content="VuePress Theme Hope 2.0.0-rc.13" />
    <style>
      html {
        background: var(--bg-color, #fff);
      }

      html[data-theme="dark"] {
        background: var(--bg-color, #1d1e1f);
      }

      body {
        background: var(--bg-color);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <link rel="alternate" hreflang="zh-cn" href="https://liz-in-tech.github.io/blog/zh/posts/llm/015_fine_tune.html"><meta property="og:url" content="https://liz-in-tech.github.io/blog/posts/llm/015_fine_tune.html"><meta property="og:site_name" content="Liz"><meta property="og:title" content="Fine-tuning"><meta property="og:description" content="Fine-tuning Model Fine-tuning Process LoRA Llama-factory Base Open-Source Models MoE: Mixture of Experts Model RLHF: Reinforcement Learning from Human Feedback"><meta property="og:type" content="article"><meta property="og:locale" content="en-US"><meta property="og:locale:alternate" content="zh-CN"><meta property="og:updated_time" content="2024-11-13T05:26:25.000Z"><meta property="article:author" content="Liz"><meta property="article:tag" content="Fine-tuning"><meta property="article:published_time" content="2024-11-05T00:00:00.000Z"><meta property="article:modified_time" content="2024-11-13T05:26:25.000Z"><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"Fine-tuning","image":[""],"datePublished":"2024-11-05T00:00:00.000Z","dateModified":"2024-11-13T05:26:25.000Z","author":[{"@type":"Person","name":"Liz","url":"https://github.com/liz-in-tech"}]}</script><link rel="icon" herf="/blogger.png"><link rel="icon" href="/blog/blogger.png"><title>Fine-tuning | Liz</title><meta name="description" content="Fine-tuning Model Fine-tuning Process LoRA Llama-factory Base Open-Source Models MoE: Mixture of Experts Model RLHF: Reinforcement Learning from Human Feedback">
    <link rel="preload" href="/blog/assets/style-m_obra2h.css" as="style"><link rel="stylesheet" href="/blog/assets/style-m_obra2h.css">
    <link rel="modulepreload" href="/blog/assets/app-74fYY7Rf.js"><link rel="modulepreload" href="/blog/assets/015_fine_tune.html-N7MDUyd-.js"><link rel="modulepreload" href="/blog/assets/015_switching_ffn_layer-fh4TiazV.js"><link rel="modulepreload" href="/blog/assets/plugin-vue_export-helper-x3n3nnut.js"><link rel="modulepreload" href="/blog/assets/015_fine_tune.html-JrbwEhT3.js">
    <link rel="prefetch" href="/blog/assets/index.html-YbPtte5_.js" as="script"><link rel="prefetch" href="/blog/assets/intro.html-CGfhr1vY.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-FUMOuem4.js" as="script"><link rel="prefetch" href="/blog/assets/index.html--TTjrkIy.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-g4Nfr7z1.js" as="script"><link rel="prefetch" href="/blog/assets/intro.html-bitGHKd2.js" as="script"><link rel="prefetch" href="/blog/assets/001_langchain.html-nrisQopy.js" as="script"><link rel="prefetch" href="/blog/assets/002_langchain_sourcecode.html-9XtwFAwc.js" as="script"><link rel="prefetch" href="/blog/assets/003_streamlit.html-oji9upQP.js" as="script"><link rel="prefetch" href="/blog/assets/004_transformer.html-xrin91s2.js" as="script"><link rel="prefetch" href="/blog/assets/005_llama.html-q7LEGqjL.js" as="script"><link rel="prefetch" href="/blog/assets/006_llm_leaderboard.html-c628DmZb.js" as="script"><link rel="prefetch" href="/blog/assets/007_computer_use.html-4RcS3hxb.js" as="script"><link rel="prefetch" href="/blog/assets/008_rag_challenge.html-_8stdYVV.js" as="script"><link rel="prefetch" href="/blog/assets/009_llm_challenge.html-eluz3bTT.js" as="script"><link rel="prefetch" href="/blog/assets/010_rag_workflow.html-Ft0RQWf3.js" as="script"><link rel="prefetch" href="/blog/assets/011_vector_database.html-CImz0KSx.js" as="script"><link rel="prefetch" href="/blog/assets/012_prompt_engineering.html-1CqW55t5.js" as="script"><link rel="prefetch" href="/blog/assets/013_optimizing_llm.html-6CxOIR84.js" as="script"><link rel="prefetch" href="/blog/assets/014_rag_evaluation.html-l_kCYUI1.js" as="script"><link rel="prefetch" href="/blog/assets/016_multimodal.html-XtD4OMNh.js" as="script"><link rel="prefetch" href="/blog/assets/017_agent_and_multiagent.html-dm178NRn.js" as="script"><link rel="prefetch" href="/blog/assets/018_huggingface.html-7ujiqdYY.js" as="script"><link rel="prefetch" href="/blog/assets/019_ollama.html-kLkdC4dl.js" as="script"><link rel="prefetch" href="/blog/assets/020_neo4j.html-61m3-6IM.js" as="script"><link rel="prefetch" href="/blog/assets/021_microsoft_graphrag.html-0d0frUhq.js" as="script"><link rel="prefetch" href="/blog/assets/022_llamaindex_graphrag.html-FazlUPBT.js" as="script"><link rel="prefetch" href="/blog/assets/023_agent_framework.html-5MCDM_Sd.js" as="script"><link rel="prefetch" href="/blog/assets/024_distribution_and_parallelism.html-uCefT9T7.js" as="script"><link rel="prefetch" href="/blog/assets/025_distribution_and_parallelism_1.html-32IzAErP.js" as="script"><link rel="prefetch" href="/blog/assets/026_distribution_and_parallelism_2.html-MEZ1JY2b.js" as="script"><link rel="prefetch" href="/blog/assets/027_distribution_and_parallelism_3.html-IYByZhbZ.js" as="script"><link rel="prefetch" href="/blog/assets/028_distribution_and_parallelism_4.html-Kub1JEXd.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ZDCSnlc1.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ZYw6WxxA.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-OavE9BET.js" as="script"><link rel="prefetch" href="/blog/assets/001_langchain.html-hE_T0u_5.js" as="script"><link rel="prefetch" href="/blog/assets/002_langchain_sourcecode.html-iH0mq6XB.js" as="script"><link rel="prefetch" href="/blog/assets/003_streamlit.html-WyFhRqF6.js" as="script"><link rel="prefetch" href="/blog/assets/004_transformer.html-YaT0PR6o.js" as="script"><link rel="prefetch" href="/blog/assets/005_llama.html-x2qtCXhJ.js" as="script"><link rel="prefetch" href="/blog/assets/006_llm_leaderboard.html-WHPR-17-.js" as="script"><link rel="prefetch" href="/blog/assets/007_computer_use.html-hz6Q-DAA.js" as="script"><link rel="prefetch" href="/blog/assets/008_rag_challenge.html-3KMCwhrh.js" as="script"><link rel="prefetch" href="/blog/assets/009_llm_challenge.html-7gxKMp_3.js" as="script"><link rel="prefetch" href="/blog/assets/010_rag_workflow.html-KndRvZAj.js" as="script"><link rel="prefetch" href="/blog/assets/011_vector_database.html-Akmj-Ub_.js" as="script"><link rel="prefetch" href="/blog/assets/012_prompt_engineering.html-bXz0YlpJ.js" as="script"><link rel="prefetch" href="/blog/assets/013_optimizing_llm.html-W-CdR_ck.js" as="script"><link rel="prefetch" href="/blog/assets/014_rag_evaluation.html-aq7YkQ-T.js" as="script"><link rel="prefetch" href="/blog/assets/015_fine_tune.html-V8hUrR0F.js" as="script"><link rel="prefetch" href="/blog/assets/016_multimodal.html-DCPUUxWe.js" as="script"><link rel="prefetch" href="/blog/assets/017_agent_and_multiagent.html-RlA7g4kG.js" as="script"><link rel="prefetch" href="/blog/assets/018_huggingface.html-YkW8PRbE.js" as="script"><link rel="prefetch" href="/blog/assets/019_ollama.html-V5tcXCC4.js" as="script"><link rel="prefetch" href="/blog/assets/020_neo4j.html-qFyQHNwt.js" as="script"><link rel="prefetch" href="/blog/assets/021_microsoft_graphrag.html-kvlLpO3f.js" as="script"><link rel="prefetch" href="/blog/assets/022_llamaindex_graphrag.html-AiRwjg9s.js" as="script"><link rel="prefetch" href="/blog/assets/023_agent_framework.html-VZsN2kO8.js" as="script"><link rel="prefetch" href="/blog/assets/024_distribution_and_parallelism.html-MO4kg9bC.js" as="script"><link rel="prefetch" href="/blog/assets/025_distribution_and_parallelism_1.html-ZR9kuXUl.js" as="script"><link rel="prefetch" href="/blog/assets/026_distribution_and_parallelism_2.html-GkjDPoeT.js" as="script"><link rel="prefetch" href="/blog/assets/027_distribution_and_parallelism_3.html-5kFJGreK.js" as="script"><link rel="prefetch" href="/blog/assets/028_distribution_and_parallelism_4.html-38Gbieji.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-wh_dBtOR.js" as="script"><link rel="prefetch" href="/blog/assets/404.html-cxLWDy2T.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-kf4JCRaf.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-RkA-insV.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-4kI_oqSd.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-WhuidxNt.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-OqGkeUA_.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-5GeN-sdD.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-c4Rf4yh1.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-2r0jUs7o.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-BSKRXRQc.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-KjTsJ0Hg.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-TteIwMx3.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-g00XXzrL.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-YxbJgo4L.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-3T79Cy0i.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-A5tlQHan.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-04ff5e0O.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-vgZ6rfFh.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-OmipPplE.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-E1KrJL6a.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-oPH9QkTj.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-cHRqZSs8.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-74SU9ZTn.js" as="script"><link rel="prefetch" href="/blog/assets/index.html--iJiA8oX.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-oZPWb_Fc.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-FUIWSLsp.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-5ERWyusD.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Zjn0JNqd.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-jcvPTrgB.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-9t2TsyuQ.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-CcLVFNIv.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-DVoYOOaL.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-V52ipvRm.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-9If_KW0o.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-df9Mrf2R.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-f9bWoKcO.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-GYH0QUoo.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-JVTfeijx.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-_C1QVNqX.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-L_IXFmna.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-nZWHmXY7.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-x4gPgqE4.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-bWnVyuyA.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-LHukpLS7.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-howjHe2f.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-DeN_iOWx.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-cnlzR0a7.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-0P_c_pcU.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-dy_CcFmq.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-FzFytZ_p.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-2KSwV7xp.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-F1coElwg.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ffflqCb9.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-F8ZuLYgH.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-HeYWaFeL.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-xKYeJEc5.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-xB-iS7Ql.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-OEUPqfTV.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-EE4iQI9m.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-g1PUF_BG.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-nUBcs85a.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-9Y3la5Sf.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-wufIFDPM.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-bXZQIxRE.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-wd6ZkEHi.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Xlk0AXmC.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Uv7c7pYa.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-FfZqC9tZ.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-mSPhZxqB.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-51HoKD5A.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Q5_K6Vux.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-jkWPo860.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-kTEqch5G.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-y4iBqBqc.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-iETYQT4k.js" as="script"><link rel="prefetch" href="/blog/assets/intro.html-ule1Jz9M.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-B26Ce-6E.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-JMfyTDfh.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-GNSVMZPS.js" as="script"><link rel="prefetch" href="/blog/assets/intro.html-XiFX24l6.js" as="script"><link rel="prefetch" href="/blog/assets/001_langchain.html-aTUuNcf0.js" as="script"><link rel="prefetch" href="/blog/assets/002_langchain_sourcecode.html-F-G_LZNv.js" as="script"><link rel="prefetch" href="/blog/assets/003_streamlit.html-1wjML3Lp.js" as="script"><link rel="prefetch" href="/blog/assets/004_transformer.html--z2TABMK.js" as="script"><link rel="prefetch" href="/blog/assets/005_llama.html-qJgD5cA8.js" as="script"><link rel="prefetch" href="/blog/assets/006_llm_leaderboard.html-MyTGH7ZD.js" as="script"><link rel="prefetch" href="/blog/assets/007_computer_use.html-R276mg6X.js" as="script"><link rel="prefetch" href="/blog/assets/008_rag_challenge.html-FggHTkut.js" as="script"><link rel="prefetch" href="/blog/assets/009_llm_challenge.html-vQmkuCAd.js" as="script"><link rel="prefetch" href="/blog/assets/010_rag_workflow.html-uw8sfEbw.js" as="script"><link rel="prefetch" href="/blog/assets/011_vector_database.html-njw3HA-K.js" as="script"><link rel="prefetch" href="/blog/assets/012_prompt_engineering.html-YZl8_3DJ.js" as="script"><link rel="prefetch" href="/blog/assets/013_optimizing_llm.html-0KGQiBPr.js" as="script"><link rel="prefetch" href="/blog/assets/014_rag_evaluation.html-ZE5Abz_N.js" as="script"><link rel="prefetch" href="/blog/assets/016_multimodal.html-tY4Lrou5.js" as="script"><link rel="prefetch" href="/blog/assets/017_agent_and_multiagent.html-LLZQoHT_.js" as="script"><link rel="prefetch" href="/blog/assets/018_huggingface.html-vlUjdk6y.js" as="script"><link rel="prefetch" href="/blog/assets/019_ollama.html-0E1a8ymD.js" as="script"><link rel="prefetch" href="/blog/assets/020_neo4j.html-VDOBSpBs.js" as="script"><link rel="prefetch" href="/blog/assets/021_microsoft_graphrag.html-NhowT-zb.js" as="script"><link rel="prefetch" href="/blog/assets/022_llamaindex_graphrag.html-m1QqxyaQ.js" as="script"><link rel="prefetch" href="/blog/assets/023_agent_framework.html-s6aaQyPq.js" as="script"><link rel="prefetch" href="/blog/assets/024_distribution_and_parallelism.html-mcWDVxU9.js" as="script"><link rel="prefetch" href="/blog/assets/025_distribution_and_parallelism_1.html-3Q1VNe84.js" as="script"><link rel="prefetch" href="/blog/assets/026_distribution_and_parallelism_2.html-plxA0Vv1.js" as="script"><link rel="prefetch" href="/blog/assets/027_distribution_and_parallelism_3.html-Djdzmvel.js" as="script"><link rel="prefetch" href="/blog/assets/028_distribution_and_parallelism_4.html-ZyvwGllI.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-MMIbGt8W.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Meezp5An.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-LHTTg6UW.js" as="script"><link rel="prefetch" href="/blog/assets/001_langchain.html--LyYB64w.js" as="script"><link rel="prefetch" href="/blog/assets/002_langchain_sourcecode.html-iQVqBKNY.js" as="script"><link rel="prefetch" href="/blog/assets/003_streamlit.html-53ADn2wT.js" as="script"><link rel="prefetch" href="/blog/assets/004_transformer.html-97ovvest.js" as="script"><link rel="prefetch" href="/blog/assets/005_llama.html-YceYqKyv.js" as="script"><link rel="prefetch" href="/blog/assets/006_llm_leaderboard.html-6bgRRWw9.js" as="script"><link rel="prefetch" href="/blog/assets/007_computer_use.html-vouBuA9W.js" as="script"><link rel="prefetch" href="/blog/assets/008_rag_challenge.html-km78igxp.js" as="script"><link rel="prefetch" href="/blog/assets/009_llm_challenge.html-SQpsJNVu.js" as="script"><link rel="prefetch" href="/blog/assets/010_rag_workflow.html-gx3_TnZU.js" as="script"><link rel="prefetch" href="/blog/assets/011_vector_database.html-ZDe65xaT.js" as="script"><link rel="prefetch" href="/blog/assets/012_prompt_engineering.html-KiDWLV83.js" as="script"><link rel="prefetch" href="/blog/assets/013_optimizing_llm.html-qZETJJKw.js" as="script"><link rel="prefetch" href="/blog/assets/014_rag_evaluation.html-vvS2fOQT.js" as="script"><link rel="prefetch" href="/blog/assets/015_fine_tune.html--pvIAqdI.js" as="script"><link rel="prefetch" href="/blog/assets/016_multimodal.html-1Ysa9iba.js" as="script"><link rel="prefetch" href="/blog/assets/017_agent_and_multiagent.html-oMffmvvX.js" as="script"><link rel="prefetch" href="/blog/assets/018_huggingface.html-iKSVOJFV.js" as="script"><link rel="prefetch" href="/blog/assets/019_ollama.html-yVAuISKR.js" as="script"><link rel="prefetch" href="/blog/assets/020_neo4j.html-vk88Pa0d.js" as="script"><link rel="prefetch" href="/blog/assets/021_microsoft_graphrag.html-L5FlOwpQ.js" as="script"><link rel="prefetch" href="/blog/assets/022_llamaindex_graphrag.html-xRgh74ep.js" as="script"><link rel="prefetch" href="/blog/assets/023_agent_framework.html-747Xrf6v.js" as="script"><link rel="prefetch" href="/blog/assets/024_distribution_and_parallelism.html-IbLXEclX.js" as="script"><link rel="prefetch" href="/blog/assets/025_distribution_and_parallelism_1.html-dAavkjtv.js" as="script"><link rel="prefetch" href="/blog/assets/026_distribution_and_parallelism_2.html-Oarj2nhk.js" as="script"><link rel="prefetch" href="/blog/assets/027_distribution_and_parallelism_3.html-77Cvv0oS.js" as="script"><link rel="prefetch" href="/blog/assets/028_distribution_and_parallelism_4.html-PBsY_rap.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Zcp-eU4_.js" as="script"><link rel="prefetch" href="/blog/assets/404.html-rkj_7lo2.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-QLwL-7Ep.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Oxf_ebnS.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-5D2IjCOg.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-A31xeYwf.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-msPfzzJg.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-DZdGhB_L.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-boE_F-iQ.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-h_NjiMfU.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-p2Tsu2p1.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-_xON_iJC.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-B2Pkj6YQ.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-W452oCoL.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-TmPJxG-7.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-V70cqVcH.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-B_T6Dw-T.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-dPdCaTCj.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-A2W7lKnn.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-j29Sywkd.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-1H13OqYN.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-0J9j5_9y.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-6XaTVS8A.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-0XfA9SW_.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-tAjPVsUY.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-IHCZ1ifx.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-_hyrX4u7.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-cyiudMuz.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-9hZ2W15j.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-5UYirEbR.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-YEuUpom_.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-QgDkvTJo.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-27VGLSN_.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-m7x4n_H9.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-vZ2L26cY.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-TFKHFmGv.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-bOiN38kD.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-JVCXdH3X.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-11ZIgyrs.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-3m_mRo18.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-tzLGsnDk.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-IxMKj7wS.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-mYApoqog.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-OmzkmQ32.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-nWtmao90.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-xZKfuCLl.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-WqiXb0WV.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-w71sLuGm.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-GtICBxns.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-BnLb2pp-.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-l_HMqEsW.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-4ecOk4nY.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-r9SC3-tn.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Z6k6LLnw.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Knbb-9ji.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-5x90Xd-z.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-2bCBwEM1.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-kq0jp3Og.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-XbG0eQrg.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-DDni3m4T.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Kfam6HkQ.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-tLjhI3cT.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-dgJiYNze.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-mLruQIuy.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Gk8Wyjk0.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-8GIfW0mp.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-zzlJAm82.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-gQrm5__9.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-BflITUVW.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Sps6mSh5.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ZrPf0SHj.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Das9heZJ.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-mcwfHmXR.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-jyaziJXl.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-UmpcJspg.js" as="script"><link rel="prefetch" href="/blog/assets/photoswipe.esm-08_zHRDQ.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">Skip to main content</a><!--]--><!--[--><div class="theme-container no-sidebar has-toc"><!--[--><header id="navbar" class="vp-navbar"><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!--[--><!----><!--]--><!--[--><a class="vp-link vp-brand vp-brand" href="/blog/"><img class="vp-nav-logo" src="/blog/blogger.png" alt><!----><span class="vp-site-name hide-in-pad">Liz</span></a><!--]--><!--[--><!----><!--]--></div><div class="vp-navbar-center"><!--[--><!----><!--]--><!--[--><nav class="vp-nav-links"><div class="nav-item hide-in-mobile"><a aria-label="Home" class="vp-link nav-link nav-link" href="/blog/"><span class="font-icon icon fa-fw fa-sm fas fa-home" style=""></span>Home<!----></a></div><div class="nav-item hide-in-mobile"><a aria-label="Project" class="vp-link nav-link nav-link" href="/blog/demo/"><span class="font-icon icon fa-fw fa-sm fas fa-star" style=""></span>Project<!----></a></div></nav><!--]--><!--[--><!----><!--]--></div><div class="vp-navbar-end"><!--[--><!----><!--]--><!--[--><div class="nav-item"><div class="dropdown-wrapper i18n-dropdown"><button type="button" class="dropdown-title" aria-label="Select language"><!--[--><svg xmlns="http://www.w3.org/2000/svg" class="icon i18n-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="i18n icon" style="width:1rem;height:1rem;vertical-align:middle;"><path d="M379.392 460.8 494.08 575.488l-42.496 102.4L307.2 532.48 138.24 701.44l-71.68-72.704L234.496 460.8l-45.056-45.056c-27.136-27.136-51.2-66.56-66.56-108.544h112.64c7.68 14.336 16.896 27.136 26.112 35.84l45.568 46.08 45.056-45.056C382.976 312.32 409.6 247.808 409.6 204.8H0V102.4h256V0h102.4v102.4h256v102.4H512c0 70.144-37.888 161.28-87.04 210.944L378.88 460.8zM576 870.4 512 1024H409.6l256-614.4H768l256 614.4H921.6l-64-153.6H576zM618.496 768h196.608L716.8 532.48 618.496 768z"></path></svg><!--]--><span class="arrow"></span><ul class="nav-dropdown"><li class="dropdown-item"><a aria-label="English" class="vp-link nav-link active nav-link active" href="/blog/posts/llm/015_fine_tune.html"><!---->English<!----></a></li><li class="dropdown-item"><a aria-label="简体中文" class="vp-link nav-link nav-link" href="/blog/zh/posts/llm/015_fine_tune.html"><!---->简体中文<!----></a></li></ul></button></div></div><div class="nav-item vp-repo"><a class="vp-repo-link" href="https://github.com/liz-in-tech" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><div class="nav-item hide-in-mobile"><button type="button" id="appearance-switch"><svg xmlns="http://www.w3.org/2000/svg" class="icon auto-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="auto icon" style="display:block;"><path d="M512 992C246.92 992 32 777.08 32 512S246.92 32 512 32s480 214.92 480 480-214.92 480-480 480zm0-840c-198.78 0-360 161.22-360 360 0 198.84 161.22 360 360 360s360-161.16 360-360c0-198.78-161.22-360-360-360zm0 660V212c165.72 0 300 134.34 300 300 0 165.72-134.28 300-300 300z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon dark-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="dark icon" style="display:none;"><path d="M524.8 938.667h-4.267a439.893 439.893 0 0 1-313.173-134.4 446.293 446.293 0 0 1-11.093-597.334A432.213 432.213 0 0 1 366.933 90.027a42.667 42.667 0 0 1 45.227 9.386 42.667 42.667 0 0 1 10.24 42.667 358.4 358.4 0 0 0 82.773 375.893 361.387 361.387 0 0 0 376.747 82.774 42.667 42.667 0 0 1 54.187 55.04 433.493 433.493 0 0 1-99.84 154.88 438.613 438.613 0 0 1-311.467 128z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon light-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="light icon" style="display:none;"><path d="M952 552h-80a40 40 0 0 1 0-80h80a40 40 0 0 1 0 80zM801.88 280.08a41 41 0 0 1-57.96-57.96l57.96-58a41.04 41.04 0 0 1 58 58l-58 57.96zM512 752a240 240 0 1 1 0-480 240 240 0 0 1 0 480zm0-560a40 40 0 0 1-40-40V72a40 40 0 0 1 80 0v80a40 40 0 0 1-40 40zm-289.88 88.08-58-57.96a41.04 41.04 0 0 1 58-58l57.96 58a41 41 0 0 1-57.96 57.96zM192 512a40 40 0 0 1-40 40H72a40 40 0 0 1 0-80h80a40 40 0 0 1 40 40zm30.12 231.92a41 41 0 0 1 57.96 57.96l-57.96 58a41.04 41.04 0 0 1-58-58l58-57.96zM512 832a40 40 0 0 1 40 40v80a40 40 0 0 1-80 0v-80a40 40 0 0 1 40-40zm289.88-88.08 58 57.96a41.04 41.04 0 0 1-58 58l-57.96-58a41 41 0 0 1 57.96-57.96z"></path></svg></button></div><form class="search-box" role="search"><input type="search" autocomplete="off" spellcheck="false" value><!----></form><!--]--><!--[--><!----><!--]--><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar"><!--[--><!----><!--]--><ul class="vp-sidebar-links"></ul><!--[--><!----><!--]--></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!--[--><!----><!--]--><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><span class="font-icon icon fa-fw fa-sm fas fa-lightbulb" style=""></span>Fine-tuning</h1><div class="page-info"><span class="page-author-info" aria-label="Author🖊" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><a class="page-author-item" href="https://github.com/liz-in-tech" target="_blank" rel="noopener noreferrer">Liz</a></span><span property="author" content="Liz"></span></span><!----><span class="page-date-info" aria-label="Writing Date📅" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span><!----></span><meta property="datePublished" content="2024-11-05T00:00:00.000Z"></span><!----><span class="page-reading-time-info" aria-label="Reading Time⌛" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>About 7 min</span><meta property="timeRequired" content="PT7M"></span><span class="page-category-info" aria-label="Category🌈" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon category-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="category icon"><path d="M148.41 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H148.41c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.311-40.31zM147.556 553.478H429.73c22.263 0 40.311 18.048 40.311 40.31v282.176c0 22.263-18.048 40.312-40.31 40.312H147.555c-22.263 0-40.311-18.049-40.311-40.312V593.79c0-22.263 18.048-40.311 40.31-40.311zM593.927 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H593.927c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.31-40.31zM730.22 920.502H623.926c-40.925 0-74.22-33.388-74.22-74.425V623.992c0-41.038 33.387-74.424 74.425-74.424h222.085c41.038 0 74.424 33.226 74.424 74.067v114.233c0 10.244-8.304 18.548-18.547 18.548s-18.548-8.304-18.548-18.548V623.635c0-20.388-16.746-36.974-37.33-36.974H624.13c-20.585 0-37.331 16.747-37.331 37.33v222.086c0 20.585 16.654 37.331 37.126 37.331H730.22c10.243 0 18.547 8.304 18.547 18.547 0 10.244-8.304 18.547-18.547 18.547z"></path></svg><!--[--><span class="page-category-item category6 clickable" role="navigation">LLM</span><!--]--><meta property="articleSection" content="LLM"></span><span class="page-tag-info" aria-label="Tag🏷" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon tag-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="tag icon"><path d="M939.902 458.563L910.17 144.567c-1.507-16.272-14.465-29.13-30.737-30.737L565.438 84.098h-.402c-3.215 0-5.726 1.005-7.634 2.913l-470.39 470.39a10.004 10.004 0 000 14.164l365.423 365.424c1.909 1.908 4.42 2.913 7.132 2.913s5.223-1.005 7.132-2.913l470.39-470.39c2.01-2.11 3.014-5.023 2.813-8.036zm-240.067-72.121c-35.458 0-64.286-28.828-64.286-64.286s28.828-64.285 64.286-64.285 64.286 28.828 64.286 64.285-28.829 64.286-64.286 64.286z"></path></svg><!--[--><span class="page-tag-item tag5 clickable" role="navigation">Fine-tuning</span><!--]--><meta property="keywords" content="Fine-tuning"></span></div><hr></div><div class="toc-place-holder"><aside id="toc"><!--[--><!----><!--]--><div class="toc-header">On This Page<button type="button" class="print-button" title="Print"><svg xmlns="http://www.w3.org/2000/svg" class="icon print-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="print icon"><path d="M819.2 364.8h-44.8V128c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v236.8h-44.8C145.067 364.8 96 413.867 96 473.6v192c0 59.733 49.067 108.8 108.8 108.8h44.8V896c0 17.067 14.933 32 32 32h460.8c17.067 0 32-14.933 32-32V774.4h44.8c59.733 0 108.8-49.067 108.8-108.8v-192c0-59.733-49.067-108.8-108.8-108.8zM313.6 160h396.8v204.8H313.6V160zm396.8 704H313.6V620.8h396.8V864zM864 665.6c0 25.6-19.2 44.8-44.8 44.8h-44.8V588.8c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v121.6h-44.8c-25.6 0-44.8-19.2-44.8-44.8v-192c0-25.6 19.2-44.8 44.8-44.8h614.4c25.6 0 44.8 19.2 44.8 44.8v192z"></path></svg></button></div><div class="toc-wrapper"><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_1-fine-tuning">1. Fine-tuning</a></li><li><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_1-1-instruction-fine-tuning-supervised-fine-tuning">1.1. Instruction Fine-tuning / Supervised Fine-tuning</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_1-2-multi-task-fine-tuning">1.2. Multi-task Fine-tuning</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_2-model-fine-tuning-process">2. Model Fine-tuning Process</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_3-data-construction">3. Data Construction</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_4-fine-tuning-strategies">4. Fine-tuning Strategies</a></li><li><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_4-1-based-on-fine-tuning-scope-full-and-partial-parameter-fine-tuning">4.1. Based on Fine-tuning Scope: Full and Partial Parameter Fine-tuning</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_4-2-based-on-task-sft-rlhf-rlaif">4.2. Based on Task: SFT, RLHF, RLAIF</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_4-3-low-resource-fine-tuning">4.3. Low-resource Fine-tuning</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_4-4-deepspeed">4.4. DeepSpeed</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_5-lora-and-qlora">5. LoRA and QLoRA</a></li><li><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_5-1-lora">5.1. LoRA</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_5-2-qlora">5.2. QLoRA</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_6-fine-tuning-practice">6. Fine-tuning Practice</a></li><li><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_6-1-3-key-components">6.1. 3 Key Components</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_6-2-advanced-fine-tuning-settings">6.2. Advanced Fine-tuning Settings</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_6-3-github-tloen-alpaca-lora">6.3. GitHub: tloen/alpaca-lora</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_6-4-llama-factory">6.4. LLaMA-Factory</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_6-5-more">6.5. More</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_7-open-source-models">7. Open-Source Models</a></li><li><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_7-1-mistral-7b">7.1. Mistral-7B</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_8-mixture-of-experts-model-moe">8. Mixture of Experts Model (MoE)</a></li><li><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#moe-advantages">MoE Advantages</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_9-rlhf-reinforcement-learning-from-human-feedback">9. RLHF (Reinforcement Learning from Human Feedback)</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_10-references">10. References</a></li><!----><!--]--></ul><div class="toc-marker" style="top:-1.7rem;"></div></div><!--[--><!----><!--]--></aside></div><!--[--><!----><!--]--><div class="theme-hope-content"><h1 id="fine-tuning" tabindex="-1"><a class="header-anchor" href="#fine-tuning" aria-hidden="true">#</a> Fine-tuning</h1><ul><li>Model Fine-tuning Process</li><li>LoRA</li><li>Llama-factory</li><li>Base Open-Source Models</li><li>MoE: Mixture of Experts Model</li><li>RLHF: Reinforcement Learning from Human Feedback</li></ul><!-- more --><h2 id="_1-fine-tuning" tabindex="-1"><a class="header-anchor" href="#_1-fine-tuning" aria-hidden="true">#</a> 1. Fine-tuning</h2><ul><li><strong>Goal</strong>: Amplify required abilities while keeping others unchanged</li><li><strong>Value</strong>: Enhances corresponding capabilities</li><li><strong>Issue</strong>: Catastrophic Forgetting (risk of degradation in other abilities) <ul><li>Solutions: <ul><li>Solution 1: No need to solve <ul><li>If other abilities are not crucial, degradation might not matter much</li></ul></li><li>Solution 2: Use larger models, as they are less likely to be affected due to better generalization ability</li><li>Solution 3: Multi-task fine-tuning <ul><li>Combine data from multiple tasks</li><li>Fill in the abilities where lacking</li></ul></li></ul></li></ul></li></ul><h3 id="_1-1-instruction-fine-tuning-supervised-fine-tuning" tabindex="-1"><a class="header-anchor" href="#_1-1-instruction-fine-tuning-supervised-fine-tuning" aria-hidden="true">#</a> 1.1. Instruction Fine-tuning / Supervised Fine-tuning</h3><ul><li><strong>FT (Fine-tuning)</strong></li><li><strong>SFT (Supervised Fine-tuning)</strong>, also known as Instruction Fine-tuning <ul><li>Fine-tuning the model with explicit instructions or examples for specific tasks, typically preserving the knowledge of the pre-trained model</li><li><strong>Advantages</strong>: Focuses on fine-tuning for specific tasks with high adaptability, while retaining the model&#39;s basic capabilities.</li><li><strong>Disadvantages</strong>: May not fully explore the model’s potential for highly complex tasks.</li></ul></li></ul><h3 id="_1-2-multi-task-fine-tuning" tabindex="-1"><a class="header-anchor" href="#_1-2-multi-task-fine-tuning" aria-hidden="true">#</a> 1.2. Multi-task Fine-tuning</h3><p>Enhancing multiple abilities by combining data from various tasks into one training set.</p><figure><img src="/blog/assets/015_multi_task_finetune-TK9vK-vK.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h2 id="_2-model-fine-tuning-process" tabindex="-1"><a class="header-anchor" href="#_2-model-fine-tuning-process" aria-hidden="true">#</a> 2. Model Fine-tuning Process</h2><ul><li>Define the problem</li><li>Try Prompt Engineering to see if it solves the issue <ul><li>Use Few-shot if possible; if not, consider Fine-tuning. Fine-tuned models improve in the targeted area but may degrade in others.</li><li><strong>Few-shot</strong><ul><li>Issues: <ul><li><ol><li>Token count increases, context fills up quickly</li></ol></li><li><ol start="2"><li>Adding multiple few-shot examples still doesn’t improve performance</li></ol></li></ul></li></ul></li></ul></li><li>If unsuccessful, proceed with Fine-tuning</li><li>Select multiple open-source models for experimentation</li><li>Analyze the gap between actual and expected performance, identify missing capabilities</li><li>Choose model: <ul><li>Fine-tuned Model</li></ul></li><li>Collect data</li><li>Clean the data</li><li>Instruction Fine-tuning (SFT)</li><li>Alignment</li><li><strong>Evaluate</strong><ul><li>A/B Testing</li></ul></li><li>Compression/Quantization &amp; Deployment</li><li><strong>RLHF (Reinforcement Learning from Human Feedback)</strong></li></ul><h2 id="_3-data-construction" tabindex="-1"><a class="header-anchor" href="#_3-data-construction" aria-hidden="true">#</a> 3. Data Construction</h2><p>Data format is different from traditional AI, using question-answer pairs (input, output), where the input part is a prompt form (because users will interact with prompts).</p><ul><li><strong>Input</strong>: Prompt = Instruction + input</li><li><strong>Output</strong>: output</li></ul><p>JSON format:</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>{
    &quot;instruction&quot;: &quot;xxx&quot;,
    &quot;input&quot;: &quot;&quot;, // Sometimes empty, sometimes with value
    &quot;output&quot;: &quot;xxx&quot;
}
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>Not much data is needed, around 1000 entries are sufficient (typically a few thousand to tens of thousands), since you are adding functionality to an existing model rather than training from scratch.</p><p>Fine-tuning process—split data into training, validation, and test sets:</p><ul><li><strong>Training set</strong>: Data used for training</li><li><strong>Validation set</strong>: Used to check performance during training (e.g., mock exams)</li><li><strong>Test set</strong>: Final evaluation after training (e.g., final exam)</li></ul><h2 id="_4-fine-tuning-strategies" tabindex="-1"><a class="header-anchor" href="#_4-fine-tuning-strategies" aria-hidden="true">#</a> 4. Fine-tuning Strategies</h2><h3 id="_4-1-based-on-fine-tuning-scope-full-and-partial-parameter-fine-tuning" tabindex="-1"><a class="header-anchor" href="#_4-1-based-on-fine-tuning-scope-full-and-partial-parameter-fine-tuning" aria-hidden="true">#</a> 4.1. Based on Fine-tuning Scope: Full and Partial Parameter Fine-tuning</h3><ul><li><strong>Full Fine-tuning</strong><ul><li>All parameters are adjusted, which has a significant impact and may affect previous capabilities. Not recommended.</li><li><strong>Advantages</strong>: Highly tailored to specific tasks, can significantly improve model performance</li><li><strong>Disadvantages</strong>: Requires a lot of computational resources and time, may reduce generalization on other tasks</li></ul></li><li><strong>Partial Fine-tuning / Freeze Fine-tuning</strong><ul><li>Only a subset of the model’s parameters (e.g., later layers or specific layers) is fine-tuned, not all parameters.</li><li><strong>Advantages</strong>: Lower resource demands, smaller risk of overfitting</li><li><strong>Disadvantages</strong>: May not adapt as well to complex tasks as full fine-tuning</li><li><strong>Sub-categories</strong>: <ul><li><strong>PEFT (Parameter-Efficient Fine-Tuning)</strong>: <ul><li>Fine-tune only a small set of parameters or additional ones to reduce computation and storage costs.</li><li>Common methods: <ul><li><strong>Adapter Fine-tuning</strong>: <ul><li>Insert small adaptive modules between layers of the pre-trained model and fine-tune them while freezing the original model&#39;s parameters.</li><li><strong>Advantages</strong>: Efficient and flexible, reducing computational costs and memory usage, applicable to multiple tasks.</li></ul></li><li><strong>LoRA (Low-Rank Adaptation)</strong>: <ul><li>A form of adaptive fine-tuning, fine-tuning a subset of parameters through low-rank matrices, typically adjusting a small subset of weights.</li><li>Most common, recommended, minimal impact on the original model&#39;s capabilities.</li></ul></li><li><strong>BitFit</strong>: <ul><li>Only fine-tunes bias parameters.</li></ul></li></ul></li></ul></li><li><strong>Choosing Layers for Fine-tuning</strong><ul><li>Not recommended</li><li><strong>Sub-categories</strong>: <ul><li><strong>Fine-tuning Last Layers</strong>: <ul><li>Fine-tune only the last few layers, useful for adding task-specific adaptation while retaining original model capabilities.</li><li><strong>Advantages</strong>: Reduces complexity and resource demand, still improves performance for specific tasks.</li><li><strong>Disadvantages</strong>: Limited fine-tuning depth, may not fully meet task needs.</li></ul></li></ul></li></ul></li></ul></li></ul></li></ul><h4 id="_4-1-1-gpu-memory-computation" tabindex="-1"><a class="header-anchor" href="#_4-1-1-gpu-memory-computation" aria-hidden="true">#</a> 4.1.1. GPU Memory &amp; Computation</h4><p>For a <strong>7B</strong> model:</p><ul><li>7 billion parameters * 4 bytes per parameter = total size in GB, denoted as &#39;a GB&#39;</li></ul><p>For <strong>Full Fine-tuning</strong> (requires 5a GB):</p><ul><li>Model itself * 1</li><li>Gradient * 1</li><li>Optimizer States * 2</li><li>Variables * 1</li></ul><p>For <strong>LoRA</strong> (slightly larger than &#39;a GB&#39;, as it fine-tunes less than 1% of the parameters):</p><ul><li>Model itself * 1</li><li>Gradient * 1 * 1%</li><li>Optimizer States * 2 * 1%</li></ul><h3 id="_4-2-based-on-task-sft-rlhf-rlaif" tabindex="-1"><a class="header-anchor" href="#_4-2-based-on-task-sft-rlhf-rlaif" aria-hidden="true">#</a> 4.2. Based on Task: SFT, RLHF, RLAIF</h3><ul><li><strong>Supervised Fine-tuning (SFT)</strong>: Supervised fine-tuning;</li><li><strong>Reinforcement Learning from Human Feedback (RLHF)</strong>: Fine-tuning using human feedback through reinforcement learning;</li><li><strong>Reinforcement Learning from AI Feedback (RLAIF)</strong>: When human feedback is costly, use AI-generated feedback.</li></ul><h3 id="_4-3-low-resource-fine-tuning" tabindex="-1"><a class="header-anchor" href="#_4-3-low-resource-fine-tuning" aria-hidden="true">#</a> 4.3. Low-resource Fine-tuning</h3><ul><li>LoRA/QLoRA (reduce training parameters)</li><li>Mixed Precision Training (reduces memory usage by half, accelerates training)</li><li><strong>LOMO</strong> (greatly reduces memory usage, but may perform worse than LoRA in some scenarios)</li><li><strong>Activation Checkpointing</strong> (reduces memory usage at the cost of additional computation)</li><li><strong>Heterogeneous Device Training</strong> (reduces memory usage)</li></ul><h3 id="_4-4-deepspeed" tabindex="-1"><a class="header-anchor" href="#_4-4-deepspeed" aria-hidden="true">#</a> 4.4. DeepSpeed</h3><p>Distributed training</p><ul><li><strong>Data Parallelism</strong>: When data is too large to fit into one memory unit.</li><li><strong>Model Parallelism</strong>: When the model is too large to fit into one memory unit.</li></ul><p>DeepSpeed partitions the model across multiple GPUs, handling memory communication to solve the issue of limited memory. It may also temporarily store the model in system RAM (offloading) if required.</p><h2 id="_5-lora-and-qlora" tabindex="-1"><a class="header-anchor" href="#_5-lora-and-qlora" aria-hidden="true">#</a> 5. LoRA and QLoRA</h2><h3 id="_5-1-lora" tabindex="-1"><a class="header-anchor" href="#_5-1-lora" aria-hidden="true">#</a> 5.1. LoRA</h3><p>Paper: <strong>LoRA: Low-Rank Adaptation of Large Language Models</strong></p><p>Paper Link: <a href="https://arxiv.org/abs/2106.09685" target="_blank" rel="noopener noreferrer">https://arxiv.org/abs/2106.09685<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><p>W + <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Δ</mi></mrow><annotation encoding="application/x-tex">\Delta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">Δ</span></span></span></span> W = <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>W</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></mrow><annotation encoding="application/x-tex">W&#39;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7519em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span></p><p>Fine-tuning changes the <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Δ</mi></mrow><annotation encoding="application/x-tex">\Delta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">Δ</span></span></span></span> W parameters, freezing W.</p><p>LoRA can be applied to any linear transformation inside the model:</p><ul><li><strong>h = Wx</strong> (linear transformation)</li><li><strong>h = (W + <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Δ</mi></mrow><annotation encoding="application/x-tex">\Delta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">Δ</span></span></span></span> W)x</strong></li></ul><p><strong>Advantages of LoRA</strong>:</p><ul><li>Fewer parameters need to be trained, and changes to existing parameters are minimized (reducing the risk of altering the original capabilities of the model).</li><li>Requires less memory for training.</li><li>Increases training efficiency.</li></ul><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>lora_config = LoraConfig(
    r=8, # LoRA rank, typically 8 or 16
    lora_alpha=32, # New W = Old W + lora_alpha/r * $\Delta$ W (affects weight update scale)  
    target_modules=modules, # Specify modules for LoRA fine-tuning (usually not all Linear layers are tuned, often QKV layers)
    lora_dropout=0.05,
    bias=&quot;none&quot;,
    task_type=&quot;CAUSAL_LM&quot;
)
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_5-2-qlora" tabindex="-1"><a class="header-anchor" href="#_5-2-qlora" aria-hidden="true">#</a> 5.2. QLoRA</h3><p>For loading large models into memory.</p><p><strong>Quantization</strong>: Quantizes the model before loading, e.g., converting from 32-bit to 4-bit to reduce memory usage.</p><p>While quantization reduces memory consumption, it leads to some loss in precision and may degrade the model’s performance.</p><p><strong>QLoRA</strong> addresses memory limitations by applying quantization before loading the model.</p><h2 id="_6-fine-tuning-practice" tabindex="-1"><a class="header-anchor" href="#_6-fine-tuning-practice" aria-hidden="true">#</a> 6. Fine-tuning Practice</h2><h3 id="_6-1-3-key-components" tabindex="-1"><a class="header-anchor" href="#_6-1-3-key-components" aria-hidden="true">#</a> 6.1. 3 Key Components</h3><ul><li>Model (from Huggingface) <ul><li>tokenizer: mapping between tokens and ids</li><li>model</li></ul></li><li>Data (from Huggingface)</li><li>Parameters</li></ul><h3 id="_6-2-advanced-fine-tuning-settings" tabindex="-1"><a class="header-anchor" href="#_6-2-advanced-fine-tuning-settings" aria-hidden="true">#</a> 6.2. Advanced Fine-tuning Settings</h3><ul><li>Quantization Level (QLoRA) <ul><li>4-bit or 8-bit</li><li>Using quantization reduces the model size, but also reduces precision, which may lead to a slight decrease in performance.</li></ul></li><li>Acceleration Method <ul><li>flash-attention</li></ul></li><li>Training Method <ul><li>SFT (Supervised Fine-Tuning) Instruction Tuning (70%-80% adoption)</li><li>Common alignment methods: <ul><li>PPO (Reinforcement Learning approach)</li><li>DPO</li></ul></li></ul></li><li>Datasets <ul><li>Local datasets</li><li>Datasets from HuggingFace</li></ul></li><li>LoRA Parameters <ul><li>LoRA matrix rank size <ul><li>Usually 8 (or 16)</li></ul></li><li>LoRA scaling factor <ul><li>Typically twice the LoRA rank, 16 or 32</li></ul></li></ul></li></ul><h3 id="_6-3-github-tloen-alpaca-lora" tabindex="-1"><a class="header-anchor" href="#_6-3-github-tloen-alpaca-lora" aria-hidden="true">#</a> 6.3. GitHub: tloen/alpaca-lora</h3><p>GitHub: <a href="https://github.com/tloen/alpaca-lora" target="_blank" rel="noopener noreferrer">https://github.com/tloen/alpaca-lora<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><p>Training</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>python finetune.py \
    --base_model &#39;decapoda-research/llama-7b-hf&#39; \ # Base model
    --data_path &#39;yahma/alpaca-cleaned&#39; \ # Dataset
    --output_dir &#39;./lora-alpaca&#39; \ # Fine-tuned model output path
    --batch_size 128 \ # Parameters from this line down
    --micro_batch_size 4 \
    --num_epochs 3 \
    --learning_rate 1e-4 \
    --cutoff_len 512 \
    --val_set_size 2000 \
    --lora_r 8 \
    --lora_alpha 16 \
    --lora_dropout 0.05 \
    --lora_target_modules &#39;[q_proj,v_proj]&#39; \
    --train_on_inputs \
    --group_by_length
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>Inference</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>python generate.py \
    --load_8bit \
    --base_model &#39;decapoda-research/llama-7b-hf&#39; \ # Original parameters
    --lora_weights &#39;tloen/alpaca-lora-7b&#39; # New parameters
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_6-4-llama-factory" tabindex="-1"><a class="header-anchor" href="#_6-4-llama-factory" aria-hidden="true">#</a> 6.4. LLaMA-Factory</h3><p>LLaMA-Factory is a fine-tuning UI interface that wraps various model and parameter configurations, simplifying the code-writing process. You only need to select and configure the options in the UI to begin fine-tuning. You won’t need to write code unless some newly released models are not yet integrated into LLaMA-Factory, in which case you can write your own code.</p><h3 id="_6-5-more" tabindex="-1"><a class="header-anchor" href="#_6-5-more" aria-hidden="true">#</a> 6.5. More</h3><p>Rent GPU</p><ul><li>Domestic: AutoDL</li><li>International: jarvislabs.ai</li></ul><p>Download Llama model parameters: <a href="https://github.com/shawwn/llama-dl" target="_blank" rel="noopener noreferrer">https://github.com/shawwn/llama-dl<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><p><a href="https://github.com/ymcui/Chinese-LLaMA-Alpaca" target="_blank" rel="noopener noreferrer">https://github.com/ymcui/Chinese-LLaMA-Alpaca<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><p><a href="https://github.com/SCIR-HI/Huatuo-Llama-Med-Chinese" target="_blank" rel="noopener noreferrer">https://github.com/SCIR-HI/Huatuo-Llama-Med-Chinese<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><h2 id="_7-open-source-models" tabindex="-1"><a class="header-anchor" href="#_7-open-source-models" aria-hidden="true">#</a> 7. Open-Source Models</h2><figure><img src="/blog/assets/015_basic_llm-CfFnBlay.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>English Open-Source Models:</p><ul><li>Llama <ul><li>A series of large language models developed by Meta.</li></ul></li><li>Alpaca: A lightweight, low-cost instruction-tuned model developed by Stanford University based on the LLaMA model. It can perform specific tasks with fewer resources.</li><li>Mistral-7B <ul><li><a href="https://colab.research.google.com/drive/1TVEd2fj3YiklvX5zOqJxQAmXnLOk6-to?usp=sharing#scrollTo=7St-hFLNmS2v" target="_blank" rel="noopener noreferrer">Link<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li></ul></li><li>Mixture of Experts (MoE) Mistral 8x7B <ul><li><a href="https://colab.research.google.com/drive/1VDa0lIfqiwm16hBlIlEaabGVTNB3dN1A?usp=sharing#scrollTo=lChdRaiR81Dc" target="_blank" rel="noopener noreferrer">Link<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li></ul></li></ul><p>Chinese Open-Source Models:</p><ul><li>Qwen</li><li>ChatGLM <ul><li>Fine-tuned mainly on 6B models, larger models not open-sourced.</li><li><code>chatglm.cpp</code> is a C++ rewrite aimed at running models on CPUs; now most models have a corresponding C++ version (quantized inference solution).</li></ul></li></ul><p>Fully open-source (includes dataset and model weights, datasets not provided for the above models):</p><ul><li>Pythia <ul><li><a href="https://github.com/EleutherAI/pythia" target="_blank" rel="noopener noreferrer">Link<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li></ul></li><li>OLMo <ul><li><a href="https://github.com/allenai/OLMo" target="_blank" rel="noopener noreferrer">Link<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li></ul></li></ul><h3 id="_7-1-mistral-7b" tabindex="-1"><a class="header-anchor" href="#_7-1-mistral-7b" aria-hidden="true">#</a> 7.1. Mistral-7B</h3><ul><li>Uses Sliding Window Attention (SWA) to handle long sequences.</li><li>Uses Grouped-query Attention (GQA) to accelerate inference. <img src="/blog/assets/015_sliding_window_attention-jXX1GIf7.png" alt="" loading="lazy"></li></ul><figure><img src="/blog/assets/015_mistral_structure-Fl6s4WOT.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h2 id="_8-mixture-of-experts-model-moe" tabindex="-1"><a class="header-anchor" href="#_8-mixture-of-experts-model-moe" aria-hidden="true">#</a> 8. Mixture of Experts Model (MoE)</h2><p>Paper Name: Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity</p><p>Paper: <a href="https://arxiv.org/pdf/2101.03961" target="_blank" rel="noopener noreferrer">https://arxiv.org/pdf/2101.03961<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><figure><img src="/blog/assets/015_moe_structure-vlzoKbsv.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><figure><img src="/blog/assets/015_switching_ffn_layer-2nh8QQUw.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><ul><li>Multiple experts <ul><li>Mistral 8x7B has 8 experts</li><li>DeepSeek’s MoE has 160 experts</li></ul></li><li>Each expert has its own area of expertise.</li><li>Router (routing selection) <ul><li>Softmax is used to determine each expert&#39;s weight ratio.</li></ul></li><li>Sparse Mixture of Experts <ul><li>Not all experts are queried at once; only a few are selected.</li><li>Mistral 7B is a sparse mixture of experts model.</li></ul></li><li>Some modules are shared, while others are separate. <ul><li>Mistral 8x7B would have 56B parameters, but with shared modules, it totals around 40B.</li></ul></li><li>MoE uses a switching FFN layer instead of the original FFN, with other modules shared. <ul><li>The MoE layer consists of a gating network and a set number of expert networks.</li></ul></li></ul><p>Despite its advantages of efficient pre-training and fast inference compared to dense models, MoE faces some challenges:</p><ul><li><strong>Training</strong>: MoE&#39;s pre-training is computationally efficient, but fine-tuning can lead to poor generalization, resulting in overfitting.</li><li><strong>Inference</strong>: While MoE may have many parameters, only a portion is used during inference. Inference is much faster than for dense models with the same number of parameters. However, all parameters need to be loaded into RAM, so memory requirements are high.</li></ul><h3 id="moe-advantages" tabindex="-1"><a class="header-anchor" href="#moe-advantages" aria-hidden="true">#</a> MoE Advantages</h3><ul><li><strong>Computational Efficiency</strong>: The sparse selection mechanism avoids having all experts involved in inference, reducing computational complexity. In practice, MoE&#39;s computational load can be approximated as <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>k</mi><mo>⋅</mo><mi>n</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(k⋅n)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">n</span><span class="mclose">)</span></span></span></span>, where <code>k</code> is the number of active experts and <code>n</code> is the input sequence length.</li><li><strong>Scalability</strong>: MoE is well-suited for large-scale models. By increasing the number of experts, the model&#39;s capacity can be expanded without significantly increasing computational costs for inference. This makes MoE particularly suitable for extremely large language models such as Switch Transformers and GShard.</li><li><strong>Flexibility</strong>: MoE dynamically selects experts based on input, allowing it to handle different types of tasks and data.</li></ul><p>MoE improves model performance and efficiency through the following designs:</p><ul><li>Sparse expert selection reduces computational complexity.</li><li>Gating networks dynamically select experts based on the input.</li><li>Load-balancing loss ensures experts are used efficiently.</li></ul><h2 id="_9-rlhf-reinforcement-learning-from-human-feedback" tabindex="-1"><a class="header-anchor" href="#_9-rlhf-reinforcement-learning-from-human-feedback" aria-hidden="true">#</a> 9. RLHF (Reinforcement Learning from Human Feedback)</h2><p>RLHF is a machine learning method that combines reinforcement learning with human feedback to help models adapt better to specific tasks and desired behaviors.</p><p>Challenges to address:</p><ul><li>Traditional reinforcement learning faces challenges in reward engineering and lacks high-quality feedback.</li><li>Defining a precise reward function is difficult for many complex tasks.</li><li>Aligning with complex human values. <ul><li>How do we evaluate the quality of text generated by GPT? The &quot;goodness&quot; of generated text is based on human values, so how can we teach GPT human values?</li></ul></li></ul><p>Main principles: RLHF consists of four key components:</p><ul><li><strong>Pre-trained model</strong>: Starts with a pre-trained model, such as a large language model trained on vast amounts of text data.</li><li><strong>Human feedback</strong>: Human feedback is collected to evaluate the quality of the model&#39;s outputs, including annotating or scoring the generated text and providing guidance for improvement.</li><li><strong>Reward modeling</strong>: Human feedback is used to train a reward model, which learns to score the model&#39;s outputs based on human feedback. <ul><li>RM (Reward Model)/Preference Model</li></ul></li><li><strong>Reinforcement learning</strong>: The reward model is used as the reward function. Standard reinforcement learning or deep learning algorithms are used to further train the original model, optimizing its outputs to maximize the score provided by the reward model.</li></ul><h2 id="_10-references" tabindex="-1"><a class="header-anchor" href="#_10-references" aria-hidden="true">#</a> 10. References</h2><ul><li><a href="https://towardsdatascience.com/mixtral-8x7b-understanding-and-running-the-sparse-mixture-of-experts-0e3fc7fde818" target="_blank" rel="noopener noreferrer">Mixtral-8x7B: Understanding and Running the Sparse Mixture of Experts<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li></ul></div><!--[--><!----><!--]--><footer class="page-meta"><!----><div class="meta-item git-info"><!----><!----></div></footer><nav class="vp-page-nav"><a aria-label="Multimodal Large Models" class="vp-link nav-link prev nav-link prev" href="/blog/posts/llm/016_multimodal.html"><div class="hint"><span class="arrow start"></span>Prev</div><div class="link"><span class="font-icon icon fa-fw fa-sm fas fa-lightbulb" style=""></span>Multimodal Large Models</div></a><a aria-label="RAG Evaluation Metrics" class="vp-link nav-link next nav-link next" href="/blog/posts/llm/014_rag_evaluation.html"><div class="hint">Next<span class="arrow end"></span></div><div class="link">RAG Evaluation Metrics<span class="font-icon icon fa-fw fa-sm fas fa-lightbulb" style=""></span></div></a></nav><!----><!--[--><!----><!--]--><!--]--></main><!--]--><!----></div><!--]--><!--]--><!----><!--]--></div>
    <script type="module" src="/blog/assets/app-74fYY7Rf.js" defer></script>
  </body>
</html>
