import{_ as a}from"./plugin-vue_export-helper-x3n3nnut.js";import{o as t,c as e,f as p,a as n,b as s,e as o}from"./app-UEw0SYZq.js";const i={},c=n("h1",{id:"sfttrainer-source-code-exploration-prepare-dataset",tabindex:"-1"},[n("a",{class:"header-anchor",href:"#sfttrainer-source-code-exploration-prepare-dataset","aria-hidden":"true"},"#"),s(" SFTTrainer Source Code Exploration: Prepare Dataset")],-1),l=n("ul",null,[n("li",null,"Prepare Dataset Overall Logic"),n("li",null,[s("Prepare Dataset Code Details "),n("ul",null,[n("li",null,[s("SFTTrainer."),n("strong",null,"init")]),n("li",null,"DataCollatorForLanguageModeling"),n("li",null,"_prepare_dataset")])])],-1),u=o(`<h2 id="_1-prepare-dataset-overall-logic" tabindex="-1"><a class="header-anchor" href="#_1-prepare-dataset-overall-logic" aria-hidden="true">#</a> 1. Prepare Dataset Overall Logic</h2><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>Overall Logic
- 1. If processing_class is None, use the base model&#39;s tokenizer
- 2. Process the Data collator by right-padding with pad_token to ensure consistent length
- 3. Check if the dataset column names contain &quot;input_ids&quot;. If present, it indicates preprocessing has been done, and subsequent preprocessing steps will be skipped
- 4. If column names contain &quot;input_ids&quot; (indicating preprocessing is done), formatting_func will be ignored. Otherwise, process with formatting_func
    - Automatically determine whether to enable batch processing based on the return type of formatting_func, then map the dataset to format each sample as {&quot;text&quot;: formatting_func result}
- 5. If the dataset column names contain &quot;prompt&quot; and &quot;completion&quot; fields
    - Determine whether the format is conversational (containing &quot;role&quot; and &quot;content&quot;) or text-based
    - Map the dataset:
        - For conversational format, format each sample as {&quot;messages&quot;: example[&quot;prompt&quot;] + example[&quot;completion&quot;]}
        - For text format, format each sample as {&quot;text&quot;: example[&quot;prompt&quot;] + example[&quot;completion&quot;]}
- 6. Perform preprocessing (skip if &quot;input_ids&quot; is present in column names)
    - Convert conversational format to unified ChatML format: {&#39;messages&#39;: [{&#39;role&#39;: &#39;user&#39;, &#39;content&#39;: &#39;What color is the sky?&#39;}, {&#39;role&#39;: &#39;assistant&#39;, &#39;content&#39;: &#39;It is blue.&#39;}]}
    - Apply tokenizer.apply_chat_template to convert the &quot;messages&quot; conversational format to text format: {&quot;text&quot;: &quot;xxx&quot;}
    - Tokenize the &quot;text&quot; field using the tokenizer to generate &quot;input_ids&quot; and &quot;attention_mask&quot; fields
- 7. Return the processed dataset, which must contain three fields: &#39;text&#39;, &#39;input_ids&#39;, &#39;attention_mask&#39;
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="_2-prepare-dataset-code-details" tabindex="-1"><a class="header-anchor" href="#_2-prepare-dataset-code-details" aria-hidden="true">#</a> 2. Prepare Dataset Code Details</h2><h3 id="_2-1-sfttrainer-init" tabindex="-1"><a class="header-anchor" href="#_2-1-sfttrainer-init" aria-hidden="true">#</a> 2.1. SFTTrainer.<strong>init</strong></h3><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">SFTTrainer</span><span class="token punctuation">(</span>Trainer<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">&quot;&quot;&quot;
    Trainer for Supervised Fine-Tuning (SFT) method.
    &quot;&quot;&quot;</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># Handle the tokenizer</span>
        <span class="token keyword">if</span> processing_class <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            processing_class <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_id<span class="token punctuation">)</span>
        
        <span class="token comment"># Data collator</span>
        <span class="token keyword">if</span> data_collator <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            <span class="token comment"># Get the pad token: if not provided, use the one from the processing class or the eos token</span>
            <span class="token comment"># if the processing class does not have a pad token.</span>
            pad_token <span class="token operator">=</span> args<span class="token punctuation">.</span>pad_token <span class="token keyword">or</span> processing_class<span class="token punctuation">.</span>pad_token <span class="token keyword">or</span> processing_class<span class="token punctuation">.</span>eos_token
            pad_token_id <span class="token operator">=</span> processing_class<span class="token punctuation">.</span>convert_tokens_to_ids<span class="token punctuation">(</span>pad_token<span class="token punctuation">)</span>
            <span class="token keyword">if</span> pad_token_id <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
                <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span>
                    <span class="token string-interpolation"><span class="token string">f&quot;The specified pad_token (&#39;</span><span class="token interpolation"><span class="token punctuation">{</span>pad_token<span class="token punctuation">}</span></span><span class="token string">&#39;) is not found in the vocabulary of the given &quot;</span></span>
                    <span class="token string-interpolation"><span class="token string">f&quot;processing_class (</span><span class="token interpolation"><span class="token punctuation">{</span>processing_class<span class="token punctuation">.</span>__class__<span class="token punctuation">.</span>__name__<span class="token punctuation">}</span></span><span class="token string">). Ensure that the pad_token exists &quot;</span></span>
                    <span class="token string">&quot;in the vocabulary before using it as a padding token.&quot;</span>
                <span class="token punctuation">)</span>
            data_collator <span class="token operator">=</span> DataCollatorForLanguageModeling<span class="token punctuation">(</span>pad_token_id<span class="token punctuation">)</span>

        <span class="token comment"># Dataset</span>
        train_dataset <span class="token operator">=</span> self<span class="token punctuation">.</span>_prepare_dataset<span class="token punctuation">(</span>
                train_dataset<span class="token punctuation">,</span> processing_class<span class="token punctuation">,</span> args<span class="token punctuation">,</span> args<span class="token punctuation">.</span>packing<span class="token punctuation">,</span> formatting_func<span class="token punctuation">,</span> <span class="token string">&quot;train&quot;</span>
            <span class="token punctuation">)</span>
        <span class="token keyword">if</span> eval_dataset <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            packing <span class="token operator">=</span> args<span class="token punctuation">.</span>packing <span class="token keyword">if</span> args<span class="token punctuation">.</span>eval_packing <span class="token keyword">is</span> <span class="token boolean">None</span> <span class="token keyword">else</span> args<span class="token punctuation">.</span>eval_packing
            <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>eval_dataset<span class="token punctuation">,</span> <span class="token builtin">dict</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                eval_dataset <span class="token operator">=</span> <span class="token punctuation">{</span>
                    key<span class="token punctuation">:</span> self<span class="token punctuation">.</span>_prepare_dataset<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> processing_class<span class="token punctuation">,</span> args<span class="token punctuation">,</span> packing<span class="token punctuation">,</span> formatting_func<span class="token punctuation">,</span> key<span class="token punctuation">)</span>
                    <span class="token keyword">for</span> key<span class="token punctuation">,</span> dataset <span class="token keyword">in</span> eval_dataset<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span>
                <span class="token punctuation">}</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                eval_dataset <span class="token operator">=</span> self<span class="token punctuation">.</span>_prepare_dataset<span class="token punctuation">(</span>
                    eval_dataset<span class="token punctuation">,</span> processing_class<span class="token punctuation">,</span> args<span class="token punctuation">,</span> packing<span class="token punctuation">,</span> formatting_func<span class="token punctuation">,</span> <span class="token string">&quot;eval&quot;</span>
                <span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_2-2-datacollatorforlanguagemodeling" tabindex="-1"><a class="header-anchor" href="#_2-2-datacollatorforlanguagemodeling" aria-hidden="true">#</a> 2.2. DataCollatorForLanguageModeling</h3><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token decorator annotation punctuation">@dataclass</span>
<span class="token keyword">class</span> <span class="token class-name">DataCollatorForLanguageModeling</span><span class="token punctuation">(</span>DataCollatorMixin<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">&quot;&quot;&quot;
    Data collator used for language modeling data. Inputs are dynamically padded to the maximum length of a batch if
    they are not all of the same length.

    Args:
        pad_token_id (int):
            Token ID to use for padding.
        return_tensors (str, *optional*, defaults to &quot;pt&quot;):
            Type of Tensor to return. Only &quot;pt&quot; is currently supported.

    Examples:
    from trl import DataCollatorForLanguageModeling
    collator = DataCollatorForLanguageModeling(pad_token_id=0)
    examples = [
        {&quot;input_ids&quot;: [1, 2, 3]},
        {&quot;input_ids&quot;: [4, 5]}
    ]
    collator(examples)
    {&#39;input_ids&#39;: tensor([[   1,   2,   3],
                          [   4,   5,   0]]),
     &#39;attention_mask&#39;: tensor([[  1,   1,   1],
                               [  1,   1,   0]]),
     &#39;labels&#39;: tensor([[   1,    2,    3],
                       [   4,    5, -100]])
    &quot;&quot;&quot;</span>

    pad_token_id<span class="token punctuation">:</span> <span class="token builtin">int</span>
    return_tensors<span class="token punctuation">:</span> <span class="token builtin">str</span> <span class="token operator">=</span> <span class="token string">&quot;pt&quot;</span>

    <span class="token keyword">def</span> <span class="token function">torch_call</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> examples<span class="token punctuation">:</span> <span class="token builtin">list</span><span class="token punctuation">[</span>Union<span class="token punctuation">[</span><span class="token builtin">list</span><span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">]</span><span class="token punctuation">,</span> Any<span class="token punctuation">,</span> <span class="token builtin">dict</span><span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">,</span> Any<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">dict</span><span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">,</span> Any<span class="token punctuation">]</span><span class="token punctuation">:</span>
        <span class="token comment"># Convert to tensor</span>
        input_ids <span class="token operator">=</span> <span class="token punctuation">[</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>example<span class="token punctuation">[</span><span class="token string">&quot;input_ids&quot;</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">for</span> example <span class="token keyword">in</span> examples<span class="token punctuation">]</span>
        attention_mask <span class="token operator">=</span> <span class="token punctuation">[</span>torch<span class="token punctuation">.</span>ones_like<span class="token punctuation">(</span>input_ids<span class="token punctuation">)</span> <span class="token keyword">for</span> input_ids <span class="token keyword">in</span> input_ids<span class="token punctuation">]</span>
        labels <span class="token operator">=</span> <span class="token punctuation">[</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>example<span class="token punctuation">[</span><span class="token string">&quot;input_ids&quot;</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">for</span> example <span class="token keyword">in</span> examples<span class="token punctuation">]</span>

        <span class="token comment"># Pad</span>
        output <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
        output<span class="token punctuation">[</span><span class="token string">&quot;input_ids&quot;</span><span class="token punctuation">]</span> <span class="token operator">=</span> pad<span class="token punctuation">(</span>input_ids<span class="token punctuation">,</span> padding_value<span class="token operator">=</span>self<span class="token punctuation">.</span>pad_token_id<span class="token punctuation">,</span> padding_side<span class="token operator">=</span><span class="token string">&quot;right&quot;</span><span class="token punctuation">)</span>
        output<span class="token punctuation">[</span><span class="token string">&quot;attention_mask&quot;</span><span class="token punctuation">]</span> <span class="token operator">=</span> pad<span class="token punctuation">(</span>attention_mask<span class="token punctuation">,</span> padding_value<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> padding_side<span class="token operator">=</span><span class="token string">&quot;right&quot;</span><span class="token punctuation">)</span>
        output<span class="token punctuation">[</span><span class="token string">&quot;labels&quot;</span><span class="token punctuation">]</span> <span class="token operator">=</span> pad<span class="token punctuation">(</span>labels<span class="token punctuation">,</span> padding_value<span class="token operator">=</span><span class="token operator">-</span><span class="token number">100</span><span class="token punctuation">,</span> padding_side<span class="token operator">=</span><span class="token string">&quot;right&quot;</span><span class="token punctuation">)</span>

        <span class="token keyword">return</span> output
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_2-3-prepare-dataset" tabindex="-1"><a class="header-anchor" href="#_2-3-prepare-dataset" aria-hidden="true">#</a> 2.3. _prepare_dataset</h3><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">_prepare_dataset</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># If the dataset is already preprocessed (tokenized), skip the processing steps.</span>
    column_names <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">next</span><span class="token punctuation">(</span><span class="token builtin">iter</span><span class="token punctuation">(</span>dataset<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    is_processed <span class="token operator">=</span> <span class="token string">&quot;input_ids&quot;</span> <span class="token keyword">in</span> column_names

    <span class="token comment"># Apply the formatting function if any</span>
    <span class="token keyword">if</span> formatting_func <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span> <span class="token keyword">and</span> is_processed<span class="token punctuation">:</span>
        warnings<span class="token punctuation">.</span>warn<span class="token punctuation">(</span>
            <span class="token string">&quot;You passed a dataset that is already processed (contains an input_ids field) together with a &quot;</span>
            <span class="token string">&quot;formatting function. Therefore formatting_func will be ignored. Either remove the &quot;</span>
            <span class="token string">&quot;formatting_func or pass a dataset that is not already processed.&quot;</span><span class="token punctuation">,</span>
            UserWarning<span class="token punctuation">,</span>
        <span class="token punctuation">)</span>

    <span class="token keyword">if</span> formatting_func <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span> <span class="token keyword">and</span> <span class="token keyword">not</span> is_processed<span class="token punctuation">:</span>
        <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># IterableDataset.map does not support desc</span>
            map_kwargs<span class="token punctuation">[</span><span class="token string">&quot;desc&quot;</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string-interpolation"><span class="token string">f&quot;Applying formatting function to </span><span class="token interpolation"><span class="token punctuation">{</span>dataset_name<span class="token punctuation">}</span></span><span class="token string"> dataset&quot;</span></span>

        batched <span class="token operator">=</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>formatting_func<span class="token punctuation">(</span><span class="token builtin">next</span><span class="token punctuation">(</span><span class="token builtin">iter</span><span class="token punctuation">(</span>dataset<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">list</span><span class="token punctuation">)</span>

        <span class="token keyword">def</span> <span class="token function">_func</span><span class="token punctuation">(</span>example<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">return</span> <span class="token punctuation">{</span><span class="token string">&quot;text&quot;</span><span class="token punctuation">:</span> formatting_func<span class="token punctuation">(</span>example<span class="token punctuation">)</span><span class="token punctuation">}</span>

        dataset <span class="token operator">=</span> dataset<span class="token punctuation">.</span><span class="token builtin">map</span><span class="token punctuation">(</span>_func<span class="token punctuation">,</span> batched<span class="token operator">=</span>batched<span class="token punctuation">,</span> <span class="token operator">**</span>map_kwargs<span class="token punctuation">)</span>

    <span class="token comment"># If the dataset is prompt-completion, convert it to language modeling type</span>
    first_example <span class="token operator">=</span> <span class="token builtin">next</span><span class="token punctuation">(</span><span class="token builtin">iter</span><span class="token punctuation">(</span>dataset<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">if</span> <span class="token string">&quot;prompt&quot;</span> <span class="token keyword">in</span> first_example<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">and</span> <span class="token string">&quot;completion&quot;</span> <span class="token keyword">in</span> first_example<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        key <span class="token operator">=</span> <span class="token string">&quot;messages&quot;</span> <span class="token keyword">if</span> is_conversational<span class="token punctuation">(</span>first_example<span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">&quot;text&quot;</span>

        <span class="token keyword">def</span> <span class="token function">concat_prompt_completion</span><span class="token punctuation">(</span>example<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">return</span> <span class="token punctuation">{</span>key<span class="token punctuation">:</span> example<span class="token punctuation">[</span><span class="token string">&quot;prompt&quot;</span><span class="token punctuation">]</span> <span class="token operator">+</span> example<span class="token punctuation">[</span><span class="token string">&quot;completion&quot;</span><span class="token punctuation">]</span><span class="token punctuation">}</span>

        dataset <span class="token operator">=</span> dataset<span class="token punctuation">.</span><span class="token builtin">map</span><span class="token punctuation">(</span>concat_prompt_completion<span class="token punctuation">,</span> remove_columns<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">&quot;prompt&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;completion&quot;</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

    <span class="token keyword">if</span> <span class="token keyword">not</span> is_processed<span class="token punctuation">:</span>
        <span class="token comment"># Convert the dataset to ChatML if needed</span>
        <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># IterableDataset.map does not support desc</span>
            map_kwargs<span class="token punctuation">[</span><span class="token string">&quot;desc&quot;</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string-interpolation"><span class="token string">f&quot;Converting </span><span class="token interpolation"><span class="token punctuation">{</span>dataset_name<span class="token punctuation">}</span></span><span class="token string"> dataset to ChatML&quot;</span></span>
        column_names <span class="token operator">=</span> <span class="token builtin">next</span><span class="token punctuation">(</span><span class="token builtin">iter</span><span class="token punctuation">(</span>dataset<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span>
        dataset <span class="token operator">=</span> dataset<span class="token punctuation">.</span><span class="token builtin">map</span><span class="token punctuation">(</span>
            maybe_convert_to_chatml<span class="token punctuation">,</span>
            remove_columns<span class="token operator">=</span><span class="token string">&quot;conversations&quot;</span> <span class="token keyword">if</span> <span class="token string">&quot;conversations&quot;</span> <span class="token keyword">in</span> column_names <span class="token keyword">else</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
            <span class="token operator">**</span>map_kwargs<span class="token punctuation">,</span>
        <span class="token punctuation">)</span>

        <span class="token comment"># Apply the chat template if needed</span>
        <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># IterableDataset.map does not support desc</span>
            map_kwargs<span class="token punctuation">[</span><span class="token string">&quot;desc&quot;</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string-interpolation"><span class="token string">f&quot;Applying chat template to </span><span class="token interpolation"><span class="token punctuation">{</span>dataset_name<span class="token punctuation">}</span></span><span class="token string"> dataset&quot;</span></span>
        column_names <span class="token operator">=</span> <span class="token builtin">next</span><span class="token punctuation">(</span><span class="token builtin">iter</span><span class="token punctuation">(</span>dataset<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span>
        dataset <span class="token operator">=</span> dataset<span class="token punctuation">.</span><span class="token builtin">map</span><span class="token punctuation">(</span>
            maybe_apply_chat_template<span class="token punctuation">,</span>
            fn_kwargs<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">&quot;tokenizer&quot;</span><span class="token punctuation">:</span> processing_class<span class="token punctuation">}</span><span class="token punctuation">,</span>
            remove_columns<span class="token operator">=</span><span class="token string">&quot;messages&quot;</span> <span class="token keyword">if</span> <span class="token string">&quot;messages&quot;</span> <span class="token keyword">in</span> column_names <span class="token keyword">else</span> <span class="token boolean">None</span><span class="token punctuation">,</span>  <span class="token comment"># renamed to &quot;text&quot;</span>
            <span class="token operator">**</span>map_kwargs<span class="token punctuation">,</span>
        <span class="token punctuation">)</span>

        <span class="token comment"># Tokenize the dataset if needed</span>
        <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># IterableDataset.map does not support desc</span>
            map_kwargs<span class="token punctuation">[</span><span class="token string">&quot;desc&quot;</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string-interpolation"><span class="token string">f&quot;Tokenizing </span><span class="token interpolation"><span class="token punctuation">{</span>dataset_name<span class="token punctuation">}</span></span><span class="token string"> dataset&quot;</span></span>

        <span class="token keyword">def</span> <span class="token function">tokenize</span><span class="token punctuation">(</span>example<span class="token punctuation">,</span> processing_class<span class="token punctuation">,</span> dataset_text_field<span class="token punctuation">)</span><span class="token punctuation">:</span>
            processed <span class="token operator">=</span> processing_class<span class="token punctuation">(</span>text<span class="token operator">=</span>example<span class="token punctuation">[</span>dataset_text_field<span class="token punctuation">]</span><span class="token punctuation">)</span>
            <span class="token keyword">if</span> <span class="token punctuation">(</span>
                processing_class<span class="token punctuation">.</span>eos_token_id <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span>
                <span class="token keyword">and</span> processed<span class="token punctuation">[</span><span class="token string">&quot;input_ids&quot;</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">!=</span> processing_class<span class="token punctuation">.</span>eos_token_id
            <span class="token punctuation">)</span><span class="token punctuation">:</span>
                processed<span class="token punctuation">[</span><span class="token string">&quot;input_ids&quot;</span><span class="token punctuation">]</span> <span class="token operator">=</span> processed<span class="token punctuation">[</span><span class="token string">&quot;input_ids&quot;</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token punctuation">[</span>processing_class<span class="token punctuation">.</span>eos_token_id<span class="token punctuation">]</span>
                processed<span class="token punctuation">[</span><span class="token string">&quot;attention_mask&quot;</span><span class="token punctuation">]</span> <span class="token operator">=</span> processed<span class="token punctuation">[</span><span class="token string">&quot;attention_mask&quot;</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
            <span class="token keyword">return</span> processed

        dataset <span class="token operator">=</span> dataset<span class="token punctuation">.</span><span class="token builtin">map</span><span class="token punctuation">(</span>
            tokenize<span class="token punctuation">,</span>
            fn_kwargs<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">&quot;processing_class&quot;</span><span class="token punctuation">:</span> processing_class<span class="token punctuation">,</span> <span class="token string">&quot;dataset_text_field&quot;</span><span class="token punctuation">:</span> args<span class="token punctuation">.</span>dataset_text_field<span class="token punctuation">}</span><span class="token punctuation">,</span>
            <span class="token operator">**</span>map_kwargs<span class="token punctuation">,</span>
        <span class="token punctuation">)</span>
    
    <span class="token keyword">return</span> dataset
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,9);function r(d,k){return t(),e("div",null,[c,l,p(" more "),u])}const b=a(i,[["render",r],["__file","033_sft_trainer_sourcecode_prepare_dataset.html.vue"]]);export{b as default};
