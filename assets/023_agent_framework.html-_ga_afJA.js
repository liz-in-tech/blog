import{_ as s}from"./plugin-vue_export-helper-x3n3nnut.js";import{r as o,o as l,c as r,f as d,a,b as e,d as i,e as t}from"./app-cafaW3Tc.js";const c={},p=a("h1",{id:"langchain-and-llamaindex-integration",tabindex:"-1"},[a("a",{class:"header-anchor",href:"#langchain-and-llamaindex-integration","aria-hidden":"true"},"#"),e(" Langchain and LlamaIndex Integration")],-1),u=t(`<h2 id="_1-individual-advantages" tabindex="-1"><a class="header-anchor" href="#_1-individual-advantages" aria-hidden="true">#</a> 1. Individual Advantages</h2><ul><li><p>LangChain Features</p><ul><li>Generality and High Modularity: LangChain is a highly modular and extensible framework suitable for building various types of applications. It provides tools for loading, processing, and indexing data and can interact with LLMs.</li><li>Strong Customization Capability: LangChain allows developers to customize the behavior of applications, making it suitable for flexible and scalable general-purpose applications.</li><li>Complex Workflow and Context Management: LangChain is suitable for handling complex workflows and context management, especially for building intelligent agents capable of performing multiple tasks simultaneously.</li><li>Tool Integration: LangChain offers a rich set of components and ready-made chains, making it easy for developers to customize existing chains or build new ones, suitable for applications that need to integrate multiple tools.</li></ul></li><li><p>LlamaIndex Features</p><ul><li>Designed for Search and Retrieval: LlamaIndex is designed for building search and retrieval applications, providing a simple interface to query LLMs and retrieve relevant documents.</li><li>Efficient Data Processing: LlamaIndex performs well when handling large amounts of data, suitable for applications that require efficient indexing and retrieval.</li><li>Data Connectivity and Integration: LlamaIndex offers rich data connectors, allowing easy integration with various data sources (such as APIs, PDFs, SQL databases) and optimizing the data ingestion process.</li><li>Deep Indexing and Retrieval: LlamaIndex excels in deep indexing and retrieval with LLMs, suitable for scenarios that require in-depth data exploration.</li></ul></li></ul><h2 id="_2-llamahub" tabindex="-1"><a class="header-anchor" href="#_2-llamahub" aria-hidden="true">#</a> 2. LlamaHub</h2><p>https://llamahub.ai/</p><ul><li>Community-Driven: LlamaHub is maintained by an active developer community, with new loaders, tools, and packages constantly being added.</li><li>Easy Integration: Designed to integrate easily with popular frameworks like LlamaIndex and LangChain, simplifying the development process.</li><li>Versatile Tools: Provides a comprehensive set of tools from data loading to complex data processing, supporting various data sources and third-party services.</li><li>Open Source and Extensible: Fully open source, encouraging community contributions, and easy to extend and customize according to specific needs.</li></ul><h2 id="_3-best-practices" tabindex="-1"><a class="header-anchor" href="#_3-best-practices" aria-hidden="true">#</a> 3. Best Practices</h2><p>LangChain Use Cases: Integrating multiple tools, performing multitasking, broader functionality, building flexible and scalable general-purpose applications, scenarios where only LLM is needed without RAG.</p><p>LlamaIndex Use Cases: Professional and efficient intelligent indexing and retrieval, easier use of plugins and data connectors to acquire data, in-depth data exploration, building efficient and simple search and retrieval applications.</p><p>LlamaIndex can be integrated into LangChain to improve and optimize LangChain&#39;s retrieval capabilities. LangChain handles complex workflows and context management, while LlamaIndex handles efficient data retrieval, leveraging their respective strengths.</p><p>LangChain and LlamaIndex Integration Use Cases: Scenarios where agents combine with RAG, building applications that need to handle complex logic and efficient data retrieval simultaneously.</p><h2 id="_4-how-to-integrate" tabindex="-1"><a class="header-anchor" href="#_4-how-to-integrate" aria-hidden="true">#</a> 4. How to Integrate</h2><h3 id="_4-1-method-1-llamaindex-as-a-tool-in-langchain-agent" tabindex="-1"><a class="header-anchor" href="#_4-1-method-1-llamaindex-as-a-tool-in-langchain-agent" aria-hidden="true">#</a> 4.1. Method 1: LlamaIndex as a Tool in LangChain Agent</h3><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> llama_index<span class="token punctuation">.</span>core<span class="token punctuation">.</span>langchain_helpers<span class="token punctuation">.</span>agents <span class="token keyword">import</span> <span class="token punctuation">(</span>
    IndexToolConfig<span class="token punctuation">,</span>
    LlamaIndexTool<span class="token punctuation">,</span>
<span class="token punctuation">)</span>

tool_config <span class="token operator">=</span> IndexToolConfig<span class="token punctuation">(</span>
    query_engine<span class="token operator">=</span>query_engine<span class="token punctuation">,</span>
    name<span class="token operator">=</span><span class="token string-interpolation"><span class="token string">f&quot;Vector Index&quot;</span></span><span class="token punctuation">,</span>
    description<span class="token operator">=</span><span class="token string-interpolation"><span class="token string">f&quot;useful for when you want to answer queries about X&quot;</span></span><span class="token punctuation">,</span>
    tool_kwargs<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">&quot;return_direct&quot;</span><span class="token punctuation">:</span> <span class="token boolean">True</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>

tool <span class="token operator">=</span> LlamaIndexTool<span class="token punctuation">.</span>from_tool_config<span class="token punctuation">(</span>tool_config<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_4-2-method-2-llamaindex-as-a-retriever-in-langchain-agent" tabindex="-1"><a class="header-anchor" href="#_4-2-method-2-llamaindex-as-a-retriever-in-langchain-agent" aria-hidden="true">#</a> 4.2. Method 2: LlamaIndex as a Retriever in LangChain Agent</h3>`,14),m={href:"https://python.langchain.com/api_reference/community/retrievers/langchain_community.retrievers.llama_index.LlamaIndexRetriever.html",target:"_blank",rel:"noopener noreferrer"},h=a("div",{class:"language-text line-numbers-mode","data-ext":"text"},[a("pre",{class:"language-text"},[a("code",null,`from langchain_community.retrievers.llama_index import LlamaIndexRetriever
`)]),a("div",{class:"line-numbers","aria-hidden":"true"},[a("div",{class:"line-number"})])],-1),g={href:"https://python.langchain.com/api_reference/community/retrievers/langchain_community.retrievers.llama_index.LlamaIndexGraphRetriever.html",target:"_blank",rel:"noopener noreferrer"},v=t(`<div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>from langchain_community.retrievers.llama_index import LlamaIndexGraphRetriever
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><h3 id="_4-3-method-3-llamaindex-as-a-memory-module-in-langchain-agent" tabindex="-1"><a class="header-anchor" href="#_4-3-method-3-llamaindex-as-a-memory-module-in-langchain-agent" aria-hidden="true">#</a> 4.3. Method 3: LlamaIndex as a Memory Module in LangChain Agent</h3><h2 id="_5-reference-documentation" tabindex="-1"><a class="header-anchor" href="#_5-reference-documentation" aria-hidden="true">#</a> 5. Reference Documentation</h2><p>LlamaIndex Documentation: https://docs.llamaindex.ai/en/v0.10.18/community/integrations/using_with_langchain.html</p><p>LangChain Documentation: https://python.langchain.com/docs/integrations/providers/llama_index/</p><p>https://aimarketplace.co/llamaindex-and-langchain-integration</p>`,6);function f(x,b){const n=o("ExternalLinkIcon");return l(),r("div",null,[p,d(" more "),u,a("p",null,[a("a",m,[e("LlamaIndexRetriever"),i(n)])]),h,a("p",null,[a("a",g,[e("LlamaIndexGraphRetriever"),i(n)])]),v])}const L=s(c,[["render",f],["__file","023_agent_framework.html.vue"]]);export{L as default};
