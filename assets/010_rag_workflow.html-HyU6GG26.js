import{_ as e,a as t}from"./010_rag_qa_process-OQhWWnJZ.js";import{_ as l}from"./plugin-vue_export-helper-x3n3nnut.js";import{o as a,c as o,f as r,e as i}from"./app-YkV2VZ8k.js";const s={},n=i('<h1 id="rag-workflow" tabindex="-1"><a class="header-anchor" href="#rag-workflow" aria-hidden="true">#</a> RAG Workflow</h1><ul><li><ol><li>Raw Data Processing Flow</li></ol></li><li><ol start="2"><li>RAG Process in Q&amp;A Scenarios</li></ol></li><li><ol start="3"><li>RAG Optimization Points</li></ol></li><li><ol start="4"><li>Prompts in RAG Scenarios</li></ol></li><li><ol start="5"><li>Text Segmentation Methods</li></ol></li></ul>',2),c=i('<h2 id="_1-raw-data-processing-flow" tabindex="-1"><a class="header-anchor" href="#_1-raw-data-processing-flow" aria-hidden="true">#</a> 1. Raw Data Processing Flow</h2><figure><img src="'+e+'" alt="alt text" tabindex="0" loading="lazy"><figcaption>alt text</figcaption></figure><ul><li>Raw Data</li><li>Data Loader</li><li>Data Transformer(Data Cleaning)</li><li>Data Split <ul><li>Split into multiple Chunks</li><li>Balance in chunk size</li></ul></li><li>Data Vectorization <ul><li>Represent each Chunk as a Vector</li><li>Text Embedding Model</li></ul></li><li>Data Vector Store</li><li>Data Retriever</li></ul><h2 id="_2-rag-process-in-q-a-scenarios" tabindex="-1"><a class="header-anchor" href="#_2-rag-process-in-q-a-scenarios" aria-hidden="true">#</a> 2. RAG Process in Q&amp;A Scenarios</h2><figure><img src="'+t+'" alt="alt text" tabindex="0" loading="lazy"><figcaption>alt text</figcaption></figure><ul><li><ol><li>User initiates a question Query</li></ol></li><li><ol start="2"><li>The userâ€™s question Query is vectorized using an Embedding Model</li></ol></li><li><ol start="3"><li>Obtain the vectorized user question as a Query Vector</li></ol></li><li><ol start="4"><li>Retrieve from the Vector Database using the Query Vector</li></ol><ul><li>Use of vector databases as external knowledge bases</li></ul></li><li><ol start="5"><li>Retrieve the Top K vectors based on semantic similarity</li></ol></li><li><ol start="6"><li>Use the semantic content of the Top K vectors along with the user Query as a Prompt to the LLM</li></ol></li><li><ol start="7"><li>LLM generates an answer based on the user&#39;s query and the retrieved data</li></ol></li><li><ol start="8"><li>User receives the answer</li></ol></li></ul><h2 id="_3-rag-optimization-points" tabindex="-1"><a class="header-anchor" href="#_3-rag-optimization-points" aria-hidden="true">#</a> 3. RAG Optimization Points</h2><ul><li>For step2 <ul><li>When vectorizing the Query, consider if it requires processing -&gt; Refined Query</li></ul></li><li>For step5 <ul><li>Separate Recall and Ranking processes</li><li>Recall (e.g., recall 50 relevant data points from the vector database) =&gt; Ranking (e.g., rank the 50 recalled data points and select the top 3)</li></ul></li></ul><h2 id="_4-prompts-in-rag-scenarios" tabindex="-1"><a class="header-anchor" href="#_4-prompts-in-rag-scenarios" aria-hidden="true">#</a> 4. Prompts in RAG Scenarios</h2><ul><li>Instruction</li><li>Context =&gt; Retrieval</li><li>Input =&gt; Query</li><li>History</li></ul><h2 id="_5-text-segmentation-methods" tabindex="-1"><a class="header-anchor" href="#_5-text-segmentation-methods" aria-hidden="true">#</a> 5. Text Segmentation Methods</h2><ul><li>Purpose <ul><li>Enable retrieval of content more relevant to the Query</li></ul></li><li>Methods <ul><li>Split by sentences</li><li>Fixed window character count</li><li>Moving window character count</li><li>Recursive method: RecursiveCharacterTextSplitter (fixed window + semantic segmentation; used by LangChain; commonly applied)</li><li>Split by semantics (more complex to implement; may result in chunks that are too long or too short)</li></ul></li></ul>',12);function d(h,u){return a(),o("div",null,[n,r(" more "),c])}const f=l(s,[["render",d],["__file","010_rag_workflow.html.vue"]]);export{f as default};
