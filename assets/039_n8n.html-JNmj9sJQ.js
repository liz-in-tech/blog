import{_ as i,a as t,b as a,c as n,d as o,e as l,f as r}from"./039_executions-VcnBxRVY.js";import{_ as s}from"./plugin-vue_export-helper-x3n3nnut.js";import{o as c,c as d,f as h,a as e,b as u,e as g}from"./app-7NDGA8r0.js";const p={},f=e("h1",{id:"using-n8n-to-build-a-telegram-personal-assistant",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#using-n8n-to-build-a-telegram-personal-assistant","aria-hidden":"true"},"#"),u(" Using n8n to Build a Telegram Personal Assistant")],-1),m=e("ul",null,[e("li",null,"What is n8n and How to Use n8n"),e("li",null,"Creating a Telegram Bot"),e("li",null,"Setting Up Telegram Trigger in n8n"),e("li",null,"Complete Workflow")],-1),b=g('<h2 id="_1-preview" tabindex="-1"><a class="header-anchor" href="#_1-preview" aria-hidden="true">#</a> 1. Preview</h2><p>With this setup, users can interact with a Telegram bot conversationally using text, voice, or images.</p><ul><li>Messages sent to the Telegram bot trigger an n8n workflow.</li><li>n8n processes the input and sends the result back to Telegram.</li><li>The user receives the bot’s response seamlessly.</li></ul><figure><img src="'+i+`" alt="n8n-assisstant" tabindex="0" loading="lazy"><figcaption>n8n-assisstant</figcaption></figure><h2 id="_2-what-is-n8n" tabindex="-1"><a class="header-anchor" href="#_2-what-is-n8n" aria-hidden="true">#</a> 2. What is n8n?</h2><p>n8n is a powerful open-source, low-code workflow automation tool that enables users to seamlessly connect and automate tasks across various apps and services. Its intuitive visual interface lets you create workflows by linking &quot;nodes&quot; (representing apps or actions) to streamline processes like data transfers, notifications, and task scheduling.</p><p>Official Website: https://n8n.io/</p><p>GitHub: https://github.com/n8n-io/n8n</p><h2 id="_3-how-to-use-n8n" tabindex="-1"><a class="header-anchor" href="#_3-how-to-use-n8n" aria-hidden="true">#</a> 3. How to Use n8n</h2><p>There are three main ways to deploy n8n:</p><ol><li>Official cloud platform</li><li>Self-hosted locally via Docker</li><li>Deploy on your own cloud server</li></ol><p>Here, I use the official cloud platform for simplicity.</p><h3 id="_3-1-option-1-official-cloud-platform" tabindex="-1"><a class="header-anchor" href="#_3-1-option-1-official-cloud-platform" aria-hidden="true">#</a> 3.1. Option 1: Official Cloud Platform</h3><p>Click <strong>“Get Started for free”</strong> on the official site.</p><ul><li><strong>Pros</strong><ul><li>14-day free trial</li><li>Stable and hassle-free</li></ul></li><li><strong>Cons</strong><ul><li>Requires payment after 14 days</li><li>No access to community nodes</li></ul></li></ul><h3 id="_3-2-option-2-self-hosted-locally-via-docker" tabindex="-1"><a class="header-anchor" href="#_3-2-option-2-self-hosted-locally-via-docker" aria-hidden="true">#</a> 3.2. Option 2: Self-hosted locally via Docker</h3><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token function">docker</span> volume create n8n_data

<span class="token function">docker</span> run <span class="token parameter variable">-it</span> <span class="token parameter variable">--rm</span> <span class="token punctuation">\\</span>
 <span class="token parameter variable">--name</span> n8n <span class="token punctuation">\\</span>
 <span class="token parameter variable">-p</span> <span class="token number">5678</span>:5678 <span class="token punctuation">\\</span>
 <span class="token parameter variable">-e</span> <span class="token assign-left variable">N8N_RUNNERS_ENABLED</span><span class="token operator">=</span>true <span class="token punctuation">\\</span>
 <span class="token parameter variable">-v</span> n8n_data:/home/node/.n8n <span class="token punctuation">\\</span>
 docker.n8n.io/n8nio/n8n
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>Then open: http://localhost:5678</p><p>Connecting n8n to Ollama (for local LLMs):</p><p>If n8n runs inside Docker, replace <code>localhost</code> with <code>host.docker.internal</code> in the Ollama node configuration:</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>http://host.docker.internal:11434
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><ul><li><strong>Pros</strong><ul><li>Completely free with Ollama integration</li><li>Supports community nodes</li></ul></li><li><strong>Cons</strong><ul><li>Using webhooks or connecting to external apps can be challenging, requiring public network exposure.</li><li>Consumes local computer resources during operation, stops when the computer is shut down, and requires restarting the Docker container each time the computer is powered on.</li></ul></li></ul><h3 id="_3-3-option-3-deploy-on-a-cloud-server" tabindex="-1"><a class="header-anchor" href="#_3-3-option-3-deploy-on-a-cloud-server" aria-hidden="true">#</a> 3.3. Option 3: Deploy on a Cloud Server</h3><ul><li><strong>Pros</strong><ul><li>Always online (24/7 uptime)</li><li>Cheaper than the official cloud option</li></ul></li><li><strong>Cons</strong><ul><li>Less stable than official hosting</li><li>Setup may be tricky for non-technical users</li></ul></li></ul><h2 id="_4-creating-a-telegram-bot" tabindex="-1"><a class="header-anchor" href="#_4-creating-a-telegram-bot" aria-hidden="true">#</a> 4. Creating a Telegram Bot</h2><ul><li>Search for <code>BotFather</code> in the Telegram search bar</li></ul><figure><img src="`+t+'" alt="Search for BotFather" tabindex="0" loading="lazy"><figcaption>Search for BotFather</figcaption></figure><ul><li><p>Add <code>BotFather</code> to create a new bot</p></li><li><p>Chat with <code>BotFather</code> to set the name and username for your new bot</p></li></ul><figure><img src="'+a+'" alt="Chat with BotFather" tabindex="0" loading="lazy"><figcaption>Chat with BotFather</figcaption></figure><ul><li>You now have your own Telegram bot and its API token.</li></ul><h2 id="_5-setting-up-telegram-trigger-in-n8n" tabindex="-1"><a class="header-anchor" href="#_5-setting-up-telegram-trigger-in-n8n" aria-hidden="true">#</a> 5. Setting Up Telegram Trigger in n8n</h2><p>Common Trigger Types</p><ul><li><strong>Manual Trigger in the n8n UI</strong>: <ul><li>Start workflows by clicking &quot;Execute Workflow&quot; in n8n</li><li>Send chat messages directly within n8n to trigger workflows</li></ul></li><li><strong>Scheduled Trigger</strong>: Run workflows every day, hour, or custom interval</li><li><strong>Chat App Events</strong>: <ul><li>Telegram</li><li>WhatsApp</li><li>Slack</li><li>Discord</li></ul></li><li><strong>Other App Events</strong>: <ul><li>Trigger on receiving a new Gmail email</li><li>Trigger when a new page is added to a Notion database</li></ul></li><li><strong>Webhook Trigger</strong>: Activate workflows via external data sent to an n8n webhook URL (requires public network access).</li></ul><p>Here, I use Telegram Trigger as the entry point.</p><h2 id="_6-routing-with-the-switch-node" tabindex="-1"><a class="header-anchor" href="#_6-routing-with-the-switch-node" aria-hidden="true">#</a> 6. Routing with the Switch Node</h2><p>Parameters Settings</p><ul><li>Mode: choosing <code>Rules</code></li><li>Routing Rules <ul><li>Drag the relevant fields directly to the Routing Rules section.</li><li>Set the matching condition to <code>String -&gt; Exists</code> to check for the presence of a specific string.</li><li>Define the Output Name for each branch.</li></ul></li></ul><figure><img src="'+n+'" alt="Switch Node" tabindex="0" loading="lazy"><figcaption>Switch Node</figcaption></figure><h2 id="_7-handling-different-branches" tabindex="-1"><a class="header-anchor" href="#_7-handling-different-branches" aria-hidden="true">#</a> 7. Handling Different Branches</h2><ul><li>Text Branch <ul><li>Extract the text message</li><li>Use it as the User Prompt</li><li>Combine with a System Prompt inside an AI Agent node</li><li>Send the generated response back to Telegram</li></ul></li><li>Voice Branch <ul><li>Receive the audio file from Telegram</li><li>Transcribe it into text using a multimodal model</li><li>Use the transcription as the User Prompt</li><li>Process with the AI Agent and send the response back to Telegram</li></ul></li><li>Image Branch <ul><li>Receive the uploaded image</li><li>Analyze it using a multimodal model</li><li>Send the analysis result back to Telegram</li></ul></li></ul><h2 id="_8-complete-workflow" tabindex="-1"><a class="header-anchor" href="#_8-complete-workflow" aria-hidden="true">#</a> 8. Complete Workflow</h2><figure><img src="'+o+'" alt="Complete Workflow" tabindex="0" loading="lazy"><figcaption>Complete Workflow</figcaption></figure><h2 id="_9-workflow-testing-and-refinement" tabindex="-1"><a class="header-anchor" href="#_9-workflow-testing-and-refinement" aria-hidden="true">#</a> 9. Workflow Testing and Refinement</h2><h3 id="_9-1-before-activation" tabindex="-1"><a class="header-anchor" href="#_9-1-before-activation" aria-hidden="true">#</a> 9.1. Before Activation</h3><ul><li><strong>Inactive State</strong>: When the workflow is &quot;Inactive&quot;, testing can only be performed by manually clicking the &quot;Execute Workflow&quot; button, located at the bottom or near the initial trigger node.</li><li><strong>Node Inspection</strong>: Each node displays its input and output results for review during testing.</li></ul><figure><img src="'+l+'" alt="Execute details" tabindex="0" loading="lazy"><figcaption>Execute details</figcaption></figure><h3 id="_9-2-after-activation" tabindex="-1"><a class="header-anchor" href="#_9-2-after-activation" aria-hidden="true">#</a> 9.2. After Activation</h3><ul><li><strong>Activating the Workflow</strong>: Once the workflow is fully built, switch its status to &quot;Active&quot;. Messages sent via Telegram will then automatically trigger the workflow.</li><li><strong>Execution Tracking</strong>: Every trigger is logged on the n8n platform. You can view details in the &quot;Executions&quot; section, including which branch was followed, whether the execution succeeded, and any errors. If a part fails, you can debug and troubleshoot to refine the workflow.</li></ul><figure><img src="'+r+'" alt="Executions" tabindex="0" loading="lazy"><figcaption>Executions</figcaption></figure><h2 id="_10-next-steps" tabindex="-1"><a class="header-anchor" href="#_10-next-steps" aria-hidden="true">#</a> 10. Next Steps</h2><ul><li>Add memory to keep track of conversation history</li><li>Add tools to extend functionality</li><li>Connect a knowledge base for richer external information</li><li>Explore other triggers and integrations to personalize your assistant</li></ul>',51);function w(v,k){return c(),d("div",null,[f,m,h(" more "),b])}const T=s(p,[["render",w],["__file","039_n8n.html.vue"]]);export{T as default};
