const e=JSON.parse('{"key":"v-200f326d","path":"/zh/posts/llm/031_qlora.html","title":"QLoRA 代码实现及过程分析","lang":"zh-CN","frontmatter":{"icon":"lightbulb","sidebar":false,"date":"2025-04-08T00:00:00.000Z","prev":"./032_sft_trainer_sourcecode_prepare_model","next":"./030_wandb","category":["LLM"],"tag":["QLoRA"],"description":"QLoRA 代码实现及过程分析 背景介绍: QLoRA/基础模型/数据集 QLoRA 代码实现 QLoRA 过程分析 QLoRA 应用价值 QLoRA 疑点思考 QLoRA 细节补充","head":[["link",{"rel":"alternate","hreflang":"en-us","href":"https://liz-in-tech.github.io/blog/posts/llm/031_qlora.html"}],["meta",{"property":"og:url","content":"https://liz-in-tech.github.io/blog/zh/posts/llm/031_qlora.html"}],["meta",{"property":"og:site_name","content":"Liz"}],["meta",{"property":"og:title","content":"QLoRA 代码实现及过程分析"}],["meta",{"property":"og:description","content":"QLoRA 代码实现及过程分析 背景介绍: QLoRA/基础模型/数据集 QLoRA 代码实现 QLoRA 过程分析 QLoRA 应用价值 QLoRA 疑点思考 QLoRA 细节补充"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:locale:alternate","content":"en-US"}],["meta",{"property":"og:updated_time","content":"2025-04-10T08:01:20.000Z"}],["meta",{"property":"article:author","content":"Liz"}],["meta",{"property":"article:tag","content":"QLoRA"}],["meta",{"property":"article:published_time","content":"2025-04-08T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2025-04-10T08:01:20.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"QLoRA 代码实现及过程分析\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2025-04-08T00:00:00.000Z\\",\\"dateModified\\":\\"2025-04-10T08:01:20.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Liz\\",\\"url\\":\\"https://github.com/liz-in-tech\\"}]}"]]},"headers":[{"level":2,"title":"1. 背景介绍: QLoRA/基础模型/数据集","slug":"_1-背景介绍-qlora-基础模型-数据集","link":"#_1-背景介绍-qlora-基础模型-数据集","children":[]},{"level":2,"title":"2. QLoRA 代码实现","slug":"_2-qlora-代码实现","link":"#_2-qlora-代码实现","children":[{"level":3,"title":"2.1. Load Model","slug":"_2-1-load-model","link":"#_2-1-load-model","children":[]},{"level":3,"title":"2.2. Preparing Dataset","slug":"_2-2-preparing-dataset","link":"#_2-2-preparing-dataset","children":[]},{"level":3,"title":"2.3. Fine-Tuning","slug":"_2-3-fine-tuning","link":"#_2-3-fine-tuning","children":[]},{"level":3,"title":"2.4. Save Trained Model","slug":"_2-4-save-trained-model","link":"#_2-4-save-trained-model","children":[]}]},{"level":2,"title":"3. QLoRA 过程分析","slug":"_3-qlora-过程分析","link":"#_3-qlora-过程分析","children":[{"level":3,"title":"3.1. 原始模型和量化模型的对比","slug":"_3-1-原始模型和量化模型的对比","link":"#_3-1-原始模型和量化模型的对比","children":[]},{"level":3,"title":"3.2. Dataset 处理流程","slug":"_3-2-dataset-处理流程","link":"#_3-2-dataset-处理流程","children":[]},{"level":3,"title":"3.3. 可训练参数量计算","slug":"_3-3-可训练参数量计算","link":"#_3-3-可训练参数量计算","children":[]}]},{"level":2,"title":"4. QLoRA 应用价值","slug":"_4-qlora-应用价值","link":"#_4-qlora-应用价值","children":[{"level":3,"title":"4.1. QLoRA 和全参数微调⽅法对比","slug":"_4-1-qlora-和全参数微调方法对比","link":"#_4-1-qlora-和全参数微调方法对比","children":[]},{"level":3,"title":"4.2. QLoRA 在该任务中的优势和潜在局限性","slug":"_4-2-qlora-在该任务中的优势和潜在局限性","link":"#_4-2-qlora-在该任务中的优势和潜在局限性","children":[]}]},{"level":2,"title":"5. QLoRA 疑点思考","slug":"_5-qlora-疑点思考","link":"#_5-qlora-疑点思考","children":[{"level":3,"title":"5.1. lora和qlora微调的方式是不是只有训练前的模型是否进行了量化这一区别？","slug":"_5-1-lora和qlora微调的方式是不是只有训练前的模型是否进行了量化这一区别","link":"#_5-1-lora和qlora微调的方式是不是只有训练前的模型是否进行了量化这一区别","children":[]},{"level":3,"title":"5.2. 为什么量化通常只用于线性层？","slug":"_5-2-为什么量化通常只用于线性层","link":"#_5-2-为什么量化通常只用于线性层","children":[]},{"level":3,"title":"5.3. 为什么不对 lm_head 层进行量化，这个也是线性层?","slug":"_5-3-为什么不对-lm-head-层进行量化-这个也是线性层","link":"#_5-3-为什么不对-lm-head-层进行量化-这个也是线性层","children":[]},{"level":3,"title":"5.4. 为什么非线性层在量化后的dtype也有变化，变为float16？","slug":"_5-4-为什么非线性层在量化后的dtype也有变化-变为float16","link":"#_5-4-为什么非线性层在量化后的dtype也有变化-变为float16","children":[]},{"level":3,"title":"5.5. 量化模型精度发生了什么变化?","slug":"_5-5-量化模型精度发生了什么变化","link":"#_5-5-量化模型精度发生了什么变化","children":[]},{"level":3,"title":"5.6. bnb_4bit_compute_dtype=torch.bfloat16是做什么的，计算精度和存储精度不同？","slug":"_5-6-bnb-4bit-compute-dtype-torch-bfloat16是做什么的-计算精度和存储精度不同","link":"#_5-6-bnb-4bit-compute-dtype-torch-bfloat16是做什么的-计算精度和存储精度不同","children":[]},{"level":3,"title":"5.7. 临时性量化与永久存储？","slug":"_5-7-临时性量化与永久存储","link":"#_5-7-临时性量化与永久存储","children":[]},{"level":3,"title":"5.8. qlora存储训练好的模型是按什么精度存储的？","slug":"_5-8-qlora存储训练好的模型是按什么精度存储的","link":"#_5-8-qlora存储训练好的模型是按什么精度存储的","children":[]}]},{"level":2,"title":"6. QLoRA 细节补充","slug":"_6-qlora-细节补充","link":"#_6-qlora-细节补充","children":[{"level":3,"title":"6.1. device_map","slug":"_6-1-device-map","link":"#_6-1-device-map","children":[]},{"level":3,"title":"6.2. seed=42 是常见“魔法数字”","slug":"_6-2-seed-42-是常见-魔法数字","link":"#_6-2-seed-42-是常见-魔法数字","children":[]}]},{"level":2,"title":"7. Reference","slug":"_7-reference","link":"#_7-reference","children":[]}],"git":{"createdTime":1744272080000,"updatedTime":1744272080000,"contributors":[{"name":"liz","email":"liz@MacBook-Pro-4.local","commits":1}]},"readingTime":{"minutes":15.77,"words":4731},"filePathRelative":"zh/posts/llm/031_qlora.md","localizedDate":"2025年4月8日","excerpt":"<h1> QLoRA 代码实现及过程分析</h1>\\n<ul>\\n<li>背景介绍: QLoRA/基础模型/数据集</li>\\n<li>QLoRA 代码实现</li>\\n<li>QLoRA 过程分析</li>\\n<li>QLoRA 应用价值</li>\\n<li>QLoRA 疑点思考</li>\\n<li>QLoRA 细节补充</li>\\n</ul>\\n","autoDesc":true}');export{e as data};
