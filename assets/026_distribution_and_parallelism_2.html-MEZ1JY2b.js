const e=JSON.parse('{"key":"v-fa82472a","path":"/posts/llm/026_distribution_and_parallelism_2.html","title":"Distributed Training Part 3: Data Parallelism","lang":"en-US","frontmatter":{"icon":"lightbulb","sidebar":false,"date":"2025-03-02T00:00:00.000Z","prev":"./027_distribution_and_parallelism_3","next":"./025_distribution_and_parallelism_1","category":["LLM"],"tag":["Distributed","Parallelism"],"description":"Distributed Training Part 3: Data Parallelism","head":[["link",{"rel":"alternate","hreflang":"zh-cn","href":"https://liz-in-tech.github.io/blog/zh/posts/llm/026_distribution_and_parallelism_2.html"}],["meta",{"property":"og:url","content":"https://liz-in-tech.github.io/blog/posts/llm/026_distribution_and_parallelism_2.html"}],["meta",{"property":"og:site_name","content":"Liz"}],["meta",{"property":"og:title","content":"Distributed Training Part 3: Data Parallelism"}],["meta",{"property":"og:description","content":"Distributed Training Part 3: Data Parallelism"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"en-US"}],["meta",{"property":"og:locale:alternate","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-03-08T14:32:06.000Z"}],["meta",{"property":"article:author","content":"Liz"}],["meta",{"property":"article:tag","content":"Distributed"}],["meta",{"property":"article:tag","content":"Parallelism"}],["meta",{"property":"article:published_time","content":"2025-03-02T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2025-03-08T14:32:06.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"Distributed Training Part 3: Data Parallelism\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2025-03-02T00:00:00.000Z\\",\\"dateModified\\":\\"2025-03-08T14:32:06.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Liz\\",\\"url\\":\\"https://github.com/liz-in-tech\\"}]}"]]},"headers":[{"level":2,"title":"1. Overview of Data Parallelism (DP)","slug":"_1-overview-of-data-parallelism-dp","link":"#_1-overview-of-data-parallelism-dp","children":[]},{"level":2,"title":"2. Data Parallelism (DP)","slug":"_2-data-parallelism-dp","link":"#_2-data-parallelism-dp","children":[{"level":3,"title":"2.1. Naive DP (naive DDP approach)","slug":"_2-1-naive-dp-naive-ddp-approach","link":"#_2-1-naive-dp-naive-ddp-approach","children":[]},{"level":3,"title":"2.2. DP Optimization","slug":"_2-2-dp-optimization","link":"#_2-2-dp-optimization","children":[]},{"level":3,"title":"2.3. DP Practice","slug":"_2-3-dp-practice","link":"#_2-3-dp-practice","children":[]},{"level":3,"title":"2.4. Performance with DP","slug":"_2-4-performance-with-dp","link":"#_2-4-performance-with-dp","children":[]}]},{"level":2,"title":"3. DeepSpeed ZeRO","slug":"_3-deepspeed-zero","link":"#_3-deepspeed-zero","children":[{"level":3,"title":"3.1. ZeRO","slug":"_3-1-zero","link":"#_3-1-zero","children":[]},{"level":3,"title":"3.2. Review of Mixed Precision Training","slug":"_3-2-review-of-mixed-precision-training","link":"#_3-2-review-of-mixed-precision-training","children":[]},{"level":3,"title":"3.3. ZeRO-1","slug":"_3-3-zero-1","link":"#_3-3-zero-1","children":[]},{"level":3,"title":"3.4. ZeRO-2","slug":"_3-4-zero-2","link":"#_3-4-zero-2","children":[]},{"level":3,"title":"3.5. ZeRO-3","slug":"_3-5-zero-3","link":"#_3-5-zero-3","children":[]}]},{"level":2,"title":"4. Extended Links","slug":"_4-extended-links","link":"#_4-extended-links","children":[]},{"level":2,"title":"5. Code Implementation","slug":"_5-code-implementation","link":"#_5-code-implementation","children":[{"level":3,"title":"5.1. Naive DP implementation with overlap in Picotron","slug":"_5-1-naive-dp-implementation-with-overlap-in-picotron","link":"#_5-1-naive-dp-implementation-with-overlap-in-picotron","children":[]},{"level":3,"title":"5.2. Bucket DP implementation in Picotron","slug":"_5-2-bucket-dp-implementation-in-picotron","link":"#_5-2-bucket-dp-implementation-in-picotron","children":[]}]}],"git":{"createdTime":1741444326000,"updatedTime":1741444326000,"contributors":[{"name":"liz","email":"liz@MacBook-Pro.local","commits":1}]},"readingTime":{"minutes":8.63,"words":2589},"filePathRelative":"posts/llm/026_distribution_and_parallelism_2.md","localizedDate":"March 2, 2025","excerpt":"<h1> Distributed Training Part 3: Data Parallelism</h1>\\n","autoDesc":true}');export{e as data};
