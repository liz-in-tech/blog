import{_ as s,a,b as t,c as e,d as p,e as o}from"./025_barrier-Cle6-zl5.js";import{_ as c}from"./plugin-vue_export-helper-x3n3nnut.js";import{o as i,c as l,f as u,a as n,b as r,e as d}from"./app-nSXwnGLr.js";const k={},v=n("h1",{id:"distributed-training-part-2-parallel-programming",tabindex:"-1"},[n("a",{class:"header-anchor",href:"#distributed-training-part-2-parallel-programming","aria-hidden":"true"},"#"),r(" Distributed Training Part 2: Parallel Programming")],-1),m=d('<h2 id="_1-overview" tabindex="-1"><a class="header-anchor" href="#_1-overview" aria-hidden="true">#</a> 1. Overview</h2><ul><li>Broadcast</li><li>Reduce</li><li>AllReduce</li><li>Gather</li><li>AllGather</li><li>Scatter</li><li>ReduceScatter</li><li>Barrier</li></ul><p>Note: The root node acts as a server, serving as the target or source for certain operations.</p><p>Relationship: AllReduce = ReduceScatter + AllGather</p><figure><img src="'+s+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h2 id="_2-broadcast" tabindex="-1"><a class="header-anchor" href="#_2-broadcast" aria-hidden="true">#</a> 2. Broadcast</h2><figure><img src="'+a+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h2 id="_3-reduce-allreduce" tabindex="-1"><a class="header-anchor" href="#_3-reduce-allreduce" aria-hidden="true">#</a> 3. Reduce &amp; AllReduce</h2><p>Combine values from each node using a function to produce a single value.</p><p>Common functions for f() are SUM or AVG.</p><ul><li>AVG is only available with the NCCL backend.</li></ul><figure><img src="'+t+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><ul><li>Reduce: The result is sent only to the root node.</li><li>AllReduce: The result is broadcast to every node (each node has the same value).</li></ul><h2 id="_4-gather-allgather" tabindex="-1"><a class="header-anchor" href="#_4-gather-allgather" aria-hidden="true">#</a> 4. Gather &amp; AllGather</h2><figure><img src="'+e+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h2 id="_5-scatter-reducescatter" tabindex="-1"><a class="header-anchor" href="#_5-scatter-reducescatter" aria-hidden="true">#</a> 5. Scatter &amp; ReduceScatter</h2><p><img src="'+p+'" alt="" loading="lazy"> Scatter</p><ul><li>Scatter differs from broadcast in that scatter sends data in pieces, while broadcast sends the entire data.</li><li>Scatter is logically the reverse operation of gather.</li></ul><p>ReduceScatter</p><ul><li>Split data on each node into pieces.</li><li>Perform Reduce on data from each piece across nodes using a function.</li><li>Scatter the result of each piece&#39;s Reduce to each node.</li></ul><h2 id="_6-barrier" tabindex="-1"><a class="header-anchor" href="#_6-barrier" aria-hidden="true">#</a> 6. Barrier</h2><p>A barrier will not be lifted until all nodes reach it. Once all nodes reach the barrier, subsequent computations can proceed, used for synchronizing nodes.</p><figure><img src="'+o+`" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h2 id="_7-pytorch-code-implementation" tabindex="-1"><a class="header-anchor" href="#_7-pytorch-code-implementation" aria-hidden="true">#</a> 7. PyTorch Code Implementation</h2><h3 id="_7-1-what-is-nccl" tabindex="-1"><a class="header-anchor" href="#_7-1-what-is-nccl" aria-hidden="true">#</a> 7.1. What is NCCL</h3><p>NCCL</p><ul><li>NVIDIA Collective Communications Library</li><li>Optimized primitives for communication between NVIDIA GPUs</li><li>Designed for efficient GPU-GPU communication</li></ul><h3 id="_7-2-broadcast" tabindex="-1"><a class="header-anchor" href="#_7-2-broadcast" aria-hidden="true">#</a> 7.2. Broadcast</h3><p>Code</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>distributed <span class="token keyword">as</span> dist

<span class="token keyword">def</span> <span class="token function">init_process</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    dist<span class="token punctuation">.</span>init_process_group<span class="token punctuation">(</span>backend<span class="token operator">=</span><span class="token string">&#39;nccl&#39;</span><span class="token punctuation">)</span>
    torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>set_device<span class="token punctuation">(</span>dist<span class="token punctuation">.</span>get_rank<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    
<span class="token keyword">def</span> <span class="token function">example_broadcast</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> dist<span class="token punctuation">.</span>get_rank<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
        tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;Before broadcast on rank </span><span class="token interpolation"><span class="token punctuation">{</span>dist<span class="token punctuation">.</span>get_rank<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">: </span><span class="token interpolation"><span class="token punctuation">{</span>tensor<span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span>
    dist<span class="token punctuation">.</span>broadcast<span class="token punctuation">(</span>tensor<span class="token punctuation">,</span> src<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;After broadcast on rank </span><span class="token interpolation"><span class="token punctuation">{</span>dist<span class="token punctuation">.</span>get_rank<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">: </span><span class="token interpolation"><span class="token punctuation">{</span>tensor<span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span>
    
init_process<span class="token punctuation">(</span><span class="token punctuation">)</span>
example_broadcast<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>Output</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>Before broadcast on rank 0: tensor([1., 2., 3., 4., 5.], device=&#39;cuda:0&#39;)
Before broadcast on rank 1: tensor([0., 0., 0., 0., 0.], device=&#39;cuda:1&#39;)
Before broadcast on rank 2: tensor([0., 0., 0., 0., 0.], device=&#39;cuda:2&#39;)

After broadcast on rank 0: tensor([1., 2., 3., 4., 5.], device=&#39;cuda:0&#39;)
After broadcast on rank 1: tensor([1., 2., 3., 4., 5.], device=&#39;cuda:1&#39;)
After broadcast on rank 2: tensor([1., 2., 3., 4., 5.], device=&#39;cuda:2&#39;)
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_7-3-reduce" tabindex="-1"><a class="header-anchor" href="#_7-3-reduce" aria-hidden="true">#</a> 7.3. Reduce</h3><p>Code</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">example_reduce</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span>dist<span class="token punctuation">.</span>get_rank<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token number">5</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;Before reduce on rank </span><span class="token interpolation"><span class="token punctuation">{</span>dist<span class="token punctuation">.</span>get_rank<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">: </span><span class="token interpolation"><span class="token punctuation">{</span>tensor<span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span>
    dist<span class="token punctuation">.</span><span class="token builtin">reduce</span><span class="token punctuation">(</span>tensor<span class="token punctuation">,</span> dst<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> op<span class="token operator">=</span>dist<span class="token punctuation">.</span>ReduceOp<span class="token punctuation">.</span>SUM<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;After reduce on rank </span><span class="token interpolation"><span class="token punctuation">{</span>rank<span class="token punctuation">}</span></span><span class="token string">: </span><span class="token interpolation"><span class="token punctuation">{</span>tensor<span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span>
    
init_process<span class="token punctuation">(</span><span class="token punctuation">)</span>
example_reduce<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>Output</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>Before reduce on rank 0: tensor([1., 1., 1., 1., 1.], device=&#39;cuda:0&#39;)
Before reduce on rank 1: tensor([2., 2., 2., 2., 2.], device=&#39;cuda:1&#39;)
Before reduce on rank 2: tensor([3., 3., 3., 3., 3.], device=&#39;cuda:2&#39;)

After reduce on rank 0: tensor([6., 6., 6., 6., 6.], device=&#39;cuda:0&#39;)
After reduce on rank 1: tensor([2., 2., 2., 2., 2.], device=&#39;cuda:1&#39;)
After reduce on rank 2: tensor([3., 3., 3., 3., 3.], device=&#39;cuda:2&#39;)
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_7-4-allreduce" tabindex="-1"><a class="header-anchor" href="#_7-4-allreduce" aria-hidden="true">#</a> 7.4. AllReduce</h3><p>Code</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">example_all_reduce</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span>dist<span class="token punctuation">.</span>get_rank<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token number">5</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;Before all_reduce on rank </span><span class="token interpolation"><span class="token punctuation">{</span>dist<span class="token punctuation">.</span>get_rank<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">: </span><span class="token interpolation"><span class="token punctuation">{</span>tensor<span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span>
    dist<span class="token punctuation">.</span>all_reduce<span class="token punctuation">(</span>tensor<span class="token punctuation">,</span> op<span class="token operator">=</span>dist<span class="token punctuation">.</span>ReduceOp<span class="token punctuation">.</span>SUM<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;After all_reduce on rank </span><span class="token interpolation"><span class="token punctuation">{</span>dist<span class="token punctuation">.</span>get_rank<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">: </span><span class="token interpolation"><span class="token punctuation">{</span>tensor<span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span>
    
init_process<span class="token punctuation">(</span><span class="token punctuation">)</span>
example_all_reduce<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>Output</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>Before all_reduce on rank 0: tensor([1., 1., 1., 1., 1.], device=&#39;cuda:0&#39;)
Before all_reduce on rank 1: tensor([2., 2., 2., 2., 2.], device=&#39;cuda:1&#39;)
Before all_reduce on rank 2: tensor([3., 3., 3., 3., 3.], device=&#39;cuda:2&#39;)

After all_reduce on rank 0: tensor([6., 6., 6., 6., 6.], device=&#39;cuda:0&#39;)
After all_reduce on rank 1: tensor([6., 6., 6., 6., 6.], device=&#39;cuda:1&#39;)
After all_reduce on rank 2: tensor([6., 6., 6., 6., 6.], device=&#39;cuda:2&#39;)
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_7-5-gather" tabindex="-1"><a class="header-anchor" href="#_7-5-gather" aria-hidden="true">#</a> 7.5. Gather</h3><p>Code</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">example_gather</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span>dist<span class="token punctuation">.</span>get_rank<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token number">5</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">if</span> dist<span class="token punctuation">.</span>get_rank<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
        gather_list <span class="token operator">=</span> <span class="token punctuation">[</span>
            torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
            <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>dist<span class="token punctuation">.</span>get_world_size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            <span class="token punctuation">]</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        gather_list <span class="token operator">=</span> <span class="token boolean">None</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;Before gather on rank </span><span class="token interpolation"><span class="token punctuation">{</span>dist<span class="token punctuation">.</span>get_rank<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">: </span><span class="token interpolation"><span class="token punctuation">{</span>tensor<span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span>
    dist<span class="token punctuation">.</span>gather<span class="token punctuation">(</span>tensor<span class="token punctuation">,</span> gather_list<span class="token punctuation">,</span> dst<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
    <span class="token keyword">if</span> dist<span class="token punctuation">.</span>get_rank<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;After gather on rank 0: </span><span class="token interpolation"><span class="token punctuation">{</span>gather_list<span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span>
    
init_process<span class="token punctuation">(</span><span class="token punctuation">)</span>
example_gather<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>Output</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>Before gather on rank 0: tensor([1., 1., 1., 1., 1.], device=&#39;cuda:0&#39;)
Before gather on rank 1: tensor([2., 2., 2., 2., 2.], device=&#39;cuda:1&#39;)
Before gather on rank 2: tensor([3., 3., 3., 3., 3.], device=&#39;cuda:2&#39;)

After gather on rank 0: [tensor([1., 1., 1., 1., 1.], device=&#39;cuda:0&#39;),
                         tensor([2., 2., 2., 2., 2.], device=&#39;cuda:0&#39;),
                         tensor([3., 3., 3., 3., 3.], device=&#39;cuda:0&#39;)]
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_7-6-allgather" tabindex="-1"><a class="header-anchor" href="#_7-6-allgather" aria-hidden="true">#</a> 7.6. AllGather</h3><p>Code</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">example_all_gather</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span>dist<span class="token punctuation">.</span>get_rank<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token number">5</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
    gather_list <span class="token operator">=</span> <span class="token punctuation">[</span>
        torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>dist<span class="token punctuation">.</span>get_world_size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token punctuation">]</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;Before all_gather on rank </span><span class="token interpolation"><span class="token punctuation">{</span>dist<span class="token punctuation">.</span>get_rank<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">: </span><span class="token interpolation"><span class="token punctuation">{</span>tensor<span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span>
    dist<span class="token punctuation">.</span>all_gather<span class="token punctuation">(</span>gather_list<span class="token punctuation">,</span> tensor<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;After all_gather on rank </span><span class="token interpolation"><span class="token punctuation">{</span>dist<span class="token punctuation">.</span>get_rank<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">: </span><span class="token interpolation"><span class="token punctuation">{</span>gather_list<span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span>
    
init_process<span class="token punctuation">(</span><span class="token punctuation">)</span>
example_all_gather<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>Output</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>Before all_gather on rank 0: tensor([1., 1., 1., 1., 1.], device=&#39;cuda:0&#39;)
Before all_gather on rank 1: tensor([2., 2., 2., 2., 2.], device=&#39;cuda:1&#39;)
Before all_gather on rank 2: tensor([3., 3., 3., 3., 3.], device=&#39;cuda:2&#39;)

After all_gather on rank 0: [tensor([1., 1., 1., 1., 1.], device=&#39;cuda:0&#39;),
                             tensor([2., 2., 2., 2., 2.], device=&#39;cuda:0&#39;),
                             tensor([3., 3., 3., 3., 3.], device=&#39;cuda:0&#39;)]
After all_gather on rank 1: [tensor([1., 1., 1., 1., 1.], device=&#39;cuda:1&#39;),
                             tensor([2., 2., 2., 2., 2.], device=&#39;cuda:0&#39;),
                             tensor([3., 3., 3., 3., 3.], device=&#39;cuda:0&#39;)]
After all_gather on rank 2: [tensor([1., 1., 1., 1., 1.], device=&#39;cuda:2&#39;),
                             tensor([2., 2., 2., 2., 2.], device=&#39;cuda:2&#39;),
                             tensor([3., 3., 3., 3., 3.], device=&#39;cuda:2&#39;)]
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_7-7-scatter" tabindex="-1"><a class="header-anchor" href="#_7-7-scatter" aria-hidden="true">#</a> 7.7. Scatter</h3><p>Code</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">example_scatter</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> dist<span class="token punctuation">.</span>get_rank<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
        scatter_list <span class="token operator">=</span> <span class="token punctuation">[</span>
            torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token number">5</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
            <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>dist<span class="token punctuation">.</span>get_world_size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            <span class="token punctuation">]</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;Rank 0: Tensor to scatter: </span><span class="token interpolation"><span class="token punctuation">{</span>scatter_list<span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        scatter_list <span class="token operator">=</span> <span class="token boolean">None</span>
    tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;Before scatter on rank </span><span class="token interpolation"><span class="token punctuation">{</span>dist<span class="token punctuation">.</span>get_rank<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">: </span><span class="token interpolation"><span class="token punctuation">{</span>tensor<span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span>
    dist<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>tensor<span class="token punctuation">,</span> scatter_list<span class="token punctuation">,</span> src<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;After scatter on rank </span><span class="token interpolation"><span class="token punctuation">{</span>dist<span class="token punctuation">.</span>get_rank<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">: </span><span class="token interpolation"><span class="token punctuation">{</span>tensor<span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span>
    
init_process<span class="token punctuation">(</span><span class="token punctuation">)</span>
example_scatter<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>Output</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>Rank 0: Tensor to scatter: [tensor([1., 1., 1., 1., 1.], device=&#39;cuda:0&#39;),
                            tensor([2., 2., 2., 2., 2.], device=&#39;cuda:0&#39;),
                            tensor([3., 3., 3., 3., 3.], device=&#39;cuda:0&#39;)]
Before scatter on rank 0: tensor([0., 0., 0., 0., 0.], device=&#39;cuda:0&#39;)
Before scatter on rank 1: tensor([0., 0., 0., 0., 0.], device=&#39;cuda:1&#39;)
Before scatter on rank 2: tensor([0., 0., 0., 0., 0.], device=&#39;cuda:2&#39;)

After scatter on rank 0: tensor([1., 1., 1., 1., 1.], device=&#39;cuda:0&#39;)
After scatter on rank 1: tensor([2., 2., 2., 2., 2.], device=&#39;cuda:1&#39;)
After scatter on rank 2: tensor([3., 3., 3., 3., 3.], device=&#39;cuda:2&#39;)
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_7-8-reducescatter" tabindex="-1"><a class="header-anchor" href="#_7-8-reducescatter" aria-hidden="true">#</a> 7.8. ReduceScatter</h3><p>Code</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">example_reduce_scatter</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    rank <span class="token operator">=</span> dist<span class="token punctuation">.</span>get_rank<span class="token punctuation">(</span><span class="token punctuation">)</span>
    world_size <span class="token operator">=</span> dist<span class="token punctuation">.</span>get_world_size<span class="token punctuation">(</span><span class="token punctuation">)</span>
    input_tensor <span class="token operator">=</span> <span class="token punctuation">[</span>
        torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">(</span>rank <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">*</span> i <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">**</span><span class="token punctuation">(</span>j<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span> 
        <span class="token keyword">for</span> j <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>world_size<span class="token punctuation">)</span>
        <span class="token punctuation">]</span>
    output_tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;Before ReduceScatter on rank </span><span class="token interpolation"><span class="token punctuation">{</span>rank<span class="token punctuation">}</span></span><span class="token string">: </span><span class="token interpolation"><span class="token punctuation">{</span>input_tensor<span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span>
    dist<span class="token punctuation">.</span>reduce_scatter<span class="token punctuation">(</span>output_tensor<span class="token punctuation">,</span> input_tensor<span class="token punctuation">,</span> op<span class="token operator">=</span>dist<span class="token punctuation">.</span>ReduceOp<span class="token punctuation">.</span>SUM<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;After ReduceScatter on rank </span><span class="token interpolation"><span class="token punctuation">{</span>rank<span class="token punctuation">}</span></span><span class="token string">: </span><span class="token interpolation"><span class="token punctuation">{</span>output_tensor<span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span>    
    
init_process<span class="token punctuation">(</span><span class="token punctuation">)</span>
example_reduce_scatter<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>Output</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>Before ReduceScatter on rank 0: [tensor([1., 2.], device=&#39;cuda:0&#39;),
                                 tensor([1., 4.], device=&#39;cuda:0&#39;),
                                 tensor([1., 8.], device=&#39;cuda:0&#39;)]
Before ReduceScatter on rank 1: [tensor([2., 4.], device=&#39;cuda:1&#39;),
                                 tensor([ 4., 16.], device=&#39;cuda:1&#39;),
                                 tensor([ 8., 64.], device=&#39;cuda:1&#39;)]
Before ReduceScatter on rank 2: [tensor([3., 6.], device=&#39;cuda:2&#39;),
                                 tensor([ 9., 36.], device=&#39;cuda:2&#39;),
                                 tensor([ 27., 216.], device=&#39;cuda:2&#39;)]

After ReduceScatter on rank 0: tensor([ 6., 12.], device=&#39;cuda:0&#39;)
After ReduceScatter on rank 1: tensor([14., 56.], device=&#39;cuda:1&#39;)
After ReduceScatter on rank 2: tensor([ 36., 288.], device=&#39;cuda:2&#39;)
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_7-9-barrier" tabindex="-1"><a class="header-anchor" href="#_7-9-barrier" aria-hidden="true">#</a> 7.9. Barrier</h3><p>Code</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">example_barrier</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    rank <span class="token operator">=</span> dist<span class="token punctuation">.</span>get_rank<span class="token punctuation">(</span><span class="token punctuation">)</span>
    t_start <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;Rank </span><span class="token interpolation"><span class="token punctuation">{</span>rank<span class="token punctuation">}</span></span><span class="token string"> sleeps </span><span class="token interpolation"><span class="token punctuation">{</span>rank<span class="token punctuation">}</span></span><span class="token string"> seconds.&quot;</span></span><span class="token punctuation">)</span>
    time<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span>rank<span class="token punctuation">)</span>  <span class="token comment"># Simulate different processing times</span>
    dist<span class="token punctuation">.</span>barrier<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;Rank </span><span class="token interpolation"><span class="token punctuation">{</span>rank<span class="token punctuation">}</span></span><span class="token string"> after barrier time delta: </span><span class="token interpolation"><span class="token punctuation">{</span>time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">-</span>t_start<span class="token punctuation">:</span><span class="token format-spec">.4f</span><span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span>
    
init_process<span class="token punctuation">(</span><span class="token punctuation">)</span>
example_barrier<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>Output</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>Rank 0 sleeps 0 seconds.
Rank 1 sleeps 1 seconds.
Rank 2 sleeps 2 seconds.

Rank 0 after barrier time delta: 2.0025
Rank 1 after barrier time delta: 2.0025
Rank 2 after barrier time delta: 2.0024
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,67);function b(g,h){return i(),l("div",null,[v,u(" more "),m])}const x=c(k,[["render",b],["__file","025_distribution_and_parallelism_1.html.vue"]]);export{x as default};
