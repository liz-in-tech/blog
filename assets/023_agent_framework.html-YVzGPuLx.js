import{_ as l}from"./plugin-vue_export-helper-x3n3nnut.js";import{r as t,o as r,c as o,f as c,a,b as n,d as i,e as s}from"./app-xaZLmYxW.js";const d={},p=a("h1",{id:"langchain-and-llamaindex-integration",tabindex:"-1"},[a("a",{class:"header-anchor",href:"#langchain-and-llamaindex-integration","aria-hidden":"true"},"#"),n(" Langchain and LLamaindex Integration")],-1),u=a("ul",null,[a("li",null,"Langchain 与 LLamaindex 各自优势"),a("li",null,"LlamaHub"),a("li",null,"最佳实践"),a("li",null,"如何整合")],-1),h=s(`<h2 id="_1-各自优势" tabindex="-1"><a class="header-anchor" href="#_1-各自优势" aria-hidden="true">#</a> 1. 各自优势</h2><ul><li><p>LangChain特点</p><ul><li>通用性和高度模块化：LangChain 是一个通用性强的高度模块化和可扩展的框架，适用于构建各种类型的应用程序。它提供了加载、处理和索引数据的工具，并能与 LLM 进行交互。</li><li>自定义能力强：LangChain 允许开发者自定义应用程序的行为，适合需要灵活和可扩展的通用应用程序。</li><li>复杂工作流与上下文管理：LangChain 适合处理复杂的工作流和上下文管理，尤其适合构建智能Agent（intelligent agents），能够同时执行多个任务。</li><li>工具集成：LangChain 提供了丰富的组件和现成的链（chains），便于开发者定制现有的链或构建新的链，适合需要集成多种工具的应用程序。</li></ul></li><li><p>LlamaIndex特点</p><ul><li>专为搜索与检索设计：LlamaIndex 专为构建搜索和检索应用程序而设计，提供了一个简单的界面来查询 LLM 并检索相关文档。</li><li>高效的数据处理：LlamaIndex 在处理大量数据时表现出色，适合需要高效索引和检索的应用程序。</li><li>数据连接与集成：LlamaIndex 提供了丰富的数据连接器，能够轻松集成多种数据源（如 APIs、PDFs、SQL 数据库等），并优化了数据摄取过程。</li><li>深度索引与检索：LlamaIndex 在 LLM 的深度索引和检索方面表现优异，适合需要深入探索数据的应用场景。</li></ul></li></ul><h2 id="_2-llamahub" tabindex="-1"><a class="header-anchor" href="#_2-llamahub" aria-hidden="true">#</a> 2. LlamaHub</h2><p>https://llamahub.ai/</p><ul><li>社区驱动：LlamaHub由一个活跃的开发者社区维护，不断有新的加载器、工具和包被添加进来。</li><li>易于集成：设计为易于与LlamaIndex和LangChain等流行框架集成，简化开发流程。</li><li>多功能工具：提供从数据加载到复杂数据处理的全面工具集，支持多种数据源和第三方服务。</li><li>开源与可扩展：完全开源，鼓励社区贡献，易于根据特定需求进行扩展和定制。</li></ul><h2 id="_3-最佳实践" tabindex="-1"><a class="header-anchor" href="#_3-最佳实践" aria-hidden="true">#</a> 3. 最佳实践</h2><p>LangChain适用场景：整合多种工具，执行多任务，更广泛的功能，构建灵活和可扩展的通用应用程序，只需要使用LLM而不需要使用RAG的场景</p><p>LlamaIndex适用场景：专业高效的智能索引和检索，更简单容易的使用插件和数据连接器来获取数据，深入探索数据，构建高效、简单的搜索和检索应用程序</p><p>LlamaIndex 可以集成到 LangChain 中，以改进和优化LangChain的检索能力，LangChain 负责复杂工作流和上下文管理，LlamaIndex 负责高效数据检索，从而发挥各自的优势。</p><p>LangChain与LlamaIndex的结合适用场景：Agent结合RAG的场景，构建需要同时处理复杂逻辑和高效数据检索的应用程序</p><h2 id="_4-如何整合" tabindex="-1"><a class="header-anchor" href="#_4-如何整合" aria-hidden="true">#</a> 4. 如何整合</h2><h3 id="_4-1-方式一-llamaindex作为langchain-agent中的一个工具tool" tabindex="-1"><a class="header-anchor" href="#_4-1-方式一-llamaindex作为langchain-agent中的一个工具tool" aria-hidden="true">#</a> 4.1. 方式一：LlamaIndex作为LangChain Agent中的一个工具Tool</h3><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> llama_index<span class="token punctuation">.</span>core<span class="token punctuation">.</span>langchain_helpers<span class="token punctuation">.</span>agents <span class="token keyword">import</span> <span class="token punctuation">(</span>
    IndexToolConfig<span class="token punctuation">,</span>
    LlamaIndexTool<span class="token punctuation">,</span>
<span class="token punctuation">)</span>

tool_config <span class="token operator">=</span> IndexToolConfig<span class="token punctuation">(</span>
    query_engine<span class="token operator">=</span>query_engine<span class="token punctuation">,</span>
    name<span class="token operator">=</span><span class="token string-interpolation"><span class="token string">f&quot;Vector Index&quot;</span></span><span class="token punctuation">,</span>
    description<span class="token operator">=</span><span class="token string-interpolation"><span class="token string">f&quot;useful for when you want to answer queries about X&quot;</span></span><span class="token punctuation">,</span>
    tool_kwargs<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">&quot;return_direct&quot;</span><span class="token punctuation">:</span> <span class="token boolean">True</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>

tool <span class="token operator">=</span> LlamaIndexTool<span class="token punctuation">.</span>from_tool_config<span class="token punctuation">(</span>tool_config<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_4-2-方式二-llamaindex作为langchain-agent中的检索器retrievers" tabindex="-1"><a class="header-anchor" href="#_4-2-方式二-llamaindex作为langchain-agent中的检索器retrievers" aria-hidden="true">#</a> 4.2. 方式二：LlamaIndex作为LangChain Agent中的检索器Retrievers</h3>`,14),m={href:"https://python.langchain.com/api_reference/community/retrievers/langchain_community.retrievers.llama_index.LlamaIndexRetriever.html",target:"_blank",rel:"noopener noreferrer"},g=a("div",{class:"language-text line-numbers-mode","data-ext":"text"},[a("pre",{class:"language-text"},[a("code",null,`from langchain_community.retrievers.llama_index import LlamaIndexRetriever
`)]),a("div",{class:"line-numbers","aria-hidden":"true"},[a("div",{class:"line-number"})])],-1),_={href:"https://python.langchain.com/api_reference/community/retrievers/langchain_community.retrievers.llama_index.LlamaIndexGraphRetriever.html",target:"_blank",rel:"noopener noreferrer"},x=s(`<div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>from langchain_community.retrievers.llama_index import LlamaIndexGraphRetriever
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><h3 id="_4-3-方式三-llamaindex作为langchain-agent中的记忆模块memory" tabindex="-1"><a class="header-anchor" href="#_4-3-方式三-llamaindex作为langchain-agent中的记忆模块memory" aria-hidden="true">#</a> 4.3. 方式三：LlamaIndex作为LangChain Agent中的记忆模块Memory</h3><h2 id="_5-参考文档" tabindex="-1"><a class="header-anchor" href="#_5-参考文档" aria-hidden="true">#</a> 5. 参考文档</h2><p>LlamaIndex文档：https://docs.llamaindex.ai/en/v0.10.18/community/integrations/using_with_langchain.html</p><p>LangChain文档：https://python.langchain.com/docs/integrations/providers/llama_index/</p><p>https://aimarketplace.co/llamaindex-and-langchain-integration</p>`,6);function v(L,k){const e=t("ExternalLinkIcon");return r(),o("div",null,[p,u,c(" more "),h,a("p",null,[a("a",m,[n("LlamaIndexRetriever"),i(e)])]),g,a("p",null,[a("a",_,[n("LlamaIndexGraphRetriever"),i(e)])]),x])}const I=l(d,[["render",v],["__file","023_agent_framework.html.vue"]]);export{I as default};
