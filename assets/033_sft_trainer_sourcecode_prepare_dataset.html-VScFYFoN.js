import{_ as a}from"./plugin-vue_export-helper-x3n3nnut.js";import{o as t,c as e,f as p,a as n,b as s,e as o}from"./app-GFs-dEn5.js";const i={},c=n("h1",{id:"sfttrainer-源码解读-prepare-dataset",tabindex:"-1"},[n("a",{class:"header-anchor",href:"#sfttrainer-源码解读-prepare-dataset","aria-hidden":"true"},"#"),s(" SFTTrainer 源码解读: Prepare Dataset")],-1),l=n("ul",null,[n("li",null,"Prepare Dataset 总体逻辑"),n("li",null,[s("Prepare Dataset 代码细节 "),n("ul",null,[n("li",null,[s("SFTTrainer."),n("strong",null,"init")]),n("li",null,"DataCollatorForLanguageModeling"),n("li",null,"_prepare_dataset")])])],-1),u=o(`<h2 id="_1-prepare-dataset-总体逻辑" tabindex="-1"><a class="header-anchor" href="#_1-prepare-dataset-总体逻辑" aria-hidden="true">#</a> 1. Prepare Dataset 总体逻辑</h2><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>总体逻辑
- 1.如果 processing_class 为 None，则使用基础模型的 tokenizer
- 2.处理 Data collator，在右侧填充 pad_token，使长度一致
- 3.查看 dataset 列名中是否有 &quot;input_ids&quot;，如果有，表示已进行过预处理，后续将跳过预处理步骤
- 4.如果列名中有 &quot;input_ids&quot;（表示已进行过预处理），就会忽略 formatting_func，否则进行 formatting_func 处理
    - 根据 formatting_func 的返回类型自动判断是否启用批处理，然后对 dataset 进行映射操作，把每个样本格式化成 {&quot;text&quot;: formatting_func结果} 的形式
- 5.如果 dataset 列名中包含 &quot;prompt&quot; 和 &quot;completion&quot; 字段
    - 判断是否是对话格式（包含&quot;role&quot;和&quot;content&quot;的格式）还是文本格式
    - 将 dataset 进行映射操作
        - 如果是是对话格式，把每个样本格式化成 {&quot;messages&quot;: example[&quot;prompt&quot;] + example[&quot;completion&quot;]} 的形式
        - 如果是是文本格式，把每个样本格式化成 {&quot;text&quot;: example[&quot;prompt&quot;] + example[&quot;completion&quot;]} 的形式
- 6.进行预处理步骤（如果列名中有 &quot;input_ids&quot; 则不处理）
    - 将对话格式处理为统一的 ChatML 格式：{&#39;messages&#39;: [{&#39;role&#39;: &#39;user&#39;, &#39;content&#39;: &#39;What color is the sky?&#39;},{&#39;role&#39;: &#39;assistant&#39;, &#39;content&#39;: &#39;It is blue.&#39;}]}
    - 应用 tokenizer.apply_chat_template 将对话格式 &quot;messages&quot; 都转为文本格式：{&quot;text&quot;: &quot;xxx&quot;}
    - 将 &quot;text&quot; 字段采用 tokenizer 进行 token 化，生成 &quot;input_ids&quot; 和 &quot;attention_mask&quot; 字段
- 7.返回处理后的 dataset，其中一定包含三个字段：&#39;text&#39;, &#39;input_ids&#39;, &#39;attention_mask&#39;
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="_2-prepare-dataset-代码细节" tabindex="-1"><a class="header-anchor" href="#_2-prepare-dataset-代码细节" aria-hidden="true">#</a> 2. Prepare Dataset 代码细节</h2><h3 id="_2-1-sfttrainer-init" tabindex="-1"><a class="header-anchor" href="#_2-1-sfttrainer-init" aria-hidden="true">#</a> 2.1. SFTTrainer.<strong>init</strong></h3><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">SFTTrainer</span><span class="token punctuation">(</span>Trainer<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">&quot;&quot;&quot;
    Trainer for Supervised Fine-Tuning (SFT) method.
    &quot;&quot;&quot;</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># Handle the tokenizer</span>
        <span class="token keyword">if</span> processing_class <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            processing_class <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_id<span class="token punctuation">)</span>
        
        <span class="token comment"># Data collator</span>
        <span class="token keyword">if</span> data_collator <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            <span class="token comment"># Get the pad token: if not provided, use the one from the processing class or the eos token</span>
            <span class="token comment"># if the processing class does not have a pad token.</span>
            pad_token <span class="token operator">=</span> args<span class="token punctuation">.</span>pad_token <span class="token keyword">or</span> processing_class<span class="token punctuation">.</span>pad_token <span class="token keyword">or</span> processing_class<span class="token punctuation">.</span>eos_token
            pad_token_id <span class="token operator">=</span> processing_class<span class="token punctuation">.</span>convert_tokens_to_ids<span class="token punctuation">(</span>pad_token<span class="token punctuation">)</span>
            <span class="token keyword">if</span> pad_token_id <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
                <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span>
                    <span class="token string-interpolation"><span class="token string">f&quot;The specified \`pad_token\` (&#39;</span><span class="token interpolation"><span class="token punctuation">{</span>pad_token<span class="token punctuation">}</span></span><span class="token string">&#39;) is not found in the vocabulary of the given &quot;</span></span>
                    <span class="token string-interpolation"><span class="token string">f&quot;\`processing_class\` (</span><span class="token interpolation"><span class="token punctuation">{</span>processing_class<span class="token punctuation">.</span>__class__<span class="token punctuation">.</span>__name__<span class="token punctuation">}</span></span><span class="token string">). Ensure that the \`pad_token\` exists &quot;</span></span>
                    <span class="token string">&quot;in the vocabulary before using it as a padding token.&quot;</span>
                <span class="token punctuation">)</span>
            data_collator <span class="token operator">=</span> DataCollatorForLanguageModeling<span class="token punctuation">(</span>pad_token_id<span class="token punctuation">)</span>

        <span class="token comment"># Dataset</span>
        train_dataset <span class="token operator">=</span> self<span class="token punctuation">.</span>_prepare_dataset<span class="token punctuation">(</span>
                train_dataset<span class="token punctuation">,</span> processing_class<span class="token punctuation">,</span> args<span class="token punctuation">,</span> args<span class="token punctuation">.</span>packing<span class="token punctuation">,</span> formatting_func<span class="token punctuation">,</span> <span class="token string">&quot;train&quot;</span>
            <span class="token punctuation">)</span>
        <span class="token keyword">if</span> eval_dataset <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            packing <span class="token operator">=</span> args<span class="token punctuation">.</span>packing <span class="token keyword">if</span> args<span class="token punctuation">.</span>eval_packing <span class="token keyword">is</span> <span class="token boolean">None</span> <span class="token keyword">else</span> args<span class="token punctuation">.</span>eval_packing
            <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>eval_dataset<span class="token punctuation">,</span> <span class="token builtin">dict</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                eval_dataset <span class="token operator">=</span> <span class="token punctuation">{</span>
                    key<span class="token punctuation">:</span> self<span class="token punctuation">.</span>_prepare_dataset<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> processing_class<span class="token punctuation">,</span> args<span class="token punctuation">,</span> packing<span class="token punctuation">,</span> formatting_func<span class="token punctuation">,</span> key<span class="token punctuation">)</span>
                    <span class="token keyword">for</span> key<span class="token punctuation">,</span> dataset <span class="token keyword">in</span> eval_dataset<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span>
                <span class="token punctuation">}</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                eval_dataset <span class="token operator">=</span> self<span class="token punctuation">.</span>_prepare_dataset<span class="token punctuation">(</span>
                    eval_dataset<span class="token punctuation">,</span> processing_class<span class="token punctuation">,</span> args<span class="token punctuation">,</span> packing<span class="token punctuation">,</span> formatting_func<span class="token punctuation">,</span> <span class="token string">&quot;eval&quot;</span>
                <span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_2-2-datacollatorforlanguagemodeling" tabindex="-1"><a class="header-anchor" href="#_2-2-datacollatorforlanguagemodeling" aria-hidden="true">#</a> 2.2. DataCollatorForLanguageModeling</h3><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token decorator annotation punctuation">@dataclass</span>
<span class="token keyword">class</span> <span class="token class-name">DataCollatorForLanguageModeling</span><span class="token punctuation">(</span>DataCollatorMixin<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">&quot;&quot;&quot;
    Data collator used for language modeling data. Inputs are dynamically padded to the maximum length of a batch if
    they are not all of the same length.

    Args:
        pad_token_id (\`int\`):
            Token ID to use for padding.
        return_tensors (\`str\`, *optional*, defaults to \`&quot;pt&quot;\`):
            Type of Tensor to return. Only \`&quot;pt&quot;\` is currently supported.

    Examples:
    from trl import DataCollatorForLanguageModeling
    collator = DataCollatorForLanguageModeling(pad_token_id=0)
    examples = [
        {&quot;input_ids&quot;: [1, 2, 3]},
        {&quot;input_ids&quot;: [4, 5]}
    ]
    collator(examples)
    {&#39;input_ids&#39;: tensor([[   1,   2,   3],
                          [   4,   5,   0]]),
     &#39;attention_mask&#39;: tensor([[  1,   1,   1],
                               [  1,   1,   0]]),
     &#39;labels&#39;: tensor([[   1,    2,    3],
                       [   4,    5, -100]])
    &quot;&quot;&quot;</span>

    pad_token_id<span class="token punctuation">:</span> <span class="token builtin">int</span>
    return_tensors<span class="token punctuation">:</span> <span class="token builtin">str</span> <span class="token operator">=</span> <span class="token string">&quot;pt&quot;</span>

    <span class="token keyword">def</span> <span class="token function">torch_call</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> examples<span class="token punctuation">:</span> <span class="token builtin">list</span><span class="token punctuation">[</span>Union<span class="token punctuation">[</span><span class="token builtin">list</span><span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">]</span><span class="token punctuation">,</span> Any<span class="token punctuation">,</span> <span class="token builtin">dict</span><span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">,</span> Any<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">dict</span><span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">,</span> Any<span class="token punctuation">]</span><span class="token punctuation">:</span>
        <span class="token comment"># Convert to tensor</span>
        input_ids <span class="token operator">=</span> <span class="token punctuation">[</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>example<span class="token punctuation">[</span><span class="token string">&quot;input_ids&quot;</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">for</span> example <span class="token keyword">in</span> examples<span class="token punctuation">]</span>
        attention_mask <span class="token operator">=</span> <span class="token punctuation">[</span>torch<span class="token punctuation">.</span>ones_like<span class="token punctuation">(</span>input_ids<span class="token punctuation">)</span> <span class="token keyword">for</span> input_ids <span class="token keyword">in</span> input_ids<span class="token punctuation">]</span>
        labels <span class="token operator">=</span> <span class="token punctuation">[</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>example<span class="token punctuation">[</span><span class="token string">&quot;input_ids&quot;</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">for</span> example <span class="token keyword">in</span> examples<span class="token punctuation">]</span>

        <span class="token comment"># Pad</span>
        output <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
        output<span class="token punctuation">[</span><span class="token string">&quot;input_ids&quot;</span><span class="token punctuation">]</span> <span class="token operator">=</span> pad<span class="token punctuation">(</span>input_ids<span class="token punctuation">,</span> padding_value<span class="token operator">=</span>self<span class="token punctuation">.</span>pad_token_id<span class="token punctuation">,</span> padding_side<span class="token operator">=</span><span class="token string">&quot;right&quot;</span><span class="token punctuation">)</span>
        output<span class="token punctuation">[</span><span class="token string">&quot;attention_mask&quot;</span><span class="token punctuation">]</span> <span class="token operator">=</span> pad<span class="token punctuation">(</span>attention_mask<span class="token punctuation">,</span> padding_value<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> padding_side<span class="token operator">=</span><span class="token string">&quot;right&quot;</span><span class="token punctuation">)</span>
        output<span class="token punctuation">[</span><span class="token string">&quot;labels&quot;</span><span class="token punctuation">]</span> <span class="token operator">=</span> pad<span class="token punctuation">(</span>labels<span class="token punctuation">,</span> padding_value<span class="token operator">=</span><span class="token operator">-</span><span class="token number">100</span><span class="token punctuation">,</span> padding_side<span class="token operator">=</span><span class="token string">&quot;right&quot;</span><span class="token punctuation">)</span>

        <span class="token keyword">return</span> output
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_2-3-prepare-dataset" tabindex="-1"><a class="header-anchor" href="#_2-3-prepare-dataset" aria-hidden="true">#</a> 2.3. _prepare_dataset</h3><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">_prepare_dataset</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># If the dataset is already preprocessed (tokenized), skip the processing steps.</span>
    column_names <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">next</span><span class="token punctuation">(</span><span class="token builtin">iter</span><span class="token punctuation">(</span>dataset<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    is_processed <span class="token operator">=</span> <span class="token string">&quot;input_ids&quot;</span> <span class="token keyword">in</span> column_names

    <span class="token comment"># Apply the formatting function if any</span>
    <span class="token keyword">if</span> formatting_func <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span> <span class="token keyword">and</span> is_processed<span class="token punctuation">:</span>
        warnings<span class="token punctuation">.</span>warn<span class="token punctuation">(</span>
            <span class="token string">&quot;You passed a dataset that is already processed (contains an \`input_ids\` field) together with a &quot;</span>
            <span class="token string">&quot;formatting function. Therefore \`formatting_func\` will be ignored. Either remove the &quot;</span>
            <span class="token string">&quot;\`formatting_func\` or pass a dataset that is not already processed.&quot;</span><span class="token punctuation">,</span>
            UserWarning<span class="token punctuation">,</span>
        <span class="token punctuation">)</span>

    <span class="token keyword">if</span> formatting_func <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span> <span class="token keyword">and</span> <span class="token keyword">not</span> is_processed<span class="token punctuation">:</span>
        <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># \`IterableDataset.map\` does not support \`desc\`</span>
            map_kwargs<span class="token punctuation">[</span><span class="token string">&quot;desc&quot;</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string-interpolation"><span class="token string">f&quot;Applying formatting function to </span><span class="token interpolation"><span class="token punctuation">{</span>dataset_name<span class="token punctuation">}</span></span><span class="token string"> dataset&quot;</span></span>

        batched <span class="token operator">=</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>formatting_func<span class="token punctuation">(</span><span class="token builtin">next</span><span class="token punctuation">(</span><span class="token builtin">iter</span><span class="token punctuation">(</span>dataset<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">list</span><span class="token punctuation">)</span>

        <span class="token keyword">def</span> <span class="token function">_func</span><span class="token punctuation">(</span>example<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">return</span> <span class="token punctuation">{</span><span class="token string">&quot;text&quot;</span><span class="token punctuation">:</span> formatting_func<span class="token punctuation">(</span>example<span class="token punctuation">)</span><span class="token punctuation">}</span>

        dataset <span class="token operator">=</span> dataset<span class="token punctuation">.</span><span class="token builtin">map</span><span class="token punctuation">(</span>_func<span class="token punctuation">,</span> batched<span class="token operator">=</span>batched<span class="token punctuation">,</span> <span class="token operator">**</span>map_kwargs<span class="token punctuation">)</span>

    <span class="token comment"># If the dataset is prompt-completion, convert it to language modeling type</span>
    first_example <span class="token operator">=</span> <span class="token builtin">next</span><span class="token punctuation">(</span><span class="token builtin">iter</span><span class="token punctuation">(</span>dataset<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">if</span> <span class="token string">&quot;prompt&quot;</span> <span class="token keyword">in</span> first_example<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">and</span> <span class="token string">&quot;completion&quot;</span> <span class="token keyword">in</span> first_example<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        key <span class="token operator">=</span> <span class="token string">&quot;messages&quot;</span> <span class="token keyword">if</span> is_conversational<span class="token punctuation">(</span>first_example<span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">&quot;text&quot;</span>

        <span class="token keyword">def</span> <span class="token function">concat_prompt_completion</span><span class="token punctuation">(</span>example<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">return</span> <span class="token punctuation">{</span>key<span class="token punctuation">:</span> example<span class="token punctuation">[</span><span class="token string">&quot;prompt&quot;</span><span class="token punctuation">]</span> <span class="token operator">+</span> example<span class="token punctuation">[</span><span class="token string">&quot;completion&quot;</span><span class="token punctuation">]</span><span class="token punctuation">}</span>

        dataset <span class="token operator">=</span> dataset<span class="token punctuation">.</span><span class="token builtin">map</span><span class="token punctuation">(</span>concat_prompt_completion<span class="token punctuation">,</span> remove_columns<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">&quot;prompt&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;completion&quot;</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

    <span class="token keyword">if</span> <span class="token keyword">not</span> is_processed<span class="token punctuation">:</span>
        <span class="token comment"># Convert the dataset to ChatML if needed</span>
        <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># \`IterableDataset.map\` does not support \`desc\`</span>
            map_kwargs<span class="token punctuation">[</span><span class="token string">&quot;desc&quot;</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string-interpolation"><span class="token string">f&quot;Converting </span><span class="token interpolation"><span class="token punctuation">{</span>dataset_name<span class="token punctuation">}</span></span><span class="token string"> dataset to ChatML&quot;</span></span>
        column_names <span class="token operator">=</span> <span class="token builtin">next</span><span class="token punctuation">(</span><span class="token builtin">iter</span><span class="token punctuation">(</span>dataset<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span>
        dataset <span class="token operator">=</span> dataset<span class="token punctuation">.</span><span class="token builtin">map</span><span class="token punctuation">(</span>
            maybe_convert_to_chatml<span class="token punctuation">,</span>
            remove_columns<span class="token operator">=</span><span class="token string">&quot;conversations&quot;</span> <span class="token keyword">if</span> <span class="token string">&quot;conversations&quot;</span> <span class="token keyword">in</span> column_names <span class="token keyword">else</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
            <span class="token operator">**</span>map_kwargs<span class="token punctuation">,</span>
        <span class="token punctuation">)</span>

        <span class="token comment"># Apply the chat template if needed</span>
        <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># \`IterableDataset.map\` does not support \`desc\`</span>
            map_kwargs<span class="token punctuation">[</span><span class="token string">&quot;desc&quot;</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string-interpolation"><span class="token string">f&quot;Applying chat template to </span><span class="token interpolation"><span class="token punctuation">{</span>dataset_name<span class="token punctuation">}</span></span><span class="token string"> dataset&quot;</span></span>
        column_names <span class="token operator">=</span> <span class="token builtin">next</span><span class="token punctuation">(</span><span class="token builtin">iter</span><span class="token punctuation">(</span>dataset<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span>
        dataset <span class="token operator">=</span> dataset<span class="token punctuation">.</span><span class="token builtin">map</span><span class="token punctuation">(</span>
            maybe_apply_chat_template<span class="token punctuation">,</span>
            fn_kwargs<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">&quot;tokenizer&quot;</span><span class="token punctuation">:</span> processing_class<span class="token punctuation">}</span><span class="token punctuation">,</span>
            remove_columns<span class="token operator">=</span><span class="token string">&quot;messages&quot;</span> <span class="token keyword">if</span> <span class="token string">&quot;messages&quot;</span> <span class="token keyword">in</span> column_names <span class="token keyword">else</span> <span class="token boolean">None</span><span class="token punctuation">,</span>  <span class="token comment"># renamed to &quot;text&quot;</span>
            <span class="token operator">**</span>map_kwargs<span class="token punctuation">,</span>
        <span class="token punctuation">)</span>

        <span class="token comment"># Tokenize the dataset if needed</span>
        <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># \`IterableDataset.map\` does not support \`desc\`</span>
            map_kwargs<span class="token punctuation">[</span><span class="token string">&quot;desc&quot;</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string-interpolation"><span class="token string">f&quot;Tokenizing </span><span class="token interpolation"><span class="token punctuation">{</span>dataset_name<span class="token punctuation">}</span></span><span class="token string"> dataset&quot;</span></span>

        <span class="token keyword">def</span> <span class="token function">tokenize</span><span class="token punctuation">(</span>example<span class="token punctuation">,</span> processing_class<span class="token punctuation">,</span> dataset_text_field<span class="token punctuation">)</span><span class="token punctuation">:</span>
            processed <span class="token operator">=</span> processing_class<span class="token punctuation">(</span>text<span class="token operator">=</span>example<span class="token punctuation">[</span>dataset_text_field<span class="token punctuation">]</span><span class="token punctuation">)</span>
            <span class="token keyword">if</span> <span class="token punctuation">(</span>
                processing_class<span class="token punctuation">.</span>eos_token_id <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span>
                <span class="token keyword">and</span> processed<span class="token punctuation">[</span><span class="token string">&quot;input_ids&quot;</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">!=</span> processing_class<span class="token punctuation">.</span>eos_token_id
            <span class="token punctuation">)</span><span class="token punctuation">:</span>
                processed<span class="token punctuation">[</span><span class="token string">&quot;input_ids&quot;</span><span class="token punctuation">]</span> <span class="token operator">=</span> processed<span class="token punctuation">[</span><span class="token string">&quot;input_ids&quot;</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token punctuation">[</span>processing_class<span class="token punctuation">.</span>eos_token_id<span class="token punctuation">]</span>
                processed<span class="token punctuation">[</span><span class="token string">&quot;attention_mask&quot;</span><span class="token punctuation">]</span> <span class="token operator">=</span> processed<span class="token punctuation">[</span><span class="token string">&quot;attention_mask&quot;</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
            <span class="token keyword">return</span> processed

        dataset <span class="token operator">=</span> dataset<span class="token punctuation">.</span><span class="token builtin">map</span><span class="token punctuation">(</span>
            tokenize<span class="token punctuation">,</span>
            fn_kwargs<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">&quot;processing_class&quot;</span><span class="token punctuation">:</span> processing_class<span class="token punctuation">,</span> <span class="token string">&quot;dataset_text_field&quot;</span><span class="token punctuation">:</span> args<span class="token punctuation">.</span>dataset_text_field<span class="token punctuation">}</span><span class="token punctuation">,</span>
            <span class="token operator">**</span>map_kwargs<span class="token punctuation">,</span>
        <span class="token punctuation">)</span>
    
    <span class="token keyword">return</span> dataset
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,9);function r(d,k){return t(),e("div",null,[c,l,p(" more "),u])}const b=a(i,[["render",r],["__file","033_sft_trainer_sourcecode_prepare_dataset.html.vue"]]);export{b as default};
