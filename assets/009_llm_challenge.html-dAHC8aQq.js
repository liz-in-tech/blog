import{_ as i}from"./plugin-vue_export-helper-x3n3nnut.js";import{o as e,c as a,f as r,a as l,b as h,e as n}from"./app-UEw0SYZq.js";const d={},t=l("h1",{id:"大模型的商业化落地挑战",tabindex:"-1"},[l("a",{class:"header-anchor",href:"#大模型的商业化落地挑战","aria-hidden":"true"},"#"),h(" 大模型的商业化落地挑战")],-1),u=l("ul",null,[l("li",null,"现阶段快速实现商业化落地的方案：RAG"),l("li",null,"大模型的商业化落地挑战"),l("li",null,"生成与检索"),l("li",null,"场景：智能客服系统的实现思路")],-1),o=n('<h2 id="_1-现阶段快速实现商业化落地的方案-rag" tabindex="-1"><a class="header-anchor" href="#_1-现阶段快速实现商业化落地的方案-rag" aria-hidden="true">#</a> 1. 现阶段快速实现商业化落地的方案：RAG</h2><ul><li>RAG（Retrieval-Augmented Generation, 检索增强生成）</li><li>RAG是现阶段快速实现商业化落地的方案</li><li>因为可以将原先的业务数据快速迁移到大模型领域</li></ul><h2 id="_2-大模型的商业化落地挑战" tabindex="-1"><a class="header-anchor" href="#_2-大模型的商业化落地挑战" aria-hidden="true">#</a> 2. 大模型的商业化落地挑战</h2><h3 id="_2-1-效果" tabindex="-1"><a class="header-anchor" href="#_2-1-效果" aria-hidden="true">#</a> 2.1. 效果</h3><ul><li>B端和C端的要求不太一样 <ul><li>B端：企业落地需要很高的要求</li><li>C端：要求低一点，有高的容错性，用户可以买单</li></ul></li></ul><h3 id="_2-2-可控生成-controllable-generation" tabindex="-1"><a class="header-anchor" href="#_2-2-可控生成-controllable-generation" aria-hidden="true">#</a> 2.2. 可控生成（Controllable Generation）</h3><ul><li>大模型通过生成来实现，有一定自由度，那生成的内容就不可能完全是我们想要的</li><li>给大模型一些限制，让它按照预期的情况生成内容</li></ul><h4 id="_2-3-隐私" tabindex="-1"><a class="header-anchor" href="#_2-3-隐私" aria-hidden="true">#</a> 2.3. 隐私</h4><ul><li>通过刻意引导，大模型如gpt4也可能把用户的一些隐私信息给套出来</li></ul><h4 id="_2-4-幻觉-hallucination-həˈluː-sɪ-neɪt" tabindex="-1"><a class="header-anchor" href="#_2-4-幻觉-hallucination-həˈluː-sɪ-neɪt" aria-hidden="true">#</a> 2.4. 幻觉，&quot;hallucination&quot;, /həˈluː.sɪ.neɪt/</h4><ul><li>一本正经的胡说八道 <ul><li>编造听起来合理但实际上不正确的内容</li><li>产生虚构信息，比如无效URL或不存在的数字</li></ul></li><li>如何减少幻觉 <ul><li>要求模型首先从文本中找到任何相关的引用，然后使用这些引用来回答问题，并可以追溯答案到原文档，这种方式通常可以减少幻觉</li></ul></li><li>问题：如果只根据给定的上下文来回复，是否能彻底解决模型的幻觉问题 <ul><li>不可能彻底解决，但可以大大地降低幻觉</li><li>不能彻底解决地原因 <ul><li>检索准确率</li><li>LLM理解能力</li><li>问题复杂度</li></ul></li></ul></li></ul><h2 id="_3-生成与检索" tabindex="-1"><a class="header-anchor" href="#_3-生成与检索" aria-hidden="true">#</a> 3. 生成与检索</h2><h3 id="_3-1-生成" tabindex="-1"><a class="header-anchor" href="#_3-1-生成" aria-hidden="true">#</a> 3.1. 生成</h3><ul><li>优点：内容的多样性、创造性</li><li>缺点： <ul><li>存在不可控性</li><li>不了解在训练数据之外的知识（eg.最近发生的事件；专有的信息内容）</li></ul></li></ul><h3 id="_3-2-检索" tabindex="-1"><a class="header-anchor" href="#_3-2-检索" aria-hidden="true">#</a> 3.2. 检索</h3><ul><li>优点： <ul><li>可控</li><li>补充更多专有或最近最新的知识内容</li></ul></li><li>缺点：内容的边界具有局限性</li></ul><h3 id="_3-3-生成与检索的结合-rag" tabindex="-1"><a class="header-anchor" href="#_3-3-生成与检索的结合-rag" aria-hidden="true">#</a> 3.3. 生成与检索的结合：RAG</h3><ul><li>RAG，其名称就是“检索增强生成”，通过检索来增强生成的能力</li><li>将生成和检索两者的优点结合在了一起</li></ul><h2 id="_4-场景-智能客服系统的实现思路" tabindex="-1"><a class="header-anchor" href="#_4-场景-智能客服系统的实现思路" aria-hidden="true">#</a> 4. 场景：智能客服系统的实现思路</h2><h3 id="_4-1-基于检索的思路" tabindex="-1"><a class="header-anchor" href="#_4-1-基于检索的思路" aria-hidden="true">#</a> 4.1. 基于检索的思路</h3><ul><li>1.构造常见问答对集&lt;Q,A&gt;（FAQ，Frequently Asked Question）</li><li>2.根据用户问题Query，检索相关的Question</li><li>3.给出相关Question的Answer作为结果</li></ul><p>特点：</p><ul><li>需要构造问答对集</li><li>Answer是确定可靠的</li></ul><h3 id="_4-2-基于生成的思路" tabindex="-1"><a class="header-anchor" href="#_4-2-基于生成的思路" aria-hidden="true">#</a> 4.2. 基于生成的思路</h3><ul><li>1.构造问答对集&lt;Q,A&gt;</li><li>2.用问答对集进行模型训练</li><li>3.用户提出问题Query，由Model生成结果</li></ul><p>特点：</p><ul><li>需要构造问答对集</li><li>结果是模型生成的，不太可靠和可控</li></ul><h3 id="_4-3-基于检索与生成的思路" tabindex="-1"><a class="header-anchor" href="#_4-3-基于检索与生成的思路" aria-hidden="true">#</a> 4.3. 基于检索与生成的思路</h3><ul><li>1.搭建知识库（不用组织成问答对形式）</li><li>2.用户提出问题Query</li><li>3.先从知识库中检索相关内容信息作为候选Candidate</li><li>4.将Query作为Input，将Candidate作为Context，还有历史消息History，由Prompt组织到一起</li><li>5.将Prompt传给LLM，由LLM给出结果</li></ul><p>特点：</p><ul><li>不需要将数据组织成问答对形式</li><li>LLM生成的内容参考了知识库中检索出的相关信息，更可靠</li></ul>',31);function s(c,_){return e(),a("div",null,[t,u,r(" more "),o])}const b=i(d,[["render",s],["__file","009_llm_challenge.html.vue"]]);export{b as default};
